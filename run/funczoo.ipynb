{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Function Zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook curates a list of helper functions. When a project finishes, reusable functions are moved here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib nbagg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import scipy.stats\n",
    "\n",
    "# Machine learning\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sklearn\n",
    "import sklearn.preprocessing, sklearn.base, sklearn.utils, sklearn.model_selection\n",
    "\n",
    "# Various Python tricks and libraries\n",
    "import requests\n",
    "import time\n",
    "import functools\n",
    "import operator\n",
    "import collections\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "import dill as pickle\n",
    "import IPython\n",
    "\n",
    "# Parallel\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterable to list (low performance, please avoid!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_iterable(L):\n",
    "    return hasattr(L, '__iter__')\n",
    "\n",
    "def to_iterable(L):\n",
    "    if isinstance(L, (np.ndarray, np.generic)):\n",
    "        return L.tolist()\n",
    "    if isinstance(L, pd.DataFrame):\n",
    "        return L.values.tolist()\n",
    "    if is_iterable(L):\n",
    "        return recursive_map(lambda x:x, L)\n",
    "    raise ValueError\n",
    "    \n",
    "def flatten(L):\n",
    "    return reduce(operator.add, map(lambda l: flatten(l) if is_iterable(l) else [l], L))\n",
    "\n",
    "def recursive_map(func, L):\n",
    "    return map(lambda l: recursive_map(func, l) if is_iterable(l) else func(l), L)\n",
    "\n",
    "def get_index(item, L, index_unexpected=-1, random_unexpected=0.): # first occurence or -1\n",
    "    return index_unexpected if np.random.rand() < random_unexpected or item not in L else np.argmax(np.array(L)==item)\n",
    "\n",
    "def get_value(index, L, value_unexpected_index=None, index_unexpected=-1): # L[index] or None\n",
    "    return value_unexpected_index if index == index_unexpected else L[index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data (low performance, please avoid!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin): \n",
    "    # sklearn.preprocessing.LabelEncoder with irregular 2D array, unexpected index or value, and random -1 return.\n",
    "    \n",
    "    def __init__(self, index_unexpected=-1, random_unexpected=0., value_unexpected_index=None):\n",
    "        self.index_unexpected = index_unexpected\n",
    "        self.random_unexpected = random_unexpected\n",
    "        self.value_unexpected_index = value_unexpected_index\n",
    "        \n",
    "    def fit(self, y):\n",
    "        y_flattened = flatten(y)\n",
    "        self.classes_ = np.unique(y_flattened)\n",
    "        return self\n",
    "\n",
    "    def transform(self, y):\n",
    "        func = functools.partial(get_index, \n",
    "                                 L=self.classes_, \n",
    "                                 index_unexpected=self.index_unexpected, \n",
    "                                 random_unexpected=self.random_unexpected)\n",
    "        return recursive_map(\n",
    "            func=lambda item: get_index(\n",
    "                item=item, \n",
    "                L=self.classes_, \n",
    "                index_unexpected=self.index_unexpected, \n",
    "                random_unexpected=self.random_unexpected),\n",
    "            L=y)\n",
    "\n",
    "    def inverse_transform(self, y):\n",
    "        return recursive_map(\n",
    "            func=lambda index: get_value(\n",
    "                index=index, \n",
    "                L=self.classes_, \n",
    "                index_unexpected=self.index_unexpected, \n",
    "                random_unexpected=self.random_unexpected),\n",
    "            L=y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(ytrue, ypred): # sklearn.metrics.r2_score in tensorflow. 1 output only. \n",
    "\n",
    "    ytrue_mean = tf.reduce_mean(ytrue, name=\"ytrue_mean\")\n",
    "    r2_score = tf.subtract(1., tf.truediv(tf.reduce_mean((ytrue - ypred) ** 2), tf.reduce_mean((ytrue - ytrue_mean) ** 2)), name=\"r2_score\")\n",
    "    return r2_score\n",
    "\n",
    "class TqdmProgBar(keras.callbacks.Callback):\n",
    "    '''features:\n",
    "    1. tqdm ETA bar\n",
    "    2. logs[field] plotted for each field in fields\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_epochs, fields): \n",
    "        self.n_epochs = n_epochs\n",
    "        self.fields = fields\n",
    "        \n",
    "        self.fields_history = dict((field, []) for field in fields)\n",
    "        self.fig, self.ax = plt.subplots(1, 1)\n",
    "        \n",
    "    def on_train_begin(self, logs):\n",
    "        self.pbar = tqdm_notebook(total=self.n_epochs, leave=False)\n",
    "        \n",
    "    def on_train_end(self, logs):\n",
    "        self.pbar.close()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs, log_interval = 40):\n",
    "        if epoch % log_interval == 0:\n",
    "            self.pbar.update(log_interval)\n",
    "\n",
    "            for field in self.fields:\n",
    "                self.fields_history[field].append(logs[field])\n",
    "\n",
    "            self.ax.clear()\n",
    "            for field in self.fields:\n",
    "                self.ax.plot(self.fields_history[field], label=\"%s=%.2f\" %(field, self.fields_history[field][-1]))\n",
    "            self.ax.legend(loc='best')\n",
    "            self.fig.canvas.draw()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline():\n",
    "    '''\n",
    "    Same as sklearn's pipeline except:\n",
    "    - does not require 2 inputs and outputs\n",
    "    - requires only fit() and transform()\n",
    "    - returns state list\n",
    "    - not too inefficient\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, ETs):\n",
    "        self.ETs = Estimators_Transformers = ETs\n",
    "      \n",
    "    def fit(self, *args):\n",
    "        '''Note: does not take keyworded input.'''\n",
    "        for ET in self.ETs:\n",
    "            args = ET.fit(*args).transform(*args)\n",
    "        return self\n",
    "\n",
    "    def transform(self, *args):\n",
    "        for ET in self.ETs:\n",
    "            args = ET.transform(*args)\n",
    "        return args\n",
    "    \n",
    "    def transforms(self, *args):\n",
    "        ET_s = []\n",
    "        for ET in self.ETs:\n",
    "            args = ET.transform(*args)\n",
    "            ET_s.append(args)\n",
    "        return ET_s\n",
    "    \n",
    "    def fit_transform(self, *args):\n",
    "        for ET in self.ETs:\n",
    "            args = ET.fit(*args).transform(*args)\n",
    "        return args\n",
    "    \n",
    "    def fit_transforms(self, *args):\n",
    "        ET_s = []\n",
    "        for ET in self.ETs:\n",
    "            args = ET.fit(*args).transform(*args)\n",
    "            ET_s.append(args)\n",
    "        return ET_s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
