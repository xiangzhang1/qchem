{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample\n",
    "\n",
    "\n",
    "        \n",
    "        jobs.loc[:, 'Wait'] = jobs.loc[:, 'Start'] - jobs.loc[:, 'Submit']\n",
    "        jobs.loc[:, 'Run'] = jobs.loc[:, 'End'] - jobs.loc[:, 'Start']\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        jobs = jobs.copy()\n",
    "        \n",
    "        jobs.loc[:, 'User'] = self.U_lbe.transform(jobs.loc[:, 'User'].copy())\n",
    "        \n",
    "        jobs.loc[:, ['Timelimit', 'Wait', 'Run']] = jobs.loc[:, ['Timelimit', 'Wait', 'Run']].copy().values / pd.Timedelta('10h')\n",
    "        jobs.loc[:, ['NNodes', 'Timelimit', 'Wait', 'Run']] = self.scaler.transform(jobs.loc[:, ['NNodes', 'Timelimit', 'Wait', 'Run']].copy())\n",
    "\n",
    "def extract_sample(i, jobs, TIMESTEPS = TIMESTEPS):\n",
    "    tj = thisjob = jobs.iloc[i].copy()\n",
    "    rj = jobs.iloc[i-TIMESTEPS:i+1].copy()\n",
    "    \n",
    "    rj.loc[:, 'Is_complete'] = rj.loc[:, 'End'].copy() < tj.Submit\n",
    "    rj.loc[:, 'Is_running'] = np.logical_and(rj.loc[:, 'End'].copy() > tj.Submit, rj.loc[:, 'Start'].copy() < tj.Submit)\n",
    "    rj.loc[:, 'Is_queueing'] = rj.loc[:, 'Start'].copy() > tj.Submit\n",
    "    rj.loc[:, 'Run'] = rj.loc[:, 'Run'].copy().values * rj.loc[:, 'Is_complete'].copy().values\n",
    "    rj.loc[:, 'Wait'] = rj.loc[:, 'Wait'].copy().values * (rj.loc[:, 'Is_complete'].copy().values + rj.loc[:, 'Is_running'].copy().values)\n",
    "    rj.loc[:, 'Queue'] = (rj.loc[:, 'Submit'] - rj.iloc[0, 3]) / pd.Timedelta('10h')\n",
    "    \n",
    "    rj.loc[:, 'Submit'] = pd.to_numeric(rj.loc[:, 'Submit'].copy())\n",
    "    \n",
    "    return [rj.loc[:, 'User'].copy().values, \n",
    "            rj.loc[:, ['NNodes', 'Timelimit']].copy().values, # 'Wait', 'Submit', 'Run', 'Queue', 'Is_complete', 'Is_running', 'Is_queueing'\n",
    "            [tj.Wait]]\n",
    "\n",
    "S = 9354 # np.random.randint(0, 13000 - TOTAL_SIZE)\n",
    "L = joblib.Parallel(n_jobs=20)(joblib.delayed(extract_sample)(i, jobs) for i in range(S, S + TOTAL_SIZE))\n",
    "U_ = np.int32(zip(*L)[0])\n",
    "X_ = np.float32(zip(*L)[1])\n",
    "y_ = np.float32(zip(*L)[2])\n",
    "\n",
    "# Prepare sample for ML\n",
    "Xscaler = sklearn.preprocessing.StandardScaler().fit(X_.reshape(-1, X_[:TRAIN_SIZE].shape[-1]))\n",
    "X_scaled = np.array([Xscaler.transform(_) for _ in X_])\n",
    "yscaler = sklearn.preprocessing.StandardScaler().fit(y_[:TRAIN_SIZE])\n",
    "y_scaled = sklearn.preprocessing.scale(y_)\n",
    "\n",
    "U_train, X_train, y_train = U_[:TRAIN_SIZE], X_scaled[:TRAIN_SIZE], y_scaled[:TRAIN_SIZE]\n",
    "U_test, X_test, y_test = U_[-TEST_SIZE:], X_scaled[-TEST_SIZE:], y_scaled[-TEST_SIZE:]\n",
    "# U_train, U_test, X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(U_, X_scaled, y_scaled, train_size=0.95, test_size=0.05)\n",
    "\n",
    "if np.random.rand() > np.std(y_test):\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select a model and train\n",
    "\n",
    "# graph\n",
    "U_VOCABULARY_SIZE = np.amax(U_) + 1\n",
    "N_EPOCHS = 300\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "r2s_train = []\n",
    "r2s_test = []\n",
    "fig, ax = plt.subplots(1,1)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "U_id = tf.placeholder(name=\"U_id\", dtype=tf.int32, shape=(None, None))\n",
    "U_embeddings = tf.get_variable(name=\"U_embeddings\", shape=[U_VOCABULARY_SIZE, 3])\n",
    "U = tf.nn.embedding_lookup(U_embeddings, U_id, name=\"U\")\n",
    "\n",
    "X = tf.placeholder(name=\"X\", dtype=tf.float32, shape=(None, None, 2))\n",
    "XU = tf.concat([X,U], axis=-1, name=\"XU\")\n",
    "XU.set_shape([None, None, 5])\n",
    "\n",
    "y = tf.placeholder(name=\"y\", dtype=tf.float32, shape=(None, 1))\n",
    "\n",
    "keep_prob = tf.placeholder(name=\"keep_prob\", dtype=tf.float32, shape=())\n",
    "\n",
    "# hs, h = tf.nn.dynamic_rnn(tf.contrib.rnn.GRUCell(5), X, dtype=tf.float32)\n",
    "hs, h = tf.nn.dynamic_rnn(tf.contrib.rnn.MultiRNNCell([tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell(5), tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell(1)]), XU, dtype=tf.float32)\n",
    "# h = tf.nn.dropout(h[1], keep_prob=keep_prob)\n",
    "yhat = tf.layers.dense(h[1], units=1, activation=None, name=\"yhat\")\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(yhat - y), keepdims=False)\n",
    "training_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n",
    "# training_op = tf.train.MomentumOptimizer(learning_rate=0.01, momentum=0.91, use_nesterov=True).minimize(loss)\n",
    "\n",
    "# sess\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "t = tqdm_notebook(range(N_EPOCHS * TRAIN_SIZE / BATCH_SIZE))\n",
    "for epoch in t:\n",
    "    index = np.random.choice(range(TRAIN_SIZE), BATCH_SIZE, replace=False)\n",
    "    sess.run(training_op, feed_dict={\n",
    "        U_id: U_train[index],\n",
    "        X: X_train[index],\n",
    "        y: y_train[index]\n",
    "    })\n",
    "    if epoch % 10 == 0:\n",
    "        yhat_train = sess.run(yhat, feed_dict={\n",
    "            U_id: U_train,\n",
    "            X: X_train,\n",
    "            y: y_train\n",
    "        })\n",
    "        r2_train = sklearn.metrics.r2_score(y_train.reshape(-1), yhat_train.reshape(-1))\n",
    "        r2s_train.append(r2_train)\n",
    "        ax.clear()\n",
    "        ax.plot(r2s_train, label='r2_train')\n",
    "        yhat_test = sess.run(yhat, feed_dict={\n",
    "            U_id: U_test,\n",
    "            X: X_test,\n",
    "            y: y_test\n",
    "        })\n",
    "        r2_test = sklearn.metrics.r2_score(y_test.reshape(-1), yhat_test.reshape(-1))\n",
    "        r2s_test.append(r2_test)\n",
    "        t.set_description('{0:.2f}, {1:.2f}'.format(r2_train, r2_test))\n",
    "        ax.plot(r2s_test, label='r2_test')\n",
    "        ax.legend(loc='best')\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.show()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.scatter(yscaler.inverse_transform(y_train).reshape(-1), yscaler.inverse_transform(yhat_train).reshape(-1), s=1, alpha=0.5, color='black', label='train', marker='o')\n",
    "plt.scatter(yscaler.inverse_transform(y_test).reshape(-1), yscaler.inverse_transform(yhat_test).reshape(-1), s=15, alpha=0.5, color='red', label='test', marker='+')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
