[94mWelcome. Libraries loaded.[0m
global_load called
warning: node 20alt -0_02 opt's parsing failed. probably old version.
warning: node naive ncl 111_1_1_1_1_1's parsing failed. probably old version.
warning: node fm dos's parsing failed. probably old version.
warning: node opt's parsing failed. probably old version.
warning: node naive ncl 111's parsing failed. probably old version.
warning: node reliable fm static's parsing failed. probably old version.
warning: node high prec fm opt's parsing failed. probably old version.
warning: node naive fm opt's parsing failed. probably old version.
warning: node reliable para static's parsing failed. probably old version.
warning: node naive ncl 011's parsing failed. probably old version.
warning: node high prec para opt's parsing failed. probably old version.
warning: node naive para opt's parsing failed. probably old version.
warning: node a really good static's parsing failed. probably old version.
warning: node naive ncl 111_1_1_1_1's parsing failed. probably old version.
warning: node naive ncl 001's parsing failed. probably old version.
warning: node naive ncl 111_1_1's parsing failed. probably old version.
warning: node opt ediffg -0_03 cont1's parsing failed. probably old version.
warning: node naive ncl 111_1's parsing failed. probably old version.
warning: node opt ediffg 1E-4's parsing failed. probably old version.
warning: node opt ediffg 1E-3's parsing failed. probably old version.
warning: node naive ncl bandgap's parsing failed. probably old version.
warning: node opt ediffg 1E-5's parsing failed. probably old version.
warning: node para opt's parsing failed. probably old version.
warning: node naive ncl 111_1_1_1's parsing failed. probably old version.
warning: node opt ediffg 1E-6 ediff not up to the task's parsing failed. probably old version.
----------------------------
epoch 0, loss 1.50165
epoch 100, loss 1.31265
epoch 200, loss 0.821711
epoch 300, loss 0.682237
epoch 400, loss 0.74099
epoch 500, loss 0.350284
epoch 600, loss 0.462929
epoch 700, loss 0.788736
epoch 800, loss 1.03419
epoch 900, loss 0.681837
epoch 1000, loss 0.836916
epoch 1100, loss 0.920202
epoch 1200, loss 0.689304
epoch 1300, loss 0.349109
epoch 1400, loss 0.508761
epoch 1500, loss 0.491692
epoch 1600, loss 0.36969
epoch 1700, loss 0.496957
epoch 1800, loss 0.431029
epoch 1900, loss 0.511769
epoch 2000, loss 0.721408
epoch 2100, loss 0.581444
epoch 2200, loss 0.512601
epoch 2300, loss 0.326472
epoch 2400, loss 0.471626
epoch 2500, loss 0.236578
epoch 2600, loss 1.01685
epoch 2700, loss 0.414473
epoch 2800, loss 0.354387
epoch 2900, loss 0.288401
epoch 3000, loss 0.542153
epoch 3100, loss 0.561202
epoch 3200, loss 0.331867
epoch 3300, loss 0.698893
epoch 3400, loss 0.37414
epoch 3500, loss 0.414397
epoch 3600, loss 0.53276
epoch 3700, loss 0.68567
epoch 3800, loss 0.824206
epoch 3900, loss 0.389798
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
13.9704 30.3202
109.588 48.9711
116.598 52.1583
32.9279 59.7782
48.9224 33.488
parameters: [ 9.   1.   2.   3.2  4. ]. error: 0.144305579073.
----------------------------
epoch 0, loss 1.91978
epoch 100, loss 0.617256
epoch 200, loss 1.37005
epoch 300, loss 0.622027
epoch 400, loss 0.740155
epoch 500, loss 0.540043
epoch 600, loss 0.598759
epoch 700, loss 0.523576
epoch 800, loss 0.446202
epoch 900, loss 0.884392
epoch 1000, loss 0.567665
epoch 1100, loss 0.534456
epoch 1200, loss 0.28969
epoch 1300, loss 0.446262
epoch 1400, loss 0.384556
epoch 1500, loss 0.650091
epoch 1600, loss 0.435405
epoch 1700, loss 0.60179
epoch 1800, loss 0.788663
epoch 1900, loss 0.604741
epoch 2000, loss 0.523918
epoch 2100, loss 0.54161
epoch 2200, loss 0.7476
epoch 2300, loss 0.715732
epoch 2400, loss 0.53915
epoch 2500, loss 0.882253
epoch 2600, loss 0.377286
epoch 2700, loss 0.738712
epoch 2800, loss 0.407915
epoch 2900, loss 0.450071
epoch 3000, loss 0.610725
epoch 3100, loss 0.284607
epoch 3200, loss 0.534207
epoch 3300, loss 0.517391
epoch 3400, loss 0.425312
epoch 3500, loss 0.639107
epoch 3600, loss 0.429486
epoch 3700, loss 0.599876
epoch 3800, loss 0.646433
epoch 3900, loss 0.395615
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
109.588 49.4039
116.598 49.7504
67.5897 95.5858
32.9441 21.2559
71.8482 40.2456
parameters: [ 9.   1.   2.   3.2  4. ]. error: 0.10787232667.
----------------------------
epoch 0, loss 1.7246
epoch 100, loss 0.54018
epoch 200, loss 0.541235
epoch 300, loss 0.518978
epoch 400, loss 0.842581
epoch 500, loss 0.294177
epoch 600, loss 0.39048
epoch 700, loss 0.467211
epoch 800, loss 0.319851
epoch 900, loss 0.542984
epoch 1000, loss 0.277639
epoch 1100, loss 0.410029
epoch 1200, loss 0.564649
epoch 1300, loss 0.435111
epoch 1400, loss 0.202779
epoch 1500, loss 0.580602
epoch 1600, loss 0.546603
epoch 1700, loss 0.680136
epoch 1800, loss 0.282825
epoch 1900, loss 0.306633
epoch 2000, loss 0.530277
epoch 2100, loss 0.685993
epoch 2200, loss 0.373747
epoch 2300, loss 0.603575
epoch 2400, loss 0.373116
epoch 2500, loss 0.481918
epoch 2600, loss 0.758702
epoch 2700, loss 0.557015
epoch 2800, loss 0.518746
epoch 2900, loss 0.376887
epoch 3000, loss 0.515606
epoch 3100, loss 0.41439
epoch 3200, loss 0.248854
epoch 3300, loss 0.399851
epoch 3400, loss 0.609105
epoch 3500, loss 0.621864
epoch 3600, loss 0.450171
epoch 3700, loss 0.467685
epoch 3800, loss 0.436985
epoch 3900, loss 0.577436
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
33.7234 39.8383
38.4634 239.767
37.0194 170.834
47.4619 94.1715
106.094 59.8033
parameters: [ 10.    1.    2.    3.2   4. ]. error: 1.01211018686.
----------------------------
epoch 0, loss 0.601059
epoch 100, loss 1.23348
epoch 200, loss 0.352438
epoch 300, loss 0.684559
epoch 400, loss 0.688848
epoch 500, loss 0.542971
epoch 600, loss 0.392283
epoch 700, loss 0.503837
epoch 800, loss 0.54427
epoch 900, loss 0.383334
epoch 1000, loss 0.44269
epoch 1100, loss 0.580218
epoch 1200, loss 0.453819
epoch 1300, loss 0.412623
epoch 1400, loss 0.752492
epoch 1500, loss 0.511158
epoch 1600, loss 0.502565
epoch 1700, loss 0.198861
epoch 1800, loss 0.581409
epoch 1900, loss 0.403416
epoch 2000, loss 0.619474
epoch 2100, loss 0.475241
epoch 2200, loss 0.791227
epoch 2300, loss 0.349584
epoch 2400, loss 0.497938
epoch 2500, loss 0.411509
epoch 2600, loss 0.573068
epoch 2700, loss 0.294016
epoch 2800, loss 0.360105
epoch 2900, loss 0.3369
epoch 3000, loss 0.762029
epoch 3100, loss 0.576268
epoch 3200, loss 0.553623
epoch 3300, loss 0.439882
epoch 3400, loss 0.546596
epoch 3500, loss 0.391718
epoch 3600, loss 0.40714
epoch 3700, loss 0.452378
epoch 3800, loss 0.775427
epoch 3900, loss 0.204136
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
32.9441 32.4976
79.3243 19.17
20.2755 35.1163
162.436 76.4978
47.6327 33.2669
parameters: [ 7.382  1.     2.     3.2    4.   ]. error: 0.38778259101.
----------------------------
epoch 0, loss 1.33487
epoch 100, loss 1.4673
epoch 200, loss 0.712454
epoch 300, loss 0.529525
epoch 400, loss 0.872264
epoch 500, loss 0.508844
epoch 600, loss 0.994987
epoch 700, loss 0.392249
epoch 800, loss 0.589326
epoch 900, loss 0.757994
epoch 1000, loss 0.845621
epoch 1100, loss 0.320595
epoch 1200, loss 0.549086
epoch 1300, loss 0.600641
epoch 1400, loss 0.795666
epoch 1500, loss 0.638627
epoch 1600, loss 0.47005
epoch 1700, loss 0.858676
epoch 1800, loss 0.404345
epoch 1900, loss 0.225173
epoch 2000, loss 0.542474
epoch 2100, loss 0.399141
epoch 2200, loss 0.256186
epoch 2300, loss 0.323507
epoch 2400, loss 0.221301
epoch 2500, loss 0.724994
epoch 2600, loss 0.44796
epoch 2700, loss 0.371155
epoch 2800, loss 0.474432
epoch 2900, loss 0.430244
epoch 3000, loss 0.371485
epoch 3100, loss 0.37445
epoch 3200, loss 0.357131
epoch 3300, loss 0.418816
epoch 3400, loss 0.859628
epoch 3500, loss 0.3863
epoch 3600, loss 0.341553
epoch 3700, loss 0.418802
epoch 3800, loss 0.779342
epoch 3900, loss 0.289901
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
94.9786 94.6795
28.3521 39.2944
127.381 66.3872
282.053 190.451
13.842 38.0151
parameters: [ 9.   1.   2.   3.2  4. ]. error: 0.175992659062.
----------------------------
epoch 0, loss 1.69539
epoch 100, loss 0.844302
epoch 200, loss 0.203187
epoch 300, loss 0.547777
epoch 400, loss 0.963283
epoch 500, loss 0.630585
epoch 600, loss 1.13142
epoch 700, loss 0.369875
epoch 800, loss 0.42406
epoch 900, loss 0.546968
epoch 1000, loss 0.491355
epoch 1100, loss 0.541506
epoch 1200, loss 0.358698
epoch 1300, loss 0.473344
epoch 1400, loss 0.350455
epoch 1500, loss 0.87781
epoch 1600, loss 0.448913
epoch 1700, loss 0.333272
epoch 1800, loss 0.500526
epoch 1900, loss 0.543473
epoch 2000, loss 0.249558
epoch 2100, loss 0.435813
epoch 2200, loss 0.596716
epoch 2300, loss 0.39241
epoch 2400, loss 0.651974
epoch 2500, loss 0.54408
epoch 2600, loss 0.571248
epoch 2700, loss 0.381574
epoch 2800, loss 0.650251
epoch 2900, loss 0.578418
epoch 3000, loss 0.466639
epoch 3100, loss 0.535443
epoch 3200, loss 0.524851
epoch 3300, loss 0.615599
epoch 3400, loss 0.623059
epoch 3500, loss 0.466567
epoch 3600, loss 0.443491
epoch 3700, loss 0.508376
epoch 3800, loss 0.225214
epoch 3900, loss 0.240296
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
22.953 29.4424
23.1269 43.0877
40.0937 37.0671
127.381 91.797
162.436 65.9002
parameters: [ 8.382  1.     2.     3.2    4.   ]. error: 0.142766474762.
----------------------------
epoch 0, loss 1.28495
epoch 100, loss 1.23029
epoch 200, loss 0.597201
epoch 300, loss 1.09897
epoch 400, loss 0.507468
epoch 500, loss 0.67185
epoch 600, loss 0.979739
epoch 700, loss 0.369049
epoch 800, loss 0.777853
epoch 900, loss 0.502055
epoch 1000, loss 0.441488
epoch 1100, loss 0.37522
epoch 1200, loss 0.72204
epoch 1300, loss 0.44809
epoch 1400, loss 0.35753
epoch 1500, loss 0.36192
epoch 1600, loss 0.457461
epoch 1700, loss 0.684996
epoch 1800, loss 0.59742
epoch 1900, loss 0.625969
epoch 2000, loss 0.409656
epoch 2100, loss 0.532724
epoch 2200, loss 0.201619
epoch 2300, loss 0.375596
epoch 2400, loss 0.615501
epoch 2500, loss 0.751973
epoch 2600, loss 0.655723
epoch 2700, loss 0.564325
epoch 2800, loss 0.487511
epoch 2900, loss 0.540054
epoch 3000, loss 0.490355
epoch 3100, loss 0.621332
epoch 3200, loss 0.380212
epoch 3300, loss 0.565818
epoch 3400, loss 0.355938
epoch 3500, loss 0.539197
epoch 3600, loss 0.603096
epoch 3700, loss 0.318649
epoch 3800, loss 0.328535
epoch 3900, loss 0.615781
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
21.6939 30.6109
28.3521 37.4092
20.2755 30.1576
37.0194 81.7431
36.7438 85.0321
parameters: [ 8.   1.   2.   3.2  4. ]. error: 0.0864706416988.
----------------------------
epoch 0, loss 1.11027
epoch 100, loss 1.17473
epoch 200, loss 0.523016
epoch 300, loss 0.752623
epoch 400, loss 0.790431
epoch 500, loss 0.413612
epoch 600, loss 0.975393
epoch 700, loss 0.444627
epoch 800, loss 0.384997
epoch 900, loss 0.974929
epoch 1000, loss 0.879126
epoch 1100, loss 0.460426
epoch 1200, loss 0.534659
epoch 1300, loss 0.862555
epoch 1400, loss 0.551955
epoch 1500, loss 0.551533
epoch 1600, loss 0.858265
epoch 1700, loss 0.41852
epoch 1800, loss 0.477981
epoch 1900, loss 0.555293
epoch 2000, loss 0.421456
epoch 2100, loss 0.791785
epoch 2200, loss 0.33807
epoch 2300, loss 1.04906
epoch 2400, loss 0.438901
epoch 2500, loss 0.529315
epoch 2600, loss 0.390892
epoch 2700, loss 0.708158
epoch 2800, loss 0.817827
epoch 2900, loss 0.354828
epoch 3000, loss 0.564503
epoch 3100, loss 0.48997
epoch 3200, loss 0.382416
epoch 3300, loss 0.597565
epoch 3400, loss 0.683643
epoch 3500, loss 0.67056
epoch 3600, loss 0.405585
epoch 3700, loss 0.503345
epoch 3800, loss 0.354316
epoch 3900, loss 0.558168
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
33.8136 41.5878
106.094 55.0563
101.017 202.616
116.598 70.9447
38.6549 20.6916
parameters: [ 7.764  1.     2.     3.2    4.   ]. error: 0.108524857038.
----------------------------
epoch 0, loss 2.1083
epoch 100, loss 1.08645
epoch 200, loss 0.965046
epoch 300, loss 0.838214
epoch 400, loss 0.48353
epoch 500, loss 0.602621
epoch 600, loss 0.491805
epoch 700, loss 0.481018
epoch 800, loss 0.352347
epoch 900, loss 0.834966
epoch 1000, loss 0.381293
epoch 1100, loss 0.84637
epoch 1200, loss 0.492519
epoch 1300, loss 0.641833
epoch 1400, loss 0.507945
epoch 1500, loss 0.609792
epoch 1600, loss 0.494727
epoch 1700, loss 0.535151
epoch 1800, loss 0.446631
epoch 1900, loss 0.449911
epoch 2000, loss 0.298306
epoch 2100, loss 0.663136
epoch 2200, loss 0.576816
epoch 2300, loss 0.583079
epoch 2400, loss 0.395046
epoch 2500, loss 0.470129
epoch 2600, loss 0.500591
epoch 2700, loss 0.600249
epoch 2800, loss 0.357512
epoch 2900, loss 0.401177
epoch 3000, loss 0.381114
epoch 3100, loss 0.492664
epoch 3200, loss 0.388246
epoch 3300, loss 0.680565
epoch 3400, loss 0.403372
epoch 3500, loss 0.51124
epoch 3600, loss 0.668705
epoch 3700, loss 0.380231
epoch 3800, loss 0.456385
epoch 3900, loss 0.693471
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
112.36 119.736
13.2248 26.7052
70.2845 119.736
40.0937 45.0442
94.9786 86.7884
parameters: [ 8.01  1.    2.    3.2   4.  ]. error: 0.0704733606433.
----------------------------
epoch 0, loss 1.5635
epoch 100, loss 1.18285
epoch 200, loss 0.704383
epoch 300, loss 0.506758
epoch 400, loss 0.944479
epoch 500, loss 0.447714
epoch 600, loss 0.4378
epoch 700, loss 0.687179
epoch 800, loss 0.573377
epoch 900, loss 0.332488
epoch 1000, loss 0.403048
epoch 1100, loss 0.572579
epoch 1200, loss 0.65765
epoch 1300, loss 0.375711
epoch 1400, loss 0.792331
epoch 1500, loss 0.535921
epoch 1600, loss 0.412123
epoch 1700, loss 0.967932
epoch 1800, loss 0.409354
epoch 1900, loss 0.317546
epoch 2000, loss 0.600388
epoch 2100, loss 0.308346
epoch 2200, loss 0.490259
epoch 2300, loss 0.439085
epoch 2400, loss 0.515361
epoch 2500, loss 0.534734
epoch 2600, loss 0.47577
epoch 2700, loss 0.694425
epoch 2800, loss 0.394937
epoch 2900, loss 0.424013
epoch 3000, loss 0.495516
epoch 3100, loss 0.888076
epoch 3200, loss 0.300398
epoch 3300, loss 0.505479
epoch 3400, loss 0.718404
epoch 3500, loss 0.380514
epoch 3600, loss 0.351127
epoch 3700, loss 0.47254
epoch 3800, loss 0.489765
epoch 3900, loss 0.430557
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
70.3904 140.258
282.053 231.536
33.8136 40.5675
32.9279 101.05
14.1268 16.6026
parameters: [ 8.152  1.     2.     3.2    4.   ]. error: 0.181357076079.
----------------------------
epoch 0, loss 1.23346
epoch 100, loss 1.19586
epoch 200, loss 1.3541
epoch 300, loss 0.58938
epoch 400, loss 0.482398
epoch 500, loss 0.478765
epoch 600, loss 0.758616
epoch 700, loss 0.931465
epoch 800, loss 0.473049
epoch 900, loss 0.526252
epoch 1000, loss 0.830798
epoch 1100, loss 0.576218
epoch 1200, loss 0.60039
epoch 1300, loss 0.66029
epoch 1400, loss 0.520794
epoch 1500, loss 0.338139
epoch 1600, loss 0.582874
epoch 1700, loss 0.630208
epoch 1800, loss 0.485491
epoch 1900, loss 0.795995
epoch 2000, loss 0.427213
epoch 2100, loss 0.758033
epoch 2200, loss 0.642103
epoch 2300, loss 0.849605
epoch 2400, loss 0.639003
epoch 2500, loss 0.673743
epoch 2600, loss 0.475261
epoch 2700, loss 0.864038
epoch 2800, loss 0.54145
epoch 2900, loss 0.731901
epoch 3000, loss 0.420208
epoch 3100, loss 0.427202
epoch 3200, loss 0.362819
epoch 3300, loss 0.614346
epoch 3400, loss 0.641354
epoch 3500, loss 0.424258
epoch 3600, loss 0.396618
epoch 3700, loss 0.410966
epoch 3800, loss 0.490396
epoch 3900, loss 0.480854
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
23.1269 23.6748
33.7234 28.0133
101.017 225.568
116.598 62.9123
94.9786 76.9489
parameters: [ 8.064  1.     2.     3.2    4.   ]. error: 0.121270797628.
----------------------------
epoch 0, loss 1.76695
epoch 100, loss 0.575855
epoch 200, loss 0.399595
epoch 300, loss 0.303859
epoch 400, loss 0.822207
epoch 500, loss 0.533436
epoch 600, loss 0.289793
epoch 700, loss 0.578542
epoch 800, loss 0.696093
epoch 900, loss 0.365361
epoch 1000, loss 0.28156
epoch 1100, loss 0.525856
epoch 1200, loss 0.545993
epoch 1300, loss 0.74
epoch 1400, loss 0.953921
epoch 1500, loss 0.486513
epoch 1600, loss 0.517644
epoch 1700, loss 0.387806
epoch 1800, loss 0.746544
epoch 1900, loss 0.582191
epoch 2000, loss 0.393365
epoch 2100, loss 0.27152
epoch 2200, loss 0.780625
epoch 2300, loss 0.443768
epoch 2400, loss 0.338356
epoch 2500, loss 0.619693
epoch 2600, loss 0.442862
epoch 2700, loss 0.423922
epoch 2800, loss 0.470149
epoch 2900, loss 0.454227
epoch 3000, loss 0.392874
epoch 3100, loss 0.683145
epoch 3200, loss 0.514971
epoch 3300, loss 0.38755
epoch 3400, loss 0.541442
epoch 3500, loss 0.649648
epoch 3600, loss 0.499624
epoch 3700, loss 0.590899
epoch 3800, loss 0.380825
epoch 3900, loss 0.303761
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
13.842 31.6359
19.4471 35.5153
28.3521 46.0503
71.8482 45.1957
244.06 230.128
parameters: [ 8.031  1.     2.     3.2    4.   ]. error: 0.110832140388.
----------------------------
epoch 0, loss 1.22003
epoch 100, loss 0.618376
epoch 200, loss 0.724097
epoch 300, loss 0.518075
epoch 400, loss 0.632953
epoch 500, loss 0.800374
epoch 600, loss 0.789883
epoch 700, loss 0.302536
epoch 800, loss 0.761807
epoch 900, loss 0.308064
epoch 1000, loss 0.368201
epoch 1100, loss 0.818877
epoch 1200, loss 0.821055
epoch 1300, loss 0.56713
epoch 1400, loss 0.31596
epoch 1500, loss 0.517208
epoch 1600, loss 0.680231
epoch 1700, loss 0.513755
epoch 1800, loss 0.682989
epoch 1900, loss 0.829861
epoch 2000, loss 0.422116
epoch 2100, loss 0.5319
epoch 2200, loss 0.673802
epoch 2300, loss 0.379639
epoch 2400, loss 0.353327
epoch 2500, loss 0.701688
epoch 2600, loss 0.565794
epoch 2700, loss 0.708637
epoch 2800, loss 0.579722
epoch 2900, loss 0.552003
epoch 3000, loss 0.677288
epoch 3100, loss 0.217715
epoch 3200, loss 0.443256
epoch 3300, loss 0.342576
epoch 3400, loss 0.828204
epoch 3500, loss 0.510891
epoch 3600, loss 0.625358
epoch 3700, loss 0.252213
epoch 3800, loss 0.34789
epoch 3900, loss 0.269151
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
21.6939 31.4425
23.1269 27.0895
32.9279 82.3622
89.2785 35.7889
36.7438 77.4208
parameters: [ 8.02  1.    2.    3.2   4.  ]. error: 0.197236141378.
----------------------------
epoch 0, loss 1.7887
epoch 100, loss 1.12128
epoch 200, loss 0.371332
epoch 300, loss 0.627183
epoch 400, loss 0.559171
epoch 500, loss 0.849416
epoch 600, loss 0.442527
epoch 700, loss 0.822005
epoch 800, loss 0.332569
epoch 900, loss 0.475935
epoch 1000, loss 0.419263
epoch 1100, loss 0.460079
epoch 1200, loss 0.846272
epoch 1300, loss 0.544748
epoch 1400, loss 0.344973
epoch 1500, loss 0.534922
epoch 1600, loss 0.507912
epoch 1700, loss 0.417921
epoch 1800, loss 0.639746
epoch 1900, loss 0.321153
epoch 2000, loss 0.718154
epoch 2100, loss 0.410846
epoch 2200, loss 0.304039
epoch 2300, loss 0.869619
epoch 2400, loss 0.413041
epoch 2500, loss 0.631477
epoch 2600, loss 0.453197
epoch 2700, loss 0.401355
epoch 2800, loss 0.491733
epoch 2900, loss 0.606625
epoch 3000, loss 0.60151
epoch 3100, loss 0.31987
epoch 3200, loss 0.498398
epoch 3300, loss 0.378477
epoch 3400, loss 0.469255
epoch 3500, loss 0.535804
epoch 3600, loss 0.502882
epoch 3700, loss 0.489037
epoch 3800, loss 0.436834
epoch 3900, loss 0.522723
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
246.534 118.432
25.6565 71.4153
45.3756 84.2218
43.9272 6.76267
13.7745 15.5996
parameters: [ 8.01  1.    2.    3.2   4.  ]. error: 1.20458540754.
----------------------------
epoch 0, loss 1.63397
epoch 100, loss 0.988319
epoch 200, loss 1.38283
epoch 300, loss 0.626813
epoch 400, loss 0.445235
epoch 500, loss 0.67521
epoch 600, loss 0.688582
epoch 700, loss 0.769487
epoch 800, loss 0.51371
epoch 900, loss 0.459913
epoch 1000, loss 0.772328
epoch 1100, loss 0.708655
epoch 1200, loss 0.884701
epoch 1300, loss 0.624849
epoch 1400, loss 0.383912
epoch 1500, loss 0.944572
epoch 1600, loss 0.391072
epoch 1700, loss 0.697816
epoch 1800, loss 0.947596
epoch 1900, loss 0.452762
epoch 2000, loss 0.917368
epoch 2100, loss 0.367707
epoch 2200, loss 0.478741
epoch 2300, loss 0.537539
epoch 2400, loss 0.514389
epoch 2500, loss 0.285986
epoch 2600, loss 0.957479
epoch 2700, loss 0.599094
epoch 2800, loss 0.574562
epoch 2900, loss 0.324666
epoch 3000, loss 0.704289
epoch 3100, loss 0.66523
epoch 3200, loss 0.41925
epoch 3300, loss 0.498507
epoch 3400, loss 0.575513
epoch 3500, loss 0.822947
epoch 3600, loss 0.622733
epoch 3700, loss 0.611056
epoch 3800, loss 1.11724
epoch 3900, loss 0.641415
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
70.3904 108.164
71.133 28.4688
28.7444 57.755
13.7745 24.5762
70.2845 108.164
parameters: [ 8.01  2.    2.    3.2   4.  ]. error: 0.155911621857.
----------------------------
epoch 0, loss 1.19986
epoch 100, loss 1.14523
epoch 200, loss 0.999465
epoch 300, loss 0.775991
epoch 400, loss 0.862304
epoch 500, loss 0.796062
epoch 600, loss 1.18521
epoch 700, loss 0.488546
epoch 800, loss 1.31627
epoch 900, loss 1.05569
epoch 1000, loss 0.845528
epoch 1100, loss 0.507535
epoch 1200, loss 0.966135
epoch 1300, loss 1.00357
epoch 1400, loss 0.791289
epoch 1500, loss 0.521463
epoch 1600, loss 0.951496
epoch 1700, loss 0.648995
epoch 1800, loss 0.973729
epoch 1900, loss 0.789635
epoch 2000, loss 0.969458
epoch 2100, loss 0.415771
epoch 2200, loss 0.893125
epoch 2300, loss 0.641976
epoch 2400, loss 0.766492
epoch 2500, loss 0.961365
epoch 2600, loss 0.642829
epoch 2700, loss 0.643537
epoch 2800, loss 0.557651
epoch 2900, loss 1.03861
epoch 3000, loss 0.424511
epoch 3100, loss 0.560088
epoch 3200, loss 0.469771
epoch 3300, loss 0.706121
epoch 3400, loss 0.606936
epoch 3500, loss 0.925065
epoch 3600, loss 0.699394
epoch 3700, loss 0.740285
epoch 3800, loss 0.594255
epoch 3900, loss 0.407792
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
53.6961 34.1533
127.381 66.9077
460.913 64.0088
53.6961 34.1533
53.6961 34.1533
parameters: [ 8.01   3.618  2.     3.2    4.   ]. error: 1.39461149201.
----------------------------
epoch 0, loss 1.19806
epoch 100, loss 0.861872
epoch 200, loss 0.733645
epoch 300, loss 0.681377
epoch 400, loss 0.478857
epoch 500, loss 0.610634
epoch 600, loss 1.33347
epoch 700, loss 0.953665
epoch 800, loss 0.891853
epoch 900, loss 0.862355
epoch 1000, loss 0.745884
epoch 1100, loss 0.704155
epoch 1200, loss 0.766572
epoch 1300, loss 0.238838
epoch 1400, loss 0.560898
epoch 1500, loss 0.54217
epoch 1600, loss 0.550536
epoch 1700, loss 0.908602
epoch 1800, loss 0.591225
epoch 1900, loss 0.532908
epoch 2000, loss 0.761262
epoch 2100, loss 0.662736
epoch 2200, loss 0.696418
epoch 2300, loss 0.478672
epoch 2400, loss 0.79363
epoch 2500, loss 0.619418
epoch 2600, loss 0.851054
epoch 2700, loss 0.264022
epoch 2800, loss 0.89454
epoch 2900, loss 0.492188
epoch 3000, loss 0.427777
epoch 3100, loss 0.372919
epoch 3200, loss 0.449814
epoch 3300, loss 0.723689
epoch 3400, loss 0.297752
epoch 3500, loss 0.525464
epoch 3600, loss 0.704641
epoch 3700, loss 0.411783
epoch 3800, loss 0.525613
epoch 3900, loss 0.358642
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
47.4619 77.2426
244.06 134.574
43.9272 4.64476
96.1397 104.02
831.403 209.567
parameters: [ 8.01  2.    2.    3.2   4.  ]. error: 2.78437486962.
----------------------------
epoch 0, loss 1.31501
epoch 100, loss 0.663618
epoch 200, loss 1.07561
epoch 300, loss 0.871173
epoch 400, loss 1.20835
epoch 500, loss 0.665467
epoch 600, loss 0.737827
epoch 700, loss 0.649374
epoch 800, loss 0.936044
epoch 900, loss 0.803727
epoch 1000, loss 1.01275
epoch 1100, loss 0.664109
epoch 1200, loss 0.479062
epoch 1300, loss 0.674045
epoch 1400, loss 1.10014
epoch 1500, loss 0.491048
epoch 1600, loss 0.633254
epoch 1700, loss 0.367395
epoch 1800, loss 1.0609
epoch 1900, loss 0.679893
epoch 2000, loss 0.345488
epoch 2100, loss 0.416091
epoch 2200, loss 0.683164
epoch 2300, loss 0.816938
epoch 2400, loss 0.319189
epoch 2500, loss 0.548199
epoch 2600, loss 1.0231
epoch 2700, loss 0.634571
epoch 2800, loss 0.678395
epoch 2900, loss 0.71321
epoch 3000, loss 0.714525
epoch 3100, loss 0.433412
epoch 3200, loss 0.781107
epoch 3300, loss 0.722826
epoch 3400, loss 1.23445
epoch 3500, loss 0.484542
epoch 3600, loss 0.678424
epoch 3700, loss 0.339108
epoch 3800, loss 0.623662
epoch 3900, loss 0.974186
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
234.37 75.3417
13.7745 31.6966
31.6796 41.5149
96.1397 118.587
2.37471 30.7377
parameters: [ 8.01   2.618  2.     3.2    4.   ]. error: 6.19841035465.
----------------------------
epoch 0, loss 1.34517
epoch 100, loss 0.504174
epoch 200, loss 1.02396
epoch 300, loss 1.14878
epoch 400, loss 1.53247
epoch 500, loss 0.968088
epoch 600, loss 0.317843
epoch 700, loss 0.930094
epoch 800, loss 0.527383
epoch 900, loss 0.653315
epoch 1000, loss 0.809823
epoch 1100, loss 0.689521
epoch 1200, loss 0.818774
epoch 1300, loss 0.986674
epoch 1400, loss 0.441243
epoch 1500, loss 0.872871
epoch 1600, loss 0.75074
epoch 1700, loss 0.353699
epoch 1800, loss 0.535342
epoch 1900, loss 0.924845
epoch 2000, loss 0.471078
epoch 2100, loss 0.592403
epoch 2200, loss 0.554973
epoch 2300, loss 0.596286
epoch 2400, loss 0.494048
epoch 2500, loss 0.506032
epoch 2600, loss 0.740018
epoch 2700, loss 0.693056
epoch 2800, loss 0.534954
epoch 2900, loss 0.427127
epoch 3000, loss 0.695789
epoch 3100, loss 0.402706
epoch 3200, loss 0.696415
epoch 3300, loss 0.441422
epoch 3400, loss 0.60436
epoch 3500, loss 0.924057
epoch 3600, loss 0.49693
epoch 3700, loss 0.59176
epoch 3800, loss 0.801361
epoch 3900, loss 0.614057
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
28.7444 60.8611
10.5701 21.5494
9.3969 23.4483
116.598 79.4419
22.953 24.3616
parameters: [ 8.01   1.618  2.     3.2    4.   ]. error: 0.124457832942.
----------------------------
epoch 0, loss 1.40404
epoch 100, loss 1.23118
epoch 200, loss 0.763263
epoch 300, loss 0.959738
epoch 400, loss 0.661619
epoch 500, loss 0.438074
epoch 600, loss 0.509791
epoch 700, loss 0.817483
epoch 800, loss 0.512528
epoch 900, loss 0.380242
epoch 1000, loss 0.907927
epoch 1100, loss 0.778895
epoch 1200, loss 0.56096
epoch 1300, loss 0.696605
epoch 1400, loss 0.297461
epoch 1500, loss 0.450261
epoch 1600, loss 0.829543
epoch 1700, loss 0.396074
epoch 1800, loss 0.757983
epoch 1900, loss 0.503378
epoch 2000, loss 0.539948
epoch 2100, loss 0.450936
epoch 2200, loss 0.513195
epoch 2300, loss 0.528937
epoch 2400, loss 1.10998
epoch 2500, loss 0.311587
epoch 2600, loss 0.297924
epoch 2700, loss 0.792066
epoch 2800, loss 0.662197
epoch 2900, loss 1.15501
epoch 3000, loss 1.02265
epoch 3100, loss 0.507085
epoch 3200, loss 0.524871
epoch 3300, loss 0.6135
epoch 3400, loss 0.37731
epoch 3500, loss 0.187211
epoch 3600, loss 0.350245
epoch 3700, loss 0.775764
epoch 3800, loss 0.476253
epoch 3900, loss 0.488547
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
33.8136 52.9748
3167.53 794.366
32.9441 23.3704
146.624 119.275
25.6565 114.221
parameters: [ 8.01   1.382  2.     3.2    4.   ]. error: 0.735698312131.
----------------------------
epoch 0, loss 1.1696
epoch 100, loss 0.910663
epoch 200, loss 0.61101
epoch 300, loss 1.21627
epoch 400, loss 1.73042
epoch 500, loss 0.453923
epoch 600, loss 1.24046
epoch 700, loss 1.06654
epoch 800, loss 0.658496
epoch 900, loss 0.457069
epoch 1000, loss 0.679211
epoch 1100, loss 0.746667
epoch 1200, loss 0.956738
epoch 1300, loss 0.557164
epoch 1400, loss 0.420818
epoch 1500, loss 0.599541
epoch 1600, loss 0.86518
epoch 1700, loss 0.809146
epoch 1800, loss 1.4804
epoch 1900, loss 0.821484
epoch 2000, loss 0.594006
epoch 2100, loss 0.467547
epoch 2200, loss 0.55382
epoch 2300, loss 0.529156
epoch 2400, loss 0.549754
epoch 2500, loss 0.571833
epoch 2600, loss 0.576296
epoch 2700, loss 0.496674
epoch 2800, loss 0.305879
epoch 2900, loss 0.650815
epoch 3000, loss 0.317722
epoch 3100, loss 0.672159
epoch 3200, loss 0.317156
epoch 3300, loss 0.367186
epoch 3400, loss 0.855742
epoch 3500, loss 0.66731
epoch 3600, loss 0.518897
epoch 3700, loss 0.613948
epoch 3800, loss 0.697791
epoch 3900, loss 0.260232
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
57.0616 54.2803
20.2734 36.244
71.8482 48.5102
13.2248 18.5184
10.5701 14.39
parameters: [ 8.01   1.584  2.     3.2    4.   ]. error: 0.0694304995338.
----------------------------
epoch 0, loss 1.29323
epoch 100, loss 0.905313
epoch 200, loss 1.03354
epoch 300, loss 0.567246
epoch 400, loss 0.727127
epoch 500, loss 0.886387
epoch 600, loss 0.748712
epoch 700, loss 0.666993
epoch 800, loss 0.589542
epoch 900, loss 0.333546
epoch 1000, loss 0.440617
epoch 1100, loss 0.406147
epoch 1200, loss 0.637742
epoch 1300, loss 0.851804
epoch 1400, loss 0.725034
epoch 1500, loss 0.540084
epoch 1600, loss 0.879085
epoch 1700, loss 0.603249
epoch 1800, loss 0.521113
epoch 1900, loss 0.569196
epoch 2000, loss 0.744979
epoch 2100, loss 0.480263
epoch 2200, loss 0.622803
epoch 2300, loss 0.838168
epoch 2400, loss 0.704126
epoch 2500, loss 0.508019
epoch 2600, loss 0.415064
epoch 2700, loss 0.301014
epoch 2800, loss 0.374979
epoch 2900, loss 1.00815
epoch 3000, loss 0.520112
epoch 3100, loss 0.637795
epoch 3200, loss 0.616875
epoch 3300, loss 0.396763
epoch 3400, loss 0.489779
epoch 3500, loss 0.526686
epoch 3600, loss 0.222569
epoch 3700, loss 0.569391
epoch 3800, loss 0.599706
epoch 3900, loss 0.582087
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
3.22686 22.1241
31.6796 29.8909
37.0194 49.9808
234.37 37.7598
6.15658 21.9664
parameters: [ 8.01   1.562  2.     3.2    4.   ]. error: 2.19068527321.
----------------------------
epoch 0, loss 1.24603
epoch 100, loss 0.929266
epoch 200, loss 0.476103
epoch 300, loss 0.628327
epoch 400, loss 0.663343
epoch 500, loss 0.624321
epoch 600, loss 1.0315
epoch 700, loss 0.552491
epoch 800, loss 0.518511
epoch 900, loss 0.501127
epoch 1000, loss 0.325931
epoch 1100, loss 0.532721
epoch 1200, loss 0.777649
epoch 1300, loss 0.50135
epoch 1400, loss 0.505251
epoch 1500, loss 0.479995
epoch 1600, loss 0.768724
epoch 1700, loss 0.551209
epoch 1800, loss 0.31326
epoch 1900, loss 0.520569
epoch 2000, loss 0.483146
epoch 2100, loss 0.319373
epoch 2200, loss 0.478009
epoch 2300, loss 0.399002
epoch 2400, loss 0.380232
epoch 2500, loss 0.509798
epoch 2600, loss 0.526129
epoch 2700, loss 0.549417
epoch 2800, loss 0.493842
epoch 2900, loss 0.600689
epoch 3000, loss 0.680976
epoch 3100, loss 0.550242
epoch 3200, loss 0.636384
epoch 3300, loss 0.731894
epoch 3400, loss 0.516737
epoch 3500, loss 0.816749
epoch 3600, loss 0.644442
epoch 3700, loss 0.607441
epoch 3800, loss 0.516713
epoch 3900, loss 0.589561
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
28.7444 58.7659
194.962 111.46
246.534 57.1115
13.2248 16.3292
47.6327 28.1522
parameters: [ 8.01   1.597  2.     3.2    4.   ]. error: 0.446917066838.
----------------------------
epoch 0, loss 1.00485
epoch 100, loss 0.74591
epoch 200, loss 0.77132
epoch 300, loss 0.383907
epoch 400, loss 0.289052
epoch 500, loss 0.993405
epoch 600, loss 0.328672
epoch 700, loss 0.508321
epoch 800, loss 0.579763
epoch 900, loss 0.422217
epoch 1000, loss 0.32743
epoch 1100, loss 0.521747
epoch 1200, loss 0.705793
epoch 1300, loss 0.515821
epoch 1400, loss 0.386722
epoch 1500, loss 0.593336
epoch 1600, loss 0.319602
epoch 1700, loss 0.622655
epoch 1800, loss 0.222824
epoch 1900, loss 0.539045
epoch 2000, loss 0.307434
epoch 2100, loss 0.618159
epoch 2200, loss 0.368172
epoch 2300, loss 0.587387
epoch 2400, loss 0.270039
epoch 2500, loss 0.801323
epoch 2600, loss 0.379372
epoch 2700, loss 0.337051
epoch 2800, loss 0.308247
epoch 2900, loss 0.474767
epoch 3000, loss 0.237404
epoch 3100, loss 0.392134
epoch 3200, loss 0.379384
epoch 3300, loss 0.739937
epoch 3400, loss 0.435403
epoch 3500, loss 0.451141
epoch 3600, loss 0.340882
epoch 3700, loss 0.29162
epoch 3800, loss 0.726194
epoch 3900, loss 0.274035
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
47.4619 86.5497
259.052 83.9315
1.11386 24.0265
38.6549 25.0097
79.3243 28.8571
parameters: [ 8.01   1.576  2.     3.2    4.   ]. error: 21.7770201155.
----------------------------
epoch 0, loss 1.94563
epoch 100, loss 1.24277
epoch 200, loss 0.407355
epoch 300, loss 0.37863
epoch 400, loss 0.706257
epoch 500, loss 0.455178
epoch 600, loss 0.425032
epoch 700, loss 0.356364
epoch 800, loss 0.808356
epoch 900, loss 0.311361
epoch 1000, loss 0.531515
epoch 1100, loss 0.666925
epoch 1200, loss 0.44083
epoch 1300, loss 0.450732
epoch 1400, loss 0.704849
epoch 1500, loss 0.54446
epoch 1600, loss 0.787541
epoch 1700, loss 0.278601
epoch 1800, loss 0.409386
epoch 1900, loss 0.622978
epoch 2000, loss 0.376662
epoch 2100, loss 0.525144
epoch 2200, loss 0.471694
epoch 2300, loss 0.470908
epoch 2400, loss 0.534349
epoch 2500, loss 0.870781
epoch 2600, loss 0.607322
epoch 2700, loss 0.301312
epoch 2800, loss 0.526916
epoch 2900, loss 0.463498
epoch 3000, loss 0.775536
epoch 3100, loss 0.427813
epoch 3200, loss 0.531667
epoch 3300, loss 0.310789
epoch 3400, loss 0.400112
epoch 3500, loss 0.437787
epoch 3600, loss 0.686589
epoch 3700, loss 0.462711
epoch 3800, loss 0.44142
epoch 3900, loss 0.450699
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
48.9224 38.8801
209.705 94.2161
1321.38 2014.45
79.3243 20.9102
89.7385 428.828
parameters: [ 8.01  1.59  2.    3.2   4.  ]. error: 0.779483709619.
----------------------------
epoch 0, loss 1.34066
epoch 100, loss 1.94425
epoch 200, loss 0.880784
epoch 300, loss 0.467174
epoch 400, loss 0.620448
epoch 500, loss 0.566836
epoch 600, loss 0.827709
epoch 700, loss 0.873186
epoch 800, loss 0.908754
epoch 900, loss 0.79397
epoch 1000, loss 0.396681
epoch 1100, loss 0.844382
epoch 1200, loss 0.859983
epoch 1300, loss 0.586502
epoch 1400, loss 0.623862
epoch 1500, loss 0.967246
epoch 1600, loss 0.532275
epoch 1700, loss 0.957919
epoch 1800, loss 0.3519
epoch 1900, loss 1.02388
epoch 2000, loss 0.655498
epoch 2100, loss 0.515146
epoch 2200, loss 0.561445
epoch 2300, loss 0.711762
epoch 2400, loss 0.451076
epoch 2500, loss 0.583147
epoch 2600, loss 0.562024
epoch 2700, loss 0.904353
epoch 2800, loss 0.434519
epoch 2900, loss 0.749196
epoch 3000, loss 0.534827
epoch 3100, loss 0.597124
epoch 3200, loss 0.781489
epoch 3300, loss 0.643667
epoch 3400, loss 0.742286
epoch 3500, loss 0.523295
epoch 3600, loss 0.595647
epoch 3700, loss 0.571906
epoch 3800, loss 0.308118
epoch 3900, loss 0.657631
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
605.821 183.826
126.871 177.236
23.1269 38.0117
14.1268 28.7451
282.053 167.703
parameters: [ 8.01   1.584  2.     3.2    4.   ]. error: 0.256231584824.
----------------------------
epoch 0, loss 1.74714
epoch 100, loss 1.23134
epoch 200, loss 1.57825
epoch 300, loss 1.24492
epoch 400, loss 1.12345
epoch 500, loss 0.400053
epoch 600, loss 0.995524
epoch 700, loss 0.614162
epoch 800, loss 0.575403
epoch 900, loss 0.459285
epoch 1000, loss 0.34644
epoch 1100, loss 1.23236
epoch 1200, loss 0.518289
epoch 1300, loss 0.398995
epoch 1400, loss 1.14706
epoch 1500, loss 0.739095
epoch 1600, loss 0.731877
epoch 1700, loss 1.16708
epoch 1800, loss 0.930076
epoch 1900, loss 1.00388
epoch 2000, loss 0.590299
epoch 2100, loss 0.907051
epoch 2200, loss 0.403836
epoch 2300, loss 0.620017
epoch 2400, loss 0.940567
epoch 2500, loss 0.861711
epoch 2600, loss 0.532128
epoch 2700, loss 1.01463
epoch 2800, loss 0.728721
epoch 2900, loss 0.702431
epoch 3000, loss 0.504262
epoch 3100, loss 1.0038
epoch 3200, loss 0.357539
epoch 3300, loss 0.914103
epoch 3400, loss 0.56027
epoch 3500, loss 0.871485
epoch 3600, loss 0.767311
epoch 3700, loss 0.541315
epoch 3800, loss 0.555947
epoch 3900, loss 0.654609
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
101.017 181.894
460.913 63.8456
32.0605 110.139
244.06 187.915
70.2845 97.7506
parameters: [ 8.01   1.584  3.     3.2    4.   ]. error: 1.61903370371.
----------------------------
epoch 0, loss 0.861616
epoch 100, loss 0.788385
epoch 200, loss 0.431416
epoch 300, loss 0.668322
epoch 400, loss 0.875181
epoch 500, loss 0.516686
epoch 600, loss 0.498056
epoch 700, loss 0.34229
epoch 800, loss 0.598923
epoch 900, loss 0.217771
epoch 1000, loss 0.324867
epoch 1100, loss 0.479694
epoch 1200, loss 0.352496
epoch 1300, loss 0.321163
epoch 1400, loss 0.639845
epoch 1500, loss 0.636085
epoch 1600, loss 0.315847
epoch 1700, loss 0.55336
epoch 1800, loss 0.587429
epoch 1900, loss 0.685126
epoch 2000, loss 0.542894
epoch 2100, loss 0.586433
epoch 2200, loss 0.439786
epoch 2300, loss 0.282021
epoch 2400, loss 0.408003
epoch 2500, loss 1.06889
epoch 2600, loss 0.36155
epoch 2700, loss 0.273071
epoch 2800, loss 0.756206
epoch 2900, loss 0.756594
epoch 3000, loss 0.505928
epoch 3100, loss 0.67275
epoch 3200, loss 0.193068
epoch 3300, loss 0.584097
epoch 3400, loss 0.792841
epoch 3500, loss 0.384793
epoch 3600, loss 0.454782
epoch 3700, loss 0.289338
epoch 3800, loss 0.698284
epoch 3900, loss 0.495469
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
209.705 125.088
70.2845 102.992
3167.53 367.75
57.0616 82.9905
13.842 31.5871
parameters: [ 8.01   1.584  0.382  3.2    4.   ]. error: 2.25597880201.
----------------------------
epoch 0, loss 1.35416
epoch 100, loss 1.2833
epoch 200, loss 0.55453
epoch 300, loss 0.876494
epoch 400, loss 0.661433
epoch 500, loss 0.769527
epoch 600, loss 0.805248
epoch 700, loss 0.436196
epoch 800, loss 0.269631
epoch 900, loss 0.557989
epoch 1000, loss 0.631536
epoch 1100, loss 0.663277
epoch 1200, loss 0.9067
epoch 1300, loss 0.60456
epoch 1400, loss 0.491767
epoch 1500, loss 0.359871
epoch 1600, loss 0.231245
epoch 1700, loss 0.346858
epoch 1800, loss 0.497283
epoch 1900, loss 0.488207
epoch 2000, loss 0.297389
epoch 2100, loss 0.586627
epoch 2200, loss 0.323902
epoch 2300, loss 0.484506
epoch 2400, loss 0.465154
epoch 2500, loss 0.515536
epoch 2600, loss 0.801566
epoch 2700, loss 0.341434
epoch 2800, loss 0.752398
epoch 2900, loss 0.490678
epoch 3000, loss 0.339562
epoch 3100, loss 0.553569
epoch 3200, loss 0.195226
epoch 3300, loss 0.595541
epoch 3400, loss 0.394893
epoch 3500, loss 0.444858
epoch 3600, loss 0.493805
epoch 3700, loss 0.558703
epoch 3800, loss 0.427957
epoch 3900, loss 0.284509
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
43.9272 14.0823
53.6961 18.9204
586.598 43.8649
57.0616 67.4625
79.3243 24.4815
parameters: [ 8.01   1.584  2.     3.2    4.   ]. error: 6.55491193786.
----------------------------
epoch 0, loss 1.09417
epoch 100, loss 0.646075
epoch 200, loss 0.73865
epoch 300, loss 0.448587
epoch 400, loss 0.657515
epoch 500, loss 0.415752
epoch 600, loss 0.221515
epoch 700, loss 0.347903
epoch 800, loss 0.411403
epoch 900, loss 0.51113
epoch 1000, loss 0.415719
epoch 1100, loss 0.43862
epoch 1200, loss 0.661116
epoch 1300, loss 0.341095
epoch 1400, loss 0.519266
epoch 1500, loss 0.495421
epoch 1600, loss 0.451186
epoch 1700, loss 0.476128
epoch 1800, loss 0.345918
epoch 1900, loss 0.72488
epoch 2000, loss 0.781005
epoch 2100, loss 0.503351
epoch 2200, loss 0.379785
epoch 2300, loss 0.592104
epoch 2400, loss 0.415833
epoch 2500, loss 0.638343
epoch 2600, loss 0.663031
epoch 2700, loss 0.390844
epoch 2800, loss 0.515929
epoch 2900, loss 0.352733
epoch 3000, loss 0.417788
epoch 3100, loss 0.443652
epoch 3200, loss 0.536704
epoch 3300, loss 0.57036
epoch 3400, loss 0.33613
epoch 3500, loss 0.526049
epoch 3600, loss 0.307509
epoch 3700, loss 0.738908
epoch 3800, loss 0.67885
epoch 3900, loss 0.347972
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
586.598 53.2032
13.7745 15.6927
116.598 59.8015
79.3243 17.2678
10.5701 12.7386
parameters: [ 8.01   1.584  1.382  3.2    4.   ]. error: 4.05246250899.
----------------------------
epoch 0, loss 0.923009
epoch 100, loss 0.617565
epoch 200, loss 0.478559
epoch 300, loss 0.434191
epoch 400, loss 0.445401
epoch 500, loss 0.487074
epoch 600, loss 0.29831
epoch 700, loss 0.294729
epoch 800, loss 0.733635
epoch 900, loss 0.321977
epoch 1000, loss 0.441427
epoch 1100, loss 0.39898
epoch 1200, loss 0.422356
epoch 1300, loss 0.511693
epoch 1400, loss 0.635914
epoch 1500, loss 0.638771
epoch 1600, loss 0.584436
epoch 1700, loss 0.311431
epoch 1800, loss 0.398816
epoch 1900, loss 0.827567
epoch 2000, loss 0.396156
epoch 2100, loss 0.246577
epoch 2200, loss 0.251264
epoch 2300, loss 0.530345
epoch 2400, loss 0.357606
epoch 2500, loss 0.360996
epoch 2600, loss 0.438971
epoch 2700, loss 0.561253
epoch 2800, loss 0.30923
epoch 2900, loss 0.153762
epoch 3000, loss 0.331802
epoch 3100, loss 0.490683
epoch 3200, loss 0.551123
epoch 3300, loss 0.340322
epoch 3400, loss 0.327788
epoch 3500, loss 0.561111
epoch 3600, loss 0.335789
epoch 3700, loss 0.63499
epoch 3800, loss 0.482604
epoch 3900, loss 0.658494
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
94.9786 77.445
69.8093 78.9509
2.37471 26.7769
146.624 77.445
586.598 69.8072
parameters: [ 8.01   1.584  1.     3.2    4.   ]. error: 6.31639054334.
----------------------------
epoch 0, loss 1.34996
epoch 100, loss 0.911682
epoch 200, loss 0.625177
epoch 300, loss 0.491318
epoch 400, loss 0.59529
epoch 500, loss 0.506224
epoch 600, loss 1.08106
epoch 700, loss 0.605419
epoch 800, loss 0.691063
epoch 900, loss 0.974225
epoch 1000, loss 0.715442
epoch 1100, loss 0.732122
epoch 1200, loss 0.506732
epoch 1300, loss 0.54372
epoch 1400, loss 0.457446
epoch 1500, loss 0.532855
epoch 1600, loss 0.552192
epoch 1700, loss 0.369188
epoch 1800, loss 0.471984
epoch 1900, loss 0.576309
epoch 2000, loss 0.508229
epoch 2100, loss 0.535975
epoch 2200, loss 0.854946
epoch 2300, loss 1.0027
epoch 2400, loss 0.370705
epoch 2500, loss 0.596531
epoch 2600, loss 0.893617
epoch 2700, loss 0.538457
epoch 2800, loss 0.452458
epoch 2900, loss 0.523987
epoch 3000, loss 0.229722
epoch 3100, loss 0.301474
epoch 3200, loss 0.409118
epoch 3300, loss 0.439699
epoch 3400, loss 0.543363
epoch 3500, loss 0.369694
epoch 3600, loss 0.611139
epoch 3700, loss 0.546986
epoch 3800, loss 0.515785
epoch 3900, loss 0.479845
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
47.4619 109.368
33.8136 41.8575
71.133 7.74656
13.9704 24.7865
94.9786 108.282
parameters: [ 8.01   1.584  1.488  3.2    4.   ]. error: 2.63569308352.
----------------------------
epoch 0, loss 0.910516
epoch 100, loss 1.40287
epoch 200, loss 0.906306
epoch 300, loss 0.275477
epoch 400, loss 0.654873
epoch 500, loss 0.922664
epoch 600, loss 0.339561
epoch 700, loss 0.938586
epoch 800, loss 0.609302
epoch 900, loss 0.375581
epoch 1000, loss 0.345442
epoch 1100, loss 0.419143
epoch 1200, loss 0.819692
epoch 1300, loss 0.576461
epoch 1400, loss 0.870521
epoch 1500, loss 0.702142
epoch 1600, loss 0.438534
epoch 1700, loss 0.742013
epoch 1800, loss 0.346564
epoch 1900, loss 0.484566
epoch 2000, loss 0.531561
epoch 2100, loss 0.329097
epoch 2200, loss 0.532209
epoch 2300, loss 0.488748
epoch 2400, loss 0.400889
epoch 2500, loss 0.474434
epoch 2600, loss 0.628235
epoch 2700, loss 1.22352
epoch 2800, loss 0.298698
epoch 2900, loss 0.645294
epoch 3000, loss 0.528467
epoch 3100, loss 0.605959
epoch 3200, loss 0.618959
epoch 3300, loss 1.1664
epoch 3400, loss 0.719642
epoch 3500, loss 0.371259
epoch 3600, loss 0.769234
epoch 3700, loss 0.768722
epoch 3800, loss 0.455922
epoch 3900, loss 0.667698
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
48.9224 35.3321
32.9441 42.8742
69.8093 84.2372
25.6565 57.6552
39.4136 33.9097
parameters: [ 8.01   1.584  1.684  3.2    4.   ]. error: 0.098261721986.
----------------------------
epoch 0, loss 0.983171
epoch 100, loss 1.16813
epoch 200, loss 1.08696
epoch 300, loss 0.794694
epoch 400, loss 1.37459
epoch 500, loss 1.04653
epoch 600, loss 0.500325
epoch 700, loss 0.39351
epoch 800, loss 0.497556
epoch 900, loss 0.704819
epoch 1000, loss 0.509181
epoch 1100, loss 0.491034
epoch 1200, loss 0.443159
epoch 1300, loss 0.619314
epoch 1400, loss 0.408345
epoch 1500, loss 0.453545
epoch 1600, loss 0.53016
epoch 1700, loss 0.651832
epoch 1800, loss 0.853247
epoch 1900, loss 0.440476
epoch 2000, loss 0.397131
epoch 2100, loss 0.346988
epoch 2200, loss 0.346591
epoch 2300, loss 0.285488
epoch 2400, loss 0.282923
epoch 2500, loss 0.668241
epoch 2600, loss 0.279901
epoch 2700, loss 0.626032
epoch 2800, loss 0.359608
epoch 2900, loss 0.618678
epoch 3000, loss 0.335132
epoch 3100, loss 0.549429
epoch 3200, loss 0.543084
epoch 3300, loss 0.285193
epoch 3400, loss 0.838728
epoch 3500, loss 0.320148
epoch 3600, loss 0.227715
epoch 3700, loss 0.381848
epoch 3800, loss 0.566841
epoch 3900, loss 0.395355
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
244.06 176.633
586.598 42.3381
13.842 35.6777
14.1268 19.6376
234.37 48.135
parameters: [ 8.01   1.584  1.804  3.2    4.   ]. error: 7.2519995717.
----------------------------
epoch 0, loss 0.961217
epoch 100, loss 1.17366
epoch 200, loss 0.977924
epoch 300, loss 0.619565
epoch 400, loss 0.700807
epoch 500, loss 0.525631
epoch 600, loss 0.443551
epoch 700, loss 0.576901
epoch 800, loss 0.29503
epoch 900, loss 0.355002
epoch 1000, loss 0.44281
epoch 1100, loss 0.67811
epoch 1200, loss 0.449756
epoch 1300, loss 0.58689
epoch 1400, loss 0.475328
epoch 1500, loss 0.485361
epoch 1600, loss 0.332748
epoch 1700, loss 0.263923
epoch 1800, loss 0.361191
epoch 1900, loss 0.566327
epoch 2000, loss 0.511176
epoch 2100, loss 0.456234
epoch 2200, loss 0.511341
epoch 2300, loss 0.645911
epoch 2400, loss 0.515069
epoch 2500, loss 0.668454
epoch 2600, loss 0.229475
epoch 2700, loss 0.382162
epoch 2800, loss 0.396472
epoch 2900, loss 0.254941
epoch 3000, loss 0.536115
epoch 3100, loss 0.506824
epoch 3200, loss 0.516724
epoch 3300, loss 0.797721
epoch 3400, loss 0.261945
epoch 3500, loss 0.363369
epoch 3600, loss 0.296724
epoch 3700, loss 0.543302
epoch 3800, loss 0.699568
epoch 3900, loss 0.462607
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
25.6565 47.758
3167.53 313.016
1321.38 245.656
89.2785 31.7063
305.167 102.676
parameters: [ 8.01   1.584  1.609  3.2    4.   ]. error: 3.30479042796.
----------------------------
epoch 0, loss 0.805651
epoch 100, loss 0.989846
epoch 200, loss 0.932426
epoch 300, loss 0.507269
epoch 400, loss 0.413583
epoch 500, loss 0.447241
epoch 600, loss 0.586242
epoch 700, loss 0.838548
epoch 800, loss 0.575112
epoch 900, loss 0.89589
epoch 1000, loss 0.630842
epoch 1100, loss 0.544361
epoch 1200, loss 0.698254
epoch 1300, loss 0.44887
epoch 1400, loss 0.521374
epoch 1500, loss 0.499989
epoch 1600, loss 0.476117
epoch 1700, loss 0.637608
epoch 1800, loss 0.981697
epoch 1900, loss 0.472436
epoch 2000, loss 0.459496
epoch 2100, loss 0.43973
epoch 2200, loss 0.593589
epoch 2300, loss 0.436843
epoch 2400, loss 0.464281
epoch 2500, loss 0.574674
epoch 2600, loss 0.805256
epoch 2700, loss 0.604638
epoch 2800, loss 0.466204
epoch 2900, loss 0.679095
epoch 3000, loss 0.693357
epoch 3100, loss 0.659964
epoch 3200, loss 0.639444
epoch 3300, loss 0.428571
epoch 3400, loss 0.444163
epoch 3500, loss 0.45097
epoch 3600, loss 0.519556
epoch 3700, loss 0.616728
epoch 3800, loss 0.576764
epoch 3900, loss 0.346978
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
43.9272 12.5135
9.3969 16.8022
20.2734 24.4682
37.0194 47.9113
69.8093 76.1859
parameters: [ 8.01   1.584  1.73   3.2    4.   ]. error: 0.273630966599.
----------------------------
epoch 0, loss 1.28475
epoch 100, loss 0.750557
epoch 200, loss 0.631889
epoch 300, loss 0.314322
epoch 400, loss 0.734556
epoch 500, loss 0.693625
epoch 600, loss 0.572625
epoch 700, loss 0.344952
epoch 800, loss 0.573854
epoch 900, loss 0.770752
epoch 1000, loss 0.87303
epoch 1100, loss 0.274335
epoch 1200, loss 0.592987
epoch 1300, loss 0.6109
epoch 1400, loss 0.651161
epoch 1500, loss 0.617403
epoch 1600, loss 0.781817
epoch 1700, loss 0.401426
epoch 1800, loss 0.733269
epoch 1900, loss 0.909376
epoch 2000, loss 1.0159
epoch 2100, loss 0.516503
epoch 2200, loss 0.413914
epoch 2300, loss 0.881758
epoch 2400, loss 0.832967
epoch 2500, loss 1.00027
epoch 2600, loss 0.467146
epoch 2700, loss 0.718864
epoch 2800, loss 0.366101
epoch 2900, loss 0.48707
epoch 3000, loss 0.388467
epoch 3100, loss 0.680648
epoch 3200, loss 0.524809
epoch 3300, loss 0.426969
epoch 3400, loss 0.449242
epoch 3500, loss 0.406711
epoch 3600, loss 0.557319
epoch 3700, loss 0.202522
epoch 3800, loss 0.287259
epoch 3900, loss 0.46799
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
106.094 47.5101
38.4634 271.31
9.3969 17.9274
21.6939 41.6982
89.7385 335.081
parameters: [ 8.01   1.584  1.679  3.2    4.   ]. error: 1.39594848412.
----------------------------
epoch 0, loss 1.40978
epoch 100, loss 0.62024
epoch 200, loss 0.768382
epoch 300, loss 0.523177
epoch 400, loss 0.560498
epoch 500, loss 0.501049
epoch 600, loss 0.487271
epoch 700, loss 0.933102
epoch 800, loss 0.710992
epoch 900, loss 0.853232
epoch 1000, loss 0.545214
epoch 1100, loss 0.53061
epoch 1200, loss 0.377584
epoch 1300, loss 0.358891
epoch 1400, loss 0.459381
epoch 1500, loss 0.59847
epoch 1600, loss 0.383623
epoch 1700, loss 0.337449
epoch 1800, loss 0.432662
epoch 1900, loss 0.61289
epoch 2000, loss 0.466234
epoch 2100, loss 0.592462
epoch 2200, loss 0.369905
epoch 2300, loss 0.539787
epoch 2400, loss 0.705421
epoch 2500, loss 0.837614
epoch 2600, loss 0.747778
epoch 2700, loss 0.52334
epoch 2800, loss 0.419763
epoch 2900, loss 0.468026
epoch 3000, loss 0.453736
epoch 3100, loss 0.484641
epoch 3200, loss 0.685896
epoch 3300, loss 0.485443
epoch 3400, loss 0.764095
epoch 3500, loss 0.471879
epoch 3600, loss 0.115196
epoch 3700, loss 0.67272
epoch 3800, loss 0.534684
epoch 3900, loss 0.626275
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
1321.38 406.243
71.8482 46.8433
38.4634 129.513
32.0605 78.439
13.2248 22.1153
parameters: [ 8.01   1.584  1.706  3.2    4.   ]. error: 0.398861407935.
----------------------------
epoch 0, loss 2.03241
epoch 100, loss 0.670668
epoch 200, loss 0.607365
epoch 300, loss 0.324612
epoch 400, loss 0.370538
epoch 500, loss 0.608171
epoch 600, loss 0.381295
epoch 700, loss 0.555887
epoch 800, loss 0.430458
epoch 900, loss 0.481547
epoch 1000, loss 0.497571
epoch 1100, loss 0.434086
epoch 1200, loss 0.483649
epoch 1300, loss 0.484955
epoch 1400, loss 0.646903
epoch 1500, loss 0.628564
epoch 1600, loss 0.582777
epoch 1700, loss 0.735401
epoch 1800, loss 0.617478
epoch 1900, loss 0.637373
epoch 2000, loss 0.419813
epoch 2100, loss 0.623204
epoch 2200, loss 0.543377
epoch 2300, loss 0.568092
epoch 2400, loss 0.643566
epoch 2500, loss 0.528866
epoch 2600, loss 0.459366
epoch 2700, loss 0.78009
epoch 2800, loss 0.344032
epoch 2900, loss 0.602218
epoch 3000, loss 0.392445
epoch 3100, loss 0.427459
epoch 3200, loss 0.267288
epoch 3300, loss 0.222596
epoch 3400, loss 0.408
epoch 3500, loss 0.347805
epoch 3600, loss 0.63608
epoch 3700, loss 0.56065
epoch 3800, loss 0.337203
epoch 3900, loss 0.486872
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
38.4634 127.242
69.8093 73.7615
28.7444 38.3456
586.598 34.7284
70.2845 82.0358
parameters: [ 8.01   1.584  1.692  3.2    4.   ]. error: 11.9247907304.
----------------------------
epoch 0, loss 2.4134
epoch 100, loss 0.505289
epoch 200, loss 0.820893
epoch 300, loss 1.0978
epoch 400, loss 0.634202
epoch 500, loss 0.830189
epoch 600, loss 0.421533
epoch 700, loss 0.831856
epoch 800, loss 0.364133
epoch 900, loss 1.09344
epoch 1000, loss 0.536098
epoch 1100, loss 0.678881
epoch 1200, loss 0.482738
epoch 1300, loss 0.708196
epoch 1400, loss 0.392816
epoch 1500, loss 0.360041
epoch 1600, loss 0.78567
epoch 1700, loss 0.321302
epoch 1800, loss 0.511558
epoch 1900, loss 0.343045
epoch 2000, loss 0.342661
epoch 2100, loss 0.492423
epoch 2200, loss 0.295815
epoch 2300, loss 0.575086
epoch 2400, loss 0.513013
epoch 2500, loss 0.328833
epoch 2600, loss 0.473154
epoch 2700, loss 0.350752
epoch 2800, loss 0.553526
epoch 2900, loss 0.520496
epoch 3000, loss 0.415308
epoch 3100, loss 0.338411
epoch 3200, loss 0.694769
epoch 3300, loss 0.407016
epoch 3400, loss 0.609857
epoch 3500, loss 0.54182
epoch 3600, loss 0.303741
epoch 3700, loss 0.471068
epoch 3800, loss 0.354994
epoch 3900, loss 0.660646
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
64.3569 76.5396
13.2248 23.0163
116.598 85.1726
126.871 238.326
1.11386 17.2212
parameters: [ 8.01   1.584  1.687  3.2    4.   ]. error: 9.42100830596.
----------------------------
epoch 0, loss 1.06614
epoch 100, loss 0.804887
epoch 200, loss 0.604937
epoch 300, loss 0.561077
epoch 400, loss 0.795218
epoch 500, loss 0.583811
epoch 600, loss 0.481763
epoch 700, loss 0.415573
epoch 800, loss 0.655745
epoch 900, loss 0.528175
epoch 1000, loss 0.950361
epoch 1100, loss 0.534192
epoch 1200, loss 0.429722
epoch 1300, loss 0.795035
epoch 1400, loss 0.702809
epoch 1500, loss 0.463206
epoch 1600, loss 0.353444
epoch 1700, loss 0.26239
epoch 1800, loss 0.365834
epoch 1900, loss 0.405119
epoch 2000, loss 0.414622
epoch 2100, loss 0.939055
epoch 2200, loss 0.373805
epoch 2300, loss 0.443139
epoch 2400, loss 0.384668
epoch 2500, loss 0.187685
epoch 2600, loss 0.58574
epoch 2700, loss 0.803238
epoch 2800, loss 0.409303
epoch 2900, loss 0.427286
epoch 3000, loss 0.337393
epoch 3100, loss 0.537511
epoch 3200, loss 0.43981
epoch 3300, loss 0.502064
epoch 3400, loss 0.519099
epoch 3500, loss 0.447817
epoch 3600, loss 0.503786
epoch 3700, loss 0.280939
epoch 3800, loss 0.319434
epoch 3900, loss 0.330788
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
89.2785 33.1241
2.37471 16.6952
13.7745 19.193
831.403 577.63
22.953 19.7366
parameters: [ 8.01   1.584  1.684  3.2    4.   ]. error: 1.42980772265.
----------------------------
epoch 0, loss 1.77621
epoch 100, loss 0.755189
epoch 200, loss 0.591566
epoch 300, loss 0.730333
epoch 400, loss 0.486146
epoch 500, loss 0.698784
epoch 600, loss 0.526529
epoch 700, loss 0.569755
epoch 800, loss 0.535518
epoch 900, loss 0.541717
epoch 1000, loss 0.463679
epoch 1100, loss 0.477792
epoch 1200, loss 0.50869
epoch 1300, loss 0.769946
epoch 1400, loss 0.350632
epoch 1500, loss 0.56059
epoch 1600, loss 0.276859
epoch 1700, loss 0.618386
epoch 1800, loss 0.332156
epoch 1900, loss 0.271778
epoch 2000, loss 0.355714
epoch 2100, loss 0.818992
epoch 2200, loss 0.531573
epoch 2300, loss 0.445069
epoch 2400, loss 0.396493
epoch 2500, loss 0.308037
epoch 2600, loss 0.795282
epoch 2700, loss 0.391466
epoch 2800, loss 0.567743
epoch 2900, loss 0.646199
epoch 3000, loss 0.592107
epoch 3100, loss 0.589416
epoch 3200, loss 0.516726
epoch 3300, loss 0.285662
epoch 3400, loss 0.515073
epoch 3500, loss 0.301328
epoch 3600, loss 0.361574
epoch 3700, loss 0.783541
epoch 3800, loss 0.335716
epoch 3900, loss 0.717296
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
146.624 87.1291
244.06 116.108
64.3569 89.658
194.962 100.032
19.4471 39.8021
parameters: [ 8.01   1.584  1.684  4.2    4.   ]. error: 0.12398736004.
----------------------------
epoch 0, loss 0.871514
epoch 100, loss 1.16374
epoch 200, loss 1.22539
epoch 300, loss 0.540244
epoch 400, loss 0.508467
epoch 500, loss 0.599499
epoch 600, loss 0.398918
epoch 700, loss 0.451433
epoch 800, loss 0.318799
epoch 900, loss 0.414347
epoch 1000, loss 0.409561
epoch 1100, loss 0.510636
epoch 1200, loss 0.468402
epoch 1300, loss 0.355547
epoch 1400, loss 0.549292
epoch 1500, loss 0.794186
epoch 1600, loss 0.839068
epoch 1700, loss 0.470371
epoch 1800, loss 0.40821
epoch 1900, loss 0.262603
epoch 2000, loss 0.443029
epoch 2100, loss 0.425617
epoch 2200, loss 0.36632
epoch 2300, loss 0.494071
epoch 2400, loss 0.634975
epoch 2500, loss 0.36799
epoch 2600, loss 0.516921
epoch 2700, loss 0.395989
epoch 2800, loss 0.471696
epoch 2900, loss 0.562798
epoch 3000, loss 0.592946
epoch 3100, loss 0.723949
epoch 3200, loss 0.693096
epoch 3300, loss 0.331853
epoch 3400, loss 0.332264
epoch 3500, loss 0.352119
epoch 3600, loss 0.543766
epoch 3700, loss 0.410455
epoch 3800, loss 0.519366
epoch 3900, loss 0.628226
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
259.052 60.3475
6.15658 15.8191
2.37471 23.077
586.598 48.9944
194.962 259.692
parameters: [ 8.01   1.584  1.684  5.818  4.   ]. error: 7.90395496363.
----------------------------
epoch 0, loss 0.930995
epoch 100, loss 0.979934
epoch 200, loss 0.970944
epoch 300, loss 0.710305
epoch 400, loss 0.65525
epoch 500, loss 0.698281
epoch 600, loss 0.665845
epoch 700, loss 0.771256
epoch 800, loss 0.588634
epoch 900, loss 0.941308
epoch 1000, loss 0.520078
epoch 1100, loss 0.439428
epoch 1200, loss 0.43711
epoch 1300, loss 0.59531
epoch 1400, loss 0.661667
epoch 1500, loss 0.480869
epoch 1600, loss 0.497677
epoch 1700, loss 0.31566
epoch 1800, loss 0.543766
epoch 1900, loss 0.532785
epoch 2000, loss 0.640664
epoch 2100, loss 0.676832
epoch 2200, loss 0.595767
epoch 2300, loss 0.583236
epoch 2400, loss 0.585823
epoch 2500, loss 0.464769
epoch 2600, loss 0.654944
epoch 2700, loss 0.697671
epoch 2800, loss 0.439982
epoch 2900, loss 0.675368
epoch 3000, loss 0.277126
epoch 3100, loss 0.457442
epoch 3200, loss 0.556733
epoch 3300, loss 0.448206
epoch 3400, loss 0.483938
epoch 3500, loss 0.253417
epoch 3600, loss 0.579343
epoch 3700, loss 0.352178
epoch 3800, loss 0.426578
epoch 3900, loss 0.56922
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
71.133 22.7074
6.15658 18.5324
127.381 71.5953
13.842 43.1802
13.9704 45.965
parameters: [ 8.01   1.584  1.684  4.2    4.   ]. error: 0.370041810355.
----------------------------
epoch 0, loss 1.10939
epoch 100, loss 1.08754
epoch 200, loss 0.8721
epoch 300, loss 0.495253
epoch 400, loss 0.353625
epoch 500, loss 0.797028
epoch 600, loss 0.469696
epoch 700, loss 0.534316
epoch 800, loss 0.578019
epoch 900, loss 0.577076
epoch 1000, loss 0.438846
epoch 1100, loss 0.453545
epoch 1200, loss 0.882306
epoch 1300, loss 0.561159
epoch 1400, loss 0.658452
epoch 1500, loss 0.467688
epoch 1600, loss 0.161886
epoch 1700, loss 0.659541
epoch 1800, loss 0.5817
epoch 1900, loss 0.463588
epoch 2000, loss 0.718874
epoch 2100, loss 0.591738
epoch 2200, loss 0.779125
epoch 2300, loss 0.435593
epoch 2400, loss 0.888013
epoch 2500, loss 0.337635
epoch 2600, loss 0.545178
epoch 2700, loss 0.506538
epoch 2800, loss 0.587411
epoch 2900, loss 0.499526
epoch 3000, loss 0.370721
epoch 3100, loss 0.511099
epoch 3200, loss 0.486106
epoch 3300, loss 0.423736
epoch 3400, loss 0.519198
epoch 3500, loss 0.268123
epoch 3600, loss 0.631697
epoch 3700, loss 0.355046
epoch 3800, loss 0.413617
epoch 3900, loss 0.663422
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
37.0194 43.9314
106.094 42.5242
69.8093 86.0541
32.9279 84.9752
33.8136 33.329
parameters: [ 8.01   1.584  1.684  4.818  4.   ]. error: 0.205303490598.
----------------------------
epoch 0, loss 1.05664
epoch 100, loss 1.26152
epoch 200, loss 0.660477
epoch 300, loss 0.733591
epoch 400, loss 0.805601
epoch 500, loss 0.482581
epoch 600, loss 0.571315
epoch 700, loss 0.487716
epoch 800, loss 0.771712
epoch 900, loss 0.523322
epoch 1000, loss 0.588571
epoch 1100, loss 0.432542
epoch 1200, loss 0.855179
epoch 1300, loss 0.553832
epoch 1400, loss 0.348601
epoch 1500, loss 0.506657
epoch 1600, loss 0.695753
epoch 1700, loss 0.879119
epoch 1800, loss 0.548746
epoch 1900, loss 0.567507
epoch 2000, loss 0.598901
epoch 2100, loss 0.76159
epoch 2200, loss 0.300811
epoch 2300, loss 0.416099
epoch 2400, loss 0.471709
epoch 2500, loss 0.517901
epoch 2600, loss 0.417673
epoch 2700, loss 0.56297
epoch 2800, loss 0.762265
epoch 2900, loss 0.451365
epoch 3000, loss 0.5568
epoch 3100, loss 0.648361
epoch 3200, loss 0.680056
epoch 3300, loss 0.57465
epoch 3400, loss 0.416888
epoch 3500, loss 0.861441
epoch 3600, loss 0.636925
epoch 3700, loss 0.482267
epoch 3800, loss 0.412218
epoch 3900, loss 0.343249
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
246.534 58.3299
45.3756 65.0597
56.7553 36.7905
64.3569 64.7844
162.436 59.7924
parameters: [ 8.01   1.584  1.684  5.2    4.   ]. error: 0.3918691606.
----------------------------
epoch 0, loss 1.72585
epoch 100, loss 0.895575
epoch 200, loss 0.71954
epoch 300, loss 0.589502
epoch 400, loss 0.679982
epoch 500, loss 0.408576
epoch 600, loss 0.496646
epoch 700, loss 0.49013
epoch 800, loss 0.563874
epoch 900, loss 0.677349
epoch 1000, loss 0.343592
epoch 1100, loss 0.519543
epoch 1200, loss 0.439457
epoch 1300, loss 0.295189
epoch 1400, loss 0.611836
epoch 1500, loss 0.499635
epoch 1600, loss 0.482731
epoch 1700, loss 0.275932
epoch 1800, loss 0.401666
epoch 1900, loss 0.627242
epoch 2000, loss 0.857113
epoch 2100, loss 0.704789
epoch 2200, loss 0.476765
epoch 2300, loss 0.558951
epoch 2400, loss 0.501177
epoch 2500, loss 0.584339
epoch 2600, loss 0.448052
epoch 2700, loss 0.707194
epoch 2800, loss 0.496597
epoch 2900, loss 0.368043
epoch 3000, loss 0.426582
epoch 3100, loss 0.489786
epoch 3200, loss 0.426117
epoch 3300, loss 0.563528
epoch 3400, loss 0.366164
epoch 3500, loss 0.391876
epoch 3600, loss 0.706313
epoch 3700, loss 0.405555
epoch 3800, loss 0.628351
epoch 3900, loss 0.741944
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
831.403 320.842
67.5897 59.0431
244.06 138.687
56.7553 30.9557
21.6939 30.2705
parameters: [ 8.01   1.584  1.684  4.686  4.   ]. error: 0.131092946429.
----------------------------
epoch 0, loss 0.940901
epoch 100, loss 0.791586
epoch 200, loss 0.469209
epoch 300, loss 0.869055
epoch 400, loss 0.745638
epoch 500, loss 0.906627
epoch 600, loss 1.03922
epoch 700, loss 0.844235
epoch 800, loss 0.477712
epoch 900, loss 0.381311
epoch 1000, loss 0.636995
epoch 1100, loss 0.395638
epoch 1200, loss 0.900271
epoch 1300, loss 0.730422
epoch 1400, loss 0.575067
epoch 1500, loss 0.530482
epoch 1600, loss 0.856334
epoch 1700, loss 0.487802
epoch 1800, loss 0.761109
epoch 1900, loss 0.465129
epoch 2000, loss 0.378623
epoch 2100, loss 0.415613
epoch 2200, loss 0.468862
epoch 2300, loss 0.498454
epoch 2400, loss 0.402088
epoch 2500, loss 0.69593
epoch 2600, loss 0.718455
epoch 2700, loss 1.11058
epoch 2800, loss 0.570752
epoch 2900, loss 0.421817
epoch 3000, loss 0.777355
epoch 3100, loss 0.309884
epoch 3200, loss 0.763624
epoch 3300, loss 0.449291
epoch 3400, loss 0.42441
epoch 3500, loss 0.492691
epoch 3600, loss 0.463651
epoch 3700, loss 0.212826
epoch 3800, loss 0.598668
epoch 3900, loss 0.589722
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
23.1269 65.2651
89.7385 362.066
28.7444 46.1154
194.962 185.903
57.0616 68.2198
parameters: [ 8.01   1.584  1.684  4.587  4.   ]. error: 0.338244049514.
----------------------------
epoch 0, loss 1.46828
epoch 100, loss 1.00295
epoch 200, loss 0.834349
epoch 300, loss 0.924331
epoch 400, loss 0.860978
epoch 500, loss 0.743002
epoch 600, loss 0.609472
epoch 700, loss 0.608837
epoch 800, loss 0.493438
epoch 900, loss 1.09732
epoch 1000, loss 0.425688
epoch 1100, loss 0.811888
epoch 1200, loss 0.635141
epoch 1300, loss 0.56121
epoch 1400, loss 0.291421
epoch 1500, loss 0.886422
epoch 1600, loss 0.440174
epoch 1700, loss 0.783371
epoch 1800, loss 0.561712
epoch 1900, loss 0.606248
epoch 2000, loss 0.38849
epoch 2100, loss 0.495022
epoch 2200, loss 0.33579
epoch 2300, loss 0.453164
epoch 2400, loss 0.542958
epoch 2500, loss 0.399606
epoch 2600, loss 0.5042
epoch 2700, loss 0.696875
epoch 2800, loss 0.534025
epoch 2900, loss 0.480963
epoch 3000, loss 0.604114
epoch 3100, loss 0.461408
epoch 3200, loss 0.484374
epoch 3300, loss 0.703194
epoch 3400, loss 0.660765
epoch 3500, loss 0.656407
epoch 3600, loss 0.806792
epoch 3700, loss 0.407624
epoch 3800, loss 0.612432
epoch 3900, loss 0.519143
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
33.7234 41.4226
22.953 25.9855
32.9441 34.0219
162.436 76.0123
45.3756 76.2449
parameters: [ 8.01   1.584  1.684  4.728  4.   ]. error: 0.103356073026.
----------------------------
epoch 0, loss 1.06276
epoch 100, loss 0.783099
epoch 200, loss 0.488473
epoch 300, loss 0.486429
epoch 400, loss 0.594098
epoch 500, loss 0.457534
epoch 600, loss 0.943804
epoch 700, loss 0.697846
epoch 800, loss 0.948707
epoch 900, loss 0.434977
epoch 1000, loss 0.868613
epoch 1100, loss 0.255633
epoch 1200, loss 0.457283
epoch 1300, loss 1.08695
epoch 1400, loss 0.743727
epoch 1500, loss 0.473921
epoch 1600, loss 0.471121
epoch 1700, loss 0.42787
epoch 1800, loss 0.690523
epoch 1900, loss 0.450837
epoch 2000, loss 0.51558
epoch 2100, loss 0.36851
epoch 2200, loss 0.468687
epoch 2300, loss 0.260395
epoch 2400, loss 0.509376
epoch 2500, loss 0.456086
epoch 2600, loss 0.732386
epoch 2700, loss 0.457158
epoch 2800, loss 0.493145
epoch 2900, loss 0.359225
epoch 3000, loss 0.487819
epoch 3100, loss 0.385089
epoch 3200, loss 0.250385
epoch 3300, loss 0.913114
epoch 3400, loss 0.682843
epoch 3500, loss 0.427577
epoch 3600, loss 0.690935
epoch 3700, loss 0.435492
epoch 3800, loss 0.286048
epoch 3900, loss 0.722002
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
25.6565 58.6668
25.6565 58.6668
209.705 47.2221
10.5701 15.5337
13.7745 15.0234
parameters: [ 8.01   1.584  1.684  4.743  4.   ]. error: 0.494648167942.
----------------------------
epoch 0, loss 0.894675
epoch 100, loss 0.946677
epoch 200, loss 0.63427
epoch 300, loss 0.728644
epoch 400, loss 0.349555
epoch 500, loss 0.818164
epoch 600, loss 0.623863
epoch 700, loss 0.491712
epoch 800, loss 0.442298
epoch 900, loss 0.365918
epoch 1000, loss 0.452246
epoch 1100, loss 0.320934
epoch 1200, loss 0.901612
epoch 1300, loss 0.547529
epoch 1400, loss 0.433097
epoch 1500, loss 0.66156
epoch 1600, loss 0.425345
epoch 1700, loss 0.475203
epoch 1800, loss 0.369817
epoch 1900, loss 0.330329
epoch 2000, loss 0.509869
epoch 2100, loss 0.434348
epoch 2200, loss 0.491264
epoch 2300, loss 0.446995
epoch 2400, loss 0.320194
epoch 2500, loss 0.749431
epoch 2600, loss 0.65575
epoch 2700, loss 0.53078
epoch 2800, loss 0.455358
epoch 2900, loss 0.521581
epoch 3000, loss 0.783905
epoch 3100, loss 0.557574
epoch 3200, loss 0.411106
epoch 3300, loss 0.548581
epoch 3400, loss 0.623013
epoch 3500, loss 0.646594
epoch 3600, loss 0.490779
epoch 3700, loss 0.342775
epoch 3800, loss 0.376798
epoch 3900, loss 0.419707
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
96.1397 97.5515
3167.53 859.441
13.7745 22.1683
23.1269 24.4516
127.381 72.1379
parameters: [ 8.01   1.584  1.684  4.712  4.   ]. error: 0.293631084059.
----------------------------
epoch 0, loss 1.64164
epoch 100, loss 0.789487
epoch 200, loss 1.16863
epoch 300, loss 0.788969
epoch 400, loss 0.715508
epoch 500, loss 0.533854
epoch 600, loss 0.892709
epoch 700, loss 0.796713
epoch 800, loss 0.645953
epoch 900, loss 0.509822
epoch 1000, loss 0.827884
epoch 1100, loss 0.693571
epoch 1200, loss 0.626228
epoch 1300, loss 0.700142
epoch 1400, loss 0.593432
epoch 1500, loss 0.647903
epoch 1600, loss 0.351348
epoch 1700, loss 0.445787
epoch 1800, loss 0.787259
epoch 1900, loss 0.485627
epoch 2000, loss 0.546116
epoch 2100, loss 0.6138
epoch 2200, loss 0.478659
epoch 2300, loss 0.519147
epoch 2400, loss 0.577973
epoch 2500, loss 0.472403
epoch 2600, loss 0.657591
epoch 2700, loss 0.818766
epoch 2800, loss 0.394309
epoch 2900, loss 0.492731
epoch 3000, loss 0.388408
epoch 3100, loss 0.529845
epoch 3200, loss 0.685081
epoch 3300, loss 0.437749
epoch 3400, loss 0.500597
epoch 3500, loss 0.45946
epoch 3600, loss 0.236526
epoch 3700, loss 0.463668
epoch 3800, loss 0.614406
epoch 3900, loss 0.618361
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
14.1268 21.5612
244.06 109.751
127.381 54.3387
246.534 91.8593
234.37 70.7762
parameters: [ 8.01   1.584  1.684  4.728  4.   ]. error: 0.228322258423.
----------------------------
epoch 0, loss 1.29622
epoch 100, loss 0.983068
epoch 200, loss 0.7821
epoch 300, loss 0.804873
epoch 400, loss 0.686155
epoch 500, loss 0.503102
epoch 600, loss 0.553764
epoch 700, loss 0.431929
epoch 800, loss 0.61003
epoch 900, loss 0.628058
epoch 1000, loss 0.371765
epoch 1100, loss 0.482539
epoch 1200, loss 0.806996
epoch 1300, loss 0.556997
epoch 1400, loss 0.650065
epoch 1500, loss 0.371173
epoch 1600, loss 0.472182
epoch 1700, loss 0.38164
epoch 1800, loss 0.542693
epoch 1900, loss 0.455867
epoch 2000, loss 0.320109
epoch 2100, loss 0.566767
epoch 2200, loss 0.596117
epoch 2300, loss 0.618122
epoch 2400, loss 0.904355
epoch 2500, loss 0.674419
epoch 2600, loss 0.494488
epoch 2700, loss 0.447919
epoch 2800, loss 0.400683
epoch 2900, loss 0.425288
epoch 3000, loss 0.51893
epoch 3100, loss 0.649022
epoch 3200, loss 0.808393
epoch 3300, loss 0.588087
epoch 3400, loss 0.584028
epoch 3500, loss 0.341988
epoch 3600, loss 0.626432
epoch 3700, loss 0.456515
epoch 3800, loss 0.275823
epoch 3900, loss 0.592924
epoch 4000, loss 0.642476
epoch 4100, loss 0.522907
epoch 4200, loss 0.351038
epoch 4300, loss 0.602072
epoch 4400, loss 0.418827
epoch 4500, loss 0.32564
epoch 4600, loss 0.538606
epoch 4700, loss 0.507787
epoch 4800, loss 0.528477
epoch 4900, loss 0.592584
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
259.052 89.5388
20.2734 33.5762
71.133 21.8242
45.3756 83.5179
89.7385 221.566
parameters: [ 8.01   1.584  1.684  4.728  5.   ]. error: 0.287580165444.
----------------------------
epoch 0, loss 1.54445
epoch 100, loss 0.845776
epoch 200, loss 0.529179
epoch 300, loss 0.496621
epoch 400, loss 0.524828
epoch 500, loss 0.538317
epoch 600, loss 0.598958
epoch 700, loss 0.416155
epoch 800, loss 0.390471
epoch 900, loss 0.37615
epoch 1000, loss 0.503642
epoch 1100, loss 0.36947
epoch 1200, loss 0.293586
epoch 1300, loss 0.529503
epoch 1400, loss 0.642388
epoch 1500, loss 0.444257
epoch 1600, loss 0.349771
epoch 1700, loss 0.501142
epoch 1800, loss 0.405413
epoch 1900, loss 0.257014
epoch 2000, loss 0.546141
epoch 2100, loss 0.432225
epoch 2200, loss 0.463536
epoch 2300, loss 0.595331
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
282.053 138.544
605.821 149.289
3167.53 218.028
21.6939 36.0751
69.8093 71.177
parameters: [ 8.01   1.584  1.684  4.728  2.382]. error: 8.0806210286.
----------------------------
epoch 0, loss 1.00705
epoch 100, loss 0.755612
epoch 200, loss 0.488535
epoch 300, loss 0.74035
epoch 400, loss 0.496723
epoch 500, loss 0.635905
epoch 600, loss 0.326078
epoch 700, loss 0.43872
epoch 800, loss 0.474029
epoch 900, loss 0.614189
epoch 1000, loss 0.50439
epoch 1100, loss 0.529704
epoch 1200, loss 0.420161
epoch 1300, loss 0.322071
epoch 1400, loss 0.602028
epoch 1500, loss 0.706429
epoch 1600, loss 0.471216
epoch 1700, loss 0.362097
epoch 1800, loss 0.346544
epoch 1900, loss 0.579015
epoch 2000, loss 0.443947
epoch 2100, loss 0.443291
epoch 2200, loss 0.348504
epoch 2300, loss 0.461701
epoch 2400, loss 0.879165
epoch 2500, loss 0.40489
epoch 2600, loss 0.249767
epoch 2700, loss 0.520948
epoch 2800, loss 0.496333
epoch 2900, loss 0.53243
epoch 3000, loss 0.269997
epoch 3100, loss 0.535205
epoch 3200, loss 0.465021
epoch 3300, loss 0.680658
epoch 3400, loss 0.522852
epoch 3500, loss 0.294279
epoch 3600, loss 0.23242
epoch 3700, loss 0.59618
epoch 3800, loss 0.560117
epoch 3900, loss 0.530557
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
43.9272 5.75821
36.7438 99.7431
47.4619 88.2272
47.4619 88.2272
3.22686 12.4233
parameters: [ 8.01   1.584  1.684  4.728  4.   ]. error: 1.89819439668.
----------------------------
epoch 0, loss 1.78295
epoch 100, loss 0.605571
epoch 200, loss 0.470717
epoch 300, loss 0.544031
epoch 400, loss 0.868046
epoch 500, loss 0.702981
epoch 600, loss 0.626074
epoch 700, loss 0.450221
epoch 800, loss 0.444173
epoch 900, loss 0.516271
epoch 1000, loss 0.393354
epoch 1100, loss 0.490836
epoch 1200, loss 0.677615
epoch 1300, loss 0.498771
epoch 1400, loss 0.434778
epoch 1500, loss 0.504037
epoch 1600, loss 0.769591
epoch 1700, loss 0.736917
epoch 1800, loss 0.55386
epoch 1900, loss 0.367198
epoch 2000, loss 0.579313
epoch 2100, loss 0.612189
epoch 2200, loss 0.454316
epoch 2300, loss 0.439119
epoch 2400, loss 0.971811
epoch 2500, loss 0.668767
epoch 2600, loss 0.32743
epoch 2700, loss 0.645898
epoch 2800, loss 0.652238
epoch 2900, loss 0.667492
epoch 3000, loss 0.439978
epoch 3100, loss 0.452882
epoch 3200, loss 0.817002
epoch 3300, loss 0.418979
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
209.705 43.3075
14.1268 19.9206
9.3969 22.23
45.3756 90.499
38.304 115.058
parameters: [ 8.01   1.584  1.684  4.728  3.382]. error: 0.672334513391.
----------------------------
epoch 0, loss 0.909588
epoch 100, loss 0.747052
epoch 200, loss 0.85188
epoch 300, loss 0.571748
epoch 400, loss 0.635411
epoch 500, loss 0.438471
epoch 600, loss 0.540101
epoch 700, loss 0.378475
epoch 800, loss 0.482112
epoch 900, loss 0.302807
epoch 1000, loss 0.678182
epoch 1100, loss 0.40432
epoch 1200, loss 0.555516
epoch 1300, loss 0.680151
epoch 1400, loss 0.401775
epoch 1500, loss 0.49433
epoch 1600, loss 0.646273
epoch 1700, loss 0.498621
epoch 1800, loss 0.303777
epoch 1900, loss 0.359298
epoch 2000, loss 0.412337
epoch 2100, loss 0.306824
epoch 2200, loss 1.00761
epoch 2300, loss 0.490716
epoch 2400, loss 0.556956
epoch 2500, loss 0.547623
epoch 2600, loss 0.602573
epoch 2700, loss 0.237906
epoch 2800, loss 0.303948
epoch 2900, loss 0.365532
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
45.3756 94.264
20.2755 29.1105
45.3756 94.264
70.3904 109.081
2.37471 22.0587
parameters: [ 8.01   1.584  1.684  4.728  3.   ]. error: 2.63385716085.
----------------------------
epoch 0, loss 1.591
epoch 100, loss 1.01675
epoch 200, loss 1.21087
epoch 300, loss 0.439582
epoch 400, loss 0.499392
epoch 500, loss 0.286885
epoch 600, loss 0.803024
epoch 700, loss 0.371761
epoch 800, loss 0.578153
epoch 900, loss 0.528166
epoch 1000, loss 0.505536
epoch 1100, loss 0.874191
epoch 1200, loss 0.737041
epoch 1300, loss 0.533161
epoch 1400, loss 0.495367
epoch 1500, loss 0.557027
epoch 1600, loss 0.511326
epoch 1700, loss 0.470814
epoch 1800, loss 0.42057
epoch 1900, loss 0.641368
epoch 2000, loss 0.308526
epoch 2100, loss 0.55402
epoch 2200, loss 0.380908
epoch 2300, loss 0.594755
epoch 2400, loss 0.654571
epoch 2500, loss 0.681518
epoch 2600, loss 0.775854
epoch 2700, loss 0.414435
epoch 2800, loss 0.885746
epoch 2900, loss 0.457048
epoch 3000, loss 0.823775
epoch 3100, loss 0.647958
epoch 3200, loss 0.395317
epoch 3300, loss 0.378465
epoch 3400, loss 0.777536
epoch 3500, loss 0.447938
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
89.2785 38.3744
37.0194 69.2576
305.167 135.475
259.052 89.7036
246.534 89.0327
parameters: [ 8.01   1.584  1.684  4.728  3.552]. error: 0.189597194199.
----------------------------
epoch 0, loss 1.70444
epoch 100, loss 0.641406
epoch 200, loss 0.680568
epoch 300, loss 0.477141
epoch 400, loss 0.483341
epoch 500, loss 0.974323
epoch 600, loss 0.843896
epoch 700, loss 0.761634
epoch 800, loss 0.422091
epoch 900, loss 0.399044
epoch 1000, loss 0.439678
epoch 1100, loss 0.311296
epoch 1200, loss 0.467947
epoch 1300, loss 0.807229
epoch 1400, loss 0.487561
epoch 1500, loss 0.41639
epoch 1600, loss 0.538543
epoch 1700, loss 0.29599
epoch 1800, loss 0.517779
epoch 1900, loss 0.790614
epoch 2000, loss 0.541539
epoch 2100, loss 1.09436
epoch 2200, loss 0.863292
epoch 2300, loss 0.692105
epoch 2400, loss 0.696106
epoch 2500, loss 0.839544
epoch 2600, loss 0.508679
epoch 2700, loss 0.288739
epoch 2800, loss 0.504715
epoch 2900, loss 0.508337
epoch 3000, loss 0.528193
epoch 3100, loss 0.604888
epoch 3200, loss 0.499053
epoch 3300, loss 0.728163
epoch 3400, loss 0.612418
epoch 3500, loss 0.292612
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
234.37 77.9429
109.588 66.1922
32.0605 87.7059
209.705 37.3048
69.8093 66.4267
parameters: [ 8.01   1.584  1.684  4.728  3.599]. error: 0.872996145938.
----------------------------
epoch 0, loss 1.27113
epoch 100, loss 0.947175
epoch 200, loss 0.679065
epoch 300, loss 0.813752
epoch 400, loss 0.520755
epoch 500, loss 0.521364
epoch 600, loss 0.447965
epoch 700, loss 0.394132
epoch 800, loss 0.403936
epoch 900, loss 0.361611
epoch 1000, loss 0.497985
epoch 1100, loss 0.332463
epoch 1200, loss 0.567405
epoch 1300, loss 0.723006
epoch 1400, loss 0.328789
epoch 1500, loss 0.900797
epoch 1600, loss 0.541157
epoch 1700, loss 0.55823
epoch 1800, loss 0.401723
epoch 1900, loss 0.373242
epoch 2000, loss 0.325733
epoch 2100, loss 0.354321
epoch 2200, loss 0.344252
epoch 2300, loss 0.438002
epoch 2400, loss 0.443161
epoch 2500, loss 0.640836
epoch 2600, loss 0.523689
epoch 2700, loss 0.303608
epoch 2800, loss 0.37143
epoch 2900, loss 0.399597
epoch 3000, loss 0.494138
epoch 3100, loss 0.44488
epoch 3200, loss 0.398237
epoch 3300, loss 0.45234
epoch 3400, loss 0.523114
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
57.0616 45.5442
1.11386 21.9266
282.053 115.14
109.588 61.2959
71.8482 50.8113
parameters: [ 8.01   1.584  1.684  4.728  3.485]. error: 17.2869621323.
----------------------------
epoch 0, loss 0.682616
epoch 100, loss 0.720632
epoch 200, loss 0.859668
epoch 300, loss 0.620099
epoch 400, loss 0.551936
epoch 500, loss 0.611721
epoch 600, loss 0.43711
epoch 700, loss 0.306187
epoch 800, loss 0.679387
epoch 900, loss 0.367928
epoch 1000, loss 0.60415
epoch 1100, loss 0.483574
epoch 1200, loss 0.951226
epoch 1300, loss 0.365171
epoch 1400, loss 0.349314
epoch 1500, loss 0.573231
epoch 1600, loss 0.342739
epoch 1700, loss 0.51408
epoch 1800, loss 0.556371
epoch 1900, loss 0.712699
epoch 2000, loss 0.559845
epoch 2100, loss 0.446345
epoch 2200, loss 0.527298
epoch 2300, loss 0.469686
epoch 2400, loss 0.596666
epoch 2500, loss 0.535486
epoch 2600, loss 0.534193
epoch 2700, loss 0.241404
epoch 2800, loss 0.45808
epoch 2900, loss 0.283182
epoch 3000, loss 0.577548
epoch 3100, loss 0.527001
epoch 3200, loss 0.562808
epoch 3300, loss 0.687886
epoch 3400, loss 0.502104
epoch 3500, loss 0.465427
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
19.4471 42.4362
23.1269 40.3129
53.6961 21.6929
28.3521 54.5328
605.821 273.939
parameters: [ 8.01   1.584  1.684  4.728  3.526]. error: 0.166737006386.
----------------------------
epoch 0, loss 1.57463
epoch 100, loss 1.69513
epoch 200, loss 0.900073
epoch 300, loss 0.712655
epoch 400, loss 0.508883
epoch 500, loss 0.644599
epoch 600, loss 0.473632
epoch 700, loss 0.679113
epoch 800, loss 0.521577
epoch 900, loss 0.408416
epoch 1000, loss 0.624453
epoch 1100, loss 0.445639
epoch 1200, loss 0.604859
epoch 1300, loss 0.350801
epoch 1400, loss 0.759721
epoch 1500, loss 0.463197
epoch 1600, loss 0.555723
epoch 1700, loss 0.528263
epoch 1800, loss 0.519709
epoch 1900, loss 0.495825
epoch 2000, loss 0.677491
epoch 2100, loss 0.711167
epoch 2200, loss 0.393128
epoch 2300, loss 0.289104
epoch 2400, loss 0.438084
epoch 2500, loss 0.648197
epoch 2600, loss 0.2855
epoch 2700, loss 0.508423
epoch 2800, loss 0.663674
epoch 2900, loss 0.546351
epoch 3000, loss 0.300228
epoch 3100, loss 0.356005
epoch 3200, loss 0.539626
epoch 3300, loss 0.33498
epoch 3400, loss 0.451083
epoch 3500, loss 0.599475
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
13.842 42.3197
94.9786 114.509
20.2755 44.7539
56.7553 38.3656
48.9224 38.3656
parameters: [ 8.01   1.584  1.684  4.728  3.521]. error: 0.190058048371.
----------------------------
epoch 0, loss 1.66808
epoch 100, loss 0.777292
epoch 200, loss 0.543438
epoch 300, loss 0.391282
epoch 400, loss 0.296204
epoch 500, loss 0.296505
epoch 600, loss 0.450614
epoch 700, loss 0.881559
epoch 800, loss 0.422619
epoch 900, loss 1.04957
epoch 1000, loss 0.697275
epoch 1100, loss 0.434337
epoch 1200, loss 0.399518
epoch 1300, loss 0.518918
epoch 1400, loss 0.339946
epoch 1500, loss 0.46443
epoch 1600, loss 0.290004
epoch 1700, loss 0.527661
epoch 1800, loss 0.371854
epoch 1900, loss 0.530645
epoch 2000, loss 0.380085
epoch 2100, loss 0.601458
epoch 2200, loss 0.475489
epoch 2300, loss 0.530734
epoch 2400, loss 0.504312
epoch 2500, loss 0.799783
epoch 2600, loss 0.592543
epoch 2700, loss 0.269802
epoch 2800, loss 0.301298
epoch 2900, loss 0.297524
epoch 3000, loss 0.464548
epoch 3100, loss 0.5899
epoch 3200, loss 0.298176
epoch 3300, loss 0.5426
epoch 3400, loss 0.630961
epoch 3500, loss 0.536488
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
109.588 80.7053
28.3521 95.0181
79.3243 23.1208
13.9704 36.8907
2.37471 21.6646
parameters: [ 8.01   1.584  1.684  4.728  3.537]. error: 2.73194844822.
----------------------------
epoch 0, loss 1.7699
epoch 100, loss 0.880038
epoch 200, loss 0.72779
epoch 300, loss 0.585597
epoch 400, loss 0.697666
epoch 500, loss 0.647341
epoch 600, loss 0.591138
epoch 700, loss 0.520395
epoch 800, loss 0.646347
epoch 900, loss 0.486189
epoch 1000, loss 0.513157
epoch 1100, loss 0.61838
epoch 1200, loss 0.776908
epoch 1300, loss 1.01016
epoch 1400, loss 0.560285
epoch 1500, loss 0.716929
epoch 1600, loss 0.441176
epoch 1700, loss 0.898196
epoch 1800, loss 0.463602
epoch 1900, loss 0.310818
epoch 2000, loss 0.393758
epoch 2100, loss 0.83845
epoch 2200, loss 0.691861
epoch 2300, loss 0.335499
epoch 2400, loss 0.426465
epoch 2500, loss 0.573523
epoch 2600, loss 0.387675
epoch 2700, loss 0.833227
epoch 2800, loss 0.579274
epoch 2900, loss 0.461679
epoch 3000, loss 0.843565
epoch 3100, loss 0.394994
epoch 3200, loss 0.254669
epoch 3300, loss 0.385645
epoch 3400, loss 0.611974
epoch 3500, loss 0.578762
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
244.06 133.916
13.7745 17.4147
32.0605 46.2751
20.2755 36.8575
70.3904 104.105
parameters: [ 8.01   1.584  1.684  4.728  3.531]. error: 0.089393703311.
----------------------------
epoch 0, loss 0.991807
epoch 100, loss 0.71327
epoch 200, loss 0.460003
epoch 300, loss 0.37429
epoch 400, loss 0.562128
epoch 500, loss 0.76714
epoch 600, loss 0.559515
epoch 700, loss 0.686663
epoch 800, loss 0.340787
epoch 900, loss 0.989762
epoch 1000, loss 0.405426
epoch 1100, loss 0.838022
epoch 1200, loss 0.568603
epoch 1300, loss 0.538042
epoch 1400, loss 0.503149
epoch 1500, loss 0.519953
epoch 1600, loss 0.525334
epoch 1700, loss 0.413998
epoch 1800, loss 0.605365
epoch 1900, loss 0.637793
epoch 2000, loss 0.60029
epoch 2100, loss 0.451445
epoch 2200, loss 0.466423
epoch 2300, loss 0.651788
epoch 2400, loss 0.470645
epoch 2500, loss 0.665025
epoch 2600, loss 0.511385
epoch 2700, loss 0.687803
epoch 2800, loss 0.332024
epoch 2900, loss 0.353057
epoch 3000, loss 0.58163
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
605.821 222.486
162.436 80.0498
9.3969 26.2558
246.534 98.7635
116.598 94.6113
parameters: [ 7.02   2.168  1.367  6.255  3.062]. error: 0.252848324467.
----------------------------
epoch 0, loss 1.0741
epoch 100, loss 0.467188
epoch 200, loss 0.54361
epoch 300, loss 0.940795
epoch 400, loss 0.321675
epoch 500, loss 0.395087
epoch 600, loss 0.404258
epoch 700, loss 0.598286
epoch 800, loss 0.536922
epoch 900, loss 0.710614
epoch 1000, loss 0.712019
epoch 1100, loss 0.747868
epoch 1200, loss 0.699799
epoch 1300, loss 0.536229
epoch 1400, loss 0.31001
epoch 1500, loss 0.458344
epoch 1600, loss 0.823399
epoch 1700, loss 0.35974
epoch 1800, loss 0.460302
epoch 1900, loss 0.481003
epoch 2000, loss 0.535334
epoch 2100, loss 0.391541
epoch 2200, loss 0.561292
epoch 2300, loss 0.377546
epoch 2400, loss 0.589595
epoch 2500, loss 0.777709
epoch 2600, loss 0.504641
epoch 2700, loss 0.652149
epoch 2800, loss 0.58106
epoch 2900, loss 0.450512
epoch 3000, loss 0.818895
epoch 3100, loss 0.350624
epoch 3200, loss 0.377824
epoch 3300, loss 0.808161
epoch 3400, loss 0.529453
epoch 3500, loss 0.406351
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
162.436 65.3856
56.7553 33.1254
127.381 59.3488
146.624 83.1238
6.15658 17.161
parameters: [ 8.01   1.584  1.684  4.728  3.531]. error: 0.226994951914.
----------------------------
epoch 0, loss 1.25214
epoch 100, loss 0.96916
epoch 200, loss 0.693652
epoch 300, loss 0.765333
epoch 400, loss 0.854923
epoch 500, loss 0.830555
epoch 600, loss 0.435554
epoch 700, loss 0.479445
epoch 800, loss 0.934858
epoch 900, loss 0.627441
epoch 1000, loss 0.728356
epoch 1100, loss 0.455653
epoch 1200, loss 0.580718
epoch 1300, loss 0.493132
epoch 1400, loss 0.585779
epoch 1500, loss 0.579078
epoch 1600, loss 0.571735
epoch 1700, loss 0.622618
epoch 1800, loss 0.521372
epoch 1900, loss 0.573138
epoch 2000, loss 0.600677
epoch 2100, loss 0.481509
epoch 2200, loss 0.448977
epoch 2300, loss 0.722361
epoch 2400, loss 0.49942
epoch 2500, loss 0.760088
epoch 2600, loss 0.807601
epoch 2700, loss 0.561289
epoch 2800, loss 0.522987
epoch 2900, loss 0.419817
epoch 3000, loss 0.39636
epoch 3100, loss 0.824213
epoch 3200, loss 0.666955
epoch 3300, loss 0.485625
epoch 3400, loss 0.319488
epoch 3500, loss 0.350839
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
13.2248 23.248
71.8482 115.034
43.9272 18.8322
112.36 116.907
33.7234 51.6326
parameters: [ 9.01   1.584  1.684  4.728  3.531]. error: 0.12406798712.
----------------------------
epoch 0, loss 2.04456
epoch 100, loss 0.681439
epoch 200, loss 0.814861
epoch 300, loss 0.538156
epoch 400, loss 0.547875
epoch 500, loss 0.450518
epoch 600, loss 0.417724
epoch 700, loss 0.765086
epoch 800, loss 0.475912
epoch 900, loss 0.595614
epoch 1000, loss 0.687601
epoch 1100, loss 0.590271
epoch 1200, loss 0.642488
epoch 1300, loss 0.444485
epoch 1400, loss 0.494827
epoch 1500, loss 0.482475
epoch 1600, loss 0.518112
epoch 1700, loss 0.702831
epoch 1800, loss 0.654167
epoch 1900, loss 0.598913
epoch 2000, loss 0.530721
epoch 2100, loss 0.451745
epoch 2200, loss 0.73965
epoch 2300, loss 0.402993
epoch 2400, loss 0.452781
epoch 2500, loss 0.501318
epoch 2600, loss 0.657519
epoch 2700, loss 0.641044
epoch 2800, loss 0.567722
epoch 2900, loss 0.626351
epoch 3000, loss 0.700051
epoch 3100, loss 0.361609
epoch 3200, loss 0.568072
epoch 3300, loss 0.486848
epoch 3400, loss 0.646078
epoch 3500, loss 0.682013
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
13.2248 17.1323
43.9272 2.21121
109.588 66.0058
460.913 120.216
13.9704 45.5905
parameters: [ 10.628   1.584   1.684   4.728   3.531]. error: 17.7819893559.
----------------------------
epoch 0, loss 1.6413
epoch 100, loss 0.5582
epoch 200, loss 0.632422
epoch 300, loss 0.511812
epoch 400, loss 0.555688
epoch 500, loss 0.375937
epoch 600, loss 0.727331
epoch 700, loss 0.5604
epoch 800, loss 0.744153
epoch 900, loss 0.334808
epoch 1000, loss 0.760174
epoch 1100, loss 0.611563
epoch 1200, loss 0.776765
epoch 1300, loss 0.448145
epoch 1400, loss 0.642767
epoch 1500, loss 0.577227
epoch 1600, loss 0.694106
epoch 1700, loss 0.72318
epoch 1800, loss 0.67477
epoch 1900, loss 0.618508
epoch 2000, loss 0.666421
epoch 2100, loss 0.462006
epoch 2200, loss 0.609782
epoch 2300, loss 0.709006
epoch 2400, loss 0.370574
epoch 2500, loss 0.854659
epoch 2600, loss 0.563655
epoch 2700, loss 0.349145
epoch 2800, loss 0.598097
epoch 2900, loss 0.393862
epoch 3000, loss 0.655761
epoch 3100, loss 0.38344
epoch 3200, loss 0.617617
epoch 3300, loss 0.465286
epoch 3400, loss 0.430438
epoch 3500, loss 0.649409
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
70.3904 118.507
70.2845 118.507
13.842 41.2037
32.9441 26.4372
209.705 33.9382
parameters: [ 9.01   1.584  1.684  4.728  3.531]. error: 1.10194831618.
----------------------------
epoch 0, loss 1.0264
epoch 100, loss 0.90769
epoch 200, loss 0.677004
epoch 300, loss 0.709459
epoch 400, loss 0.699904
epoch 500, loss 0.565069
epoch 600, loss 0.499753
epoch 700, loss 0.332658
epoch 800, loss 0.707082
epoch 900, loss 0.520508
epoch 1000, loss 0.645152
epoch 1100, loss 0.69543
epoch 1200, loss 0.424554
epoch 1300, loss 0.350726
epoch 1400, loss 0.53672
epoch 1500, loss 0.60067
epoch 1600, loss 0.321003
epoch 1700, loss 0.300431
epoch 1800, loss 0.365045
epoch 1900, loss 0.514882
epoch 2000, loss 0.720429
epoch 2100, loss 0.329333
epoch 2200, loss 0.492439
epoch 2300, loss 0.798877
epoch 2400, loss 0.402024
epoch 2500, loss 0.42144
epoch 2600, loss 0.624678
epoch 2700, loss 0.343346
epoch 2800, loss 0.513766
epoch 2900, loss 0.497874
epoch 3000, loss 0.728645
epoch 3100, loss 0.781277
epoch 3200, loss 0.643857
epoch 3300, loss 0.720537
epoch 3400, loss 0.521593
epoch 3500, loss 0.59773
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
38.4634 102.699
831.403 313.892
33.8136 29.0415
259.052 52.289
246.534 64.6059
parameters: [ 9.628  1.584  1.684  4.728  3.531]. error: 0.662804581616.
----------------------------
epoch 0, loss 1.36553
epoch 100, loss 0.750628
epoch 200, loss 0.838472
epoch 300, loss 0.759226
epoch 400, loss 0.710052
epoch 500, loss 0.613832
epoch 600, loss 0.497834
epoch 700, loss 0.534829
epoch 800, loss 0.366791
epoch 900, loss 0.425691
epoch 1000, loss 0.325443
epoch 1100, loss 0.722552
epoch 1200, loss 0.248103
epoch 1300, loss 0.345733
epoch 1400, loss 0.699486
epoch 1500, loss 0.799668
epoch 1600, loss 0.491314
epoch 1700, loss 0.590017
epoch 1800, loss 0.661001
epoch 1900, loss 0.724683
epoch 2000, loss 0.49503
epoch 2100, loss 0.408485
epoch 2200, loss 0.331923
epoch 2300, loss 0.593739
epoch 2400, loss 0.496894
epoch 2500, loss 0.448733
epoch 2600, loss 0.509807
epoch 2700, loss 0.371236
epoch 2800, loss 0.667851
epoch 2900, loss 0.492444
epoch 3000, loss 0.498169
epoch 3100, loss 0.808145
epoch 3200, loss 0.95384
epoch 3300, loss 0.458003
epoch 3400, loss 0.374363
epoch 3500, loss 0.516918
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
67.5897 95.2113
53.6961 26.2927
13.842 35.9821
33.8136 44.4817
53.6961 26.2927
parameters: [ 10.01    1.584   1.684   4.728   3.531]. error: 0.168551604134.
----------------------------
epoch 0, loss 0.983068
epoch 100, loss 1.06986
epoch 200, loss 0.643024
epoch 300, loss 0.8211
epoch 400, loss 0.816358
epoch 500, loss 0.771998
epoch 600, loss 0.543275
epoch 700, loss 0.803552
epoch 800, loss 0.393475
epoch 900, loss 0.422393
epoch 1000, loss 0.48427
epoch 1100, loss 0.739567
epoch 1200, loss 0.406057
epoch 1300, loss 0.504034
epoch 1400, loss 0.529741
epoch 1500, loss 0.354722
epoch 1600, loss 0.483383
epoch 1700, loss 0.491688
epoch 1800, loss 0.3886
epoch 1900, loss 0.603237
epoch 2000, loss 0.620101
epoch 2100, loss 0.660474
epoch 2200, loss 0.515723
epoch 2300, loss 0.381931
epoch 2400, loss 0.584863
epoch 2500, loss 0.386725
epoch 2600, loss 0.514223
epoch 2700, loss 0.406416
epoch 2800, loss 0.590616
epoch 2900, loss 0.515245
epoch 3000, loss 0.344763
epoch 3100, loss 0.388262
epoch 3200, loss 0.43681
epoch 3300, loss 0.616362
epoch 3400, loss 0.35218
epoch 3500, loss 0.532333
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
13.842 32.5812
96.1397 84.2894
106.094 36.7667
3167.53 741.706
21.6939 26.6287
parameters: [ 10.246   1.584   1.684   4.728   3.531]. error: 0.461898330138.
----------------------------
epoch 0, loss 1.14985
epoch 100, loss 0.67438
epoch 200, loss 0.967053
epoch 300, loss 0.625531
epoch 400, loss 0.519172
epoch 500, loss 0.692287
epoch 600, loss 0.770558
epoch 700, loss 0.586738
epoch 800, loss 0.277869
epoch 900, loss 0.471279
epoch 1000, loss 0.26116
epoch 1100, loss 0.507869
epoch 1200, loss 0.401213
epoch 1300, loss 0.612138
epoch 1400, loss 0.497789
epoch 1500, loss 0.530673
epoch 1600, loss 0.419422
epoch 1700, loss 0.863709
epoch 1800, loss 0.453629
epoch 1900, loss 0.688731
epoch 2000, loss 0.620401
epoch 2100, loss 0.718631
epoch 2200, loss 0.547822
epoch 2300, loss 0.438181
epoch 2400, loss 0.495334
epoch 2500, loss 0.474627
epoch 2600, loss 0.736381
epoch 2700, loss 0.431397
epoch 2800, loss 0.371638
epoch 2900, loss 0.512712
epoch 3000, loss 0.362247
epoch 3100, loss 0.555625
epoch 3200, loss 0.335719
epoch 3300, loss 0.464928
epoch 3400, loss 0.497985
epoch 3500, loss 0.399251
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
38.4634 249.681
127.381 104.025
109.588 104.025
13.2248 16.6201
37.0194 80.8206
parameters: [ 9.977  1.584  1.684  4.728  3.531]. error: 1.0901990672.
----------------------------
epoch 0, loss 1.46832
epoch 100, loss 0.752638
epoch 200, loss 0.982231
epoch 300, loss 1.13263
epoch 400, loss 0.540879
epoch 500, loss 0.786432
epoch 600, loss 0.830204
epoch 700, loss 0.620234
epoch 800, loss 0.926564
epoch 900, loss 0.496181
epoch 1000, loss 0.507621
epoch 1100, loss 0.644854
epoch 1200, loss 0.57324
epoch 1300, loss 0.58603
epoch 1400, loss 0.558099
epoch 1500, loss 0.736201
epoch 1600, loss 0.220944
epoch 1700, loss 0.467585
epoch 1800, loss 0.569989
epoch 1900, loss 0.406957
epoch 2000, loss 0.694236
epoch 2100, loss 0.426995
epoch 2200, loss 0.559755
epoch 2300, loss 0.618725
epoch 2400, loss 0.352946
epoch 2500, loss 0.422495
epoch 2600, loss 0.72632
epoch 2700, loss 0.606814
epoch 2800, loss 0.482006
epoch 2900, loss 0.705055
epoch 3000, loss 0.751002
epoch 3100, loss 0.448886
epoch 3200, loss 0.44169
epoch 3300, loss 0.375444
epoch 3400, loss 0.789854
epoch 3500, loss 0.553248
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
112.36 127.35
305.167 90.3803
33.8136 39.468
14.1268 17.5765
32.0605 99.3479
parameters: [ 10.03    1.584   1.684   4.728   3.531]. error: 0.378520563479.
----------------------------
epoch 0, loss 1.3948
epoch 100, loss 0.867545
epoch 200, loss 0.740987
epoch 300, loss 0.904454
epoch 400, loss 0.997168
epoch 500, loss 0.414053
epoch 600, loss 0.763427
epoch 700, loss 0.382212
epoch 800, loss 0.671026
epoch 900, loss 0.713478
epoch 1000, loss 0.389138
epoch 1100, loss 0.423252
epoch 1200, loss 0.68399
epoch 1300, loss 0.428373
epoch 1400, loss 0.335819
epoch 1500, loss 0.657207
epoch 1600, loss 0.314196
epoch 1700, loss 0.278505
epoch 1800, loss 0.769494
epoch 1900, loss 0.823103
epoch 2000, loss 0.670792
epoch 2100, loss 0.459329
epoch 2200, loss 0.638743
epoch 2300, loss 0.655018
epoch 2400, loss 0.427484
epoch 2500, loss 0.420724
epoch 2600, loss 0.514859
epoch 2700, loss 0.504024
epoch 2800, loss 0.242853
epoch 2900, loss 0.703654
epoch 3000, loss 0.764877
epoch 3100, loss 0.434562
epoch 3200, loss 0.662075
epoch 3300, loss 0.404497
epoch 3400, loss 0.687565
epoch 3500, loss 0.462921
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
10.5701 13.1105
282.053 390.847
56.7553 44.0573
146.624 105.604
45.3756 88.7877
parameters: [ 10.01    1.584   1.684   4.728   3.531]. error: 0.0762731508488.
----------------------------
epoch 0, loss 1.1594
epoch 100, loss 1.16039
epoch 200, loss 0.767892
epoch 300, loss 0.814887
epoch 400, loss 0.72906
epoch 500, loss 1.23862
epoch 600, loss 0.607402
epoch 700, loss 0.5159
epoch 800, loss 0.516516
epoch 900, loss 0.492267
epoch 1000, loss 0.499717
epoch 1100, loss 0.488438
epoch 1200, loss 0.567732
epoch 1300, loss 0.690303
epoch 1400, loss 0.44853
epoch 1500, loss 0.605414
epoch 1600, loss 0.794103
epoch 1700, loss 0.54319
epoch 1800, loss 0.637346
epoch 1900, loss 0.465635
epoch 2000, loss 0.447205
epoch 2100, loss 0.536624
epoch 2200, loss 0.695357
epoch 2300, loss 0.386887
epoch 2400, loss 0.584884
epoch 2500, loss 0.82032
epoch 2600, loss 0.724011
epoch 2700, loss 0.468983
epoch 2800, loss 0.50643
epoch 2900, loss 0.514705
epoch 3000, loss 1.37176
epoch 3100, loss 0.746509
epoch 3200, loss 0.691793
epoch 3300, loss 0.475889
epoch 3400, loss 0.590006
epoch 3500, loss 0.578813
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
3.22686 22.0146
40.0937 44.6749
28.3521 43.9294
10.5701 23.6608
23.1269 41.0752
parameters: [ 10.01    2.584   1.684   4.728   3.531]. error: 1.22333625502.
----------------------------
epoch 0, loss 1.51503
epoch 100, loss 0.481896
epoch 200, loss 0.399484
epoch 300, loss 0.272479
epoch 400, loss 0.6451
epoch 500, loss 0.366619
epoch 600, loss 0.367793
epoch 700, loss 0.364971
epoch 800, loss 0.325996
epoch 900, loss 0.259533
epoch 1000, loss 0.2234
epoch 1100, loss 0.381322
epoch 1200, loss 0.675559
epoch 1300, loss 0.373331
epoch 1400, loss 0.336389
epoch 1500, loss 0.298983
epoch 1600, loss 0.291845
epoch 1700, loss 0.276687
epoch 1800, loss 0.355871
epoch 1900, loss 0.498597
epoch 2000, loss 0.292438
epoch 2100, loss 0.282611
epoch 2200, loss 0.284541
epoch 2300, loss 0.306815
epoch 2400, loss 0.223415
epoch 2500, loss 0.336716
epoch 2600, loss 0.288282
epoch 2700, loss 0.233578
epoch 2800, loss 0.177465
epoch 2900, loss 0.300866
epoch 3000, loss 0.326941
epoch 3100, loss 0.30456
epoch 3200, loss 0.306805
epoch 3300, loss 0.430626
epoch 3400, loss 0.24251
epoch 3500, loss 0.323458
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
20.2755 23.1011
13.2248 16.1869
28.7444 54.0423
19.4471 42.7483
64.3569 68.8659
parameters: [ 10.01    0.034   1.684   4.728   3.531]. error: 0.08008309185.
----------------------------
epoch 0, loss 0.91886
epoch 100, loss 1.26537
epoch 200, loss 0.57126
epoch 300, loss 0.733981
epoch 400, loss 0.339325
epoch 500, loss 0.898702
epoch 600, loss 0.281564
epoch 700, loss 0.516345
epoch 800, loss 0.713061
epoch 900, loss 0.617985
epoch 1000, loss 0.418718
epoch 1100, loss 0.627519
epoch 1200, loss 0.511171
epoch 1300, loss 0.374621
epoch 1400, loss 0.404286
epoch 1500, loss 0.674486
epoch 1600, loss 0.342482
epoch 1700, loss 0.756936
epoch 1800, loss 0.37549
epoch 1900, loss 0.403362
epoch 2000, loss 0.401759
epoch 2100, loss 0.726021
epoch 2200, loss 0.351348
epoch 2300, loss 0.314393
epoch 2400, loss 0.442713
epoch 2500, loss 0.630765
epoch 2600, loss 0.45735
epoch 2700, loss 0.72182
epoch 2800, loss 0.709849
epoch 2900, loss 0.765206
epoch 3000, loss 0.705762
epoch 3100, loss 0.491214
epoch 3200, loss 0.493525
epoch 3300, loss 0.464838
epoch 3400, loss 0.363004
epoch 3500, loss 0.597716
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
57.0616 55.1775
45.3756 78.9121
36.7438 108.678
38.6549 26.9771
31.6796 31.8238
parameters: [ 10.01    1.584   1.684   4.728   3.531]. error: 0.175029031164.
----------------------------
epoch 0, loss 1.30868
epoch 100, loss 0.742967
epoch 200, loss 0.505953
epoch 300, loss 0.409449
epoch 400, loss 0.481192
epoch 500, loss 0.401324
epoch 600, loss 0.513115
epoch 700, loss 0.73359
epoch 800, loss 0.934337
epoch 900, loss 0.351118
epoch 1000, loss 0.446268
epoch 1100, loss 0.377324
epoch 1200, loss 0.719987
epoch 1300, loss 0.886555
epoch 1400, loss 0.671592
epoch 1500, loss 0.489593
epoch 1600, loss 0.288538
epoch 1700, loss 0.417424
epoch 1800, loss 0.558431
epoch 1900, loss 0.452579
epoch 2000, loss 0.368127
epoch 2100, loss 0.459035
epoch 2200, loss 0.44978
epoch 2300, loss 0.515884
epoch 2400, loss 0.385427
epoch 2500, loss 0.296321
epoch 2600, loss 0.492406
epoch 2700, loss 0.313728
epoch 2800, loss 0.808988
epoch 2900, loss 0.228266
epoch 3000, loss 0.340449
epoch 3100, loss 0.362254
epoch 3200, loss 0.524795
epoch 3300, loss 0.188084
epoch 3400, loss 0.20543
epoch 3500, loss 0.416763
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
64.3569 51.4753
21.6939 35.8809
116.598 52.0402
259.052 61.2557
70.2845 59.3511
parameters: [ 10.01    0.966   1.684   4.728   3.531]. error: 0.402971845652.
----------------------------
epoch 0, loss 1.36306
epoch 100, loss 1.34096
epoch 200, loss 0.81643
epoch 300, loss 0.894333
epoch 400, loss 0.840393
epoch 500, loss 0.876935
epoch 600, loss 1.09428
epoch 700, loss 1.39442
epoch 800, loss 0.992922
epoch 900, loss 0.735705
epoch 1000, loss 1.15923
epoch 1100, loss 0.707244
epoch 1200, loss 0.671318
epoch 1300, loss 0.807193
epoch 1400, loss 0.668861
epoch 1500, loss 0.662404
epoch 1600, loss 0.44704
epoch 1700, loss 0.378986
epoch 1800, loss 0.889546
epoch 1900, loss 0.696531
epoch 2000, loss 0.956983
epoch 2100, loss 0.489862
epoch 2200, loss 0.572471
epoch 2300, loss 0.561207
epoch 2400, loss 0.655094
epoch 2500, loss 0.511661
epoch 2600, loss 0.824468
epoch 2700, loss 0.719847
epoch 2800, loss 0.451852
epoch 2900, loss 0.829858
epoch 3000, loss 0.697555
epoch 3100, loss 0.478521
epoch 3200, loss 0.926588
epoch 3300, loss 0.700535
epoch 3400, loss 0.591788
epoch 3500, loss 0.523449
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
33.8136 36.094
23.1269 34.4101
57.0616 47.3874
305.167 122.749
116.598 66.9693
parameters: [ 10.01    1.966   1.684   4.728   3.531]. error: 0.124458197732.
----------------------------
epoch 0, loss 0.637626
epoch 100, loss 0.98779
epoch 200, loss 0.611463
epoch 300, loss 0.477547
epoch 400, loss 0.627595
epoch 500, loss 0.833964
epoch 600, loss 0.765018
epoch 700, loss 0.751356
epoch 800, loss 0.351913
epoch 900, loss 0.439112
epoch 1000, loss 0.869669
epoch 1100, loss 0.626916
epoch 1200, loss 0.595077
epoch 1300, loss 0.313175
epoch 1400, loss 0.392685
epoch 1500, loss 0.414861
epoch 1600, loss 0.543737
epoch 1700, loss 0.569434
epoch 1800, loss 0.593012
epoch 1900, loss 0.614446
epoch 2000, loss 0.429608
epoch 2100, loss 0.717772
epoch 2200, loss 0.747343
epoch 2300, loss 0.638537
epoch 2400, loss 0.568888
epoch 2500, loss 0.907972
epoch 2600, loss 0.650541
epoch 2700, loss 0.867733
epoch 2800, loss 0.685448
epoch 2900, loss 0.35144
epoch 3000, loss 0.5227
epoch 3100, loss 0.618848
epoch 3200, loss 0.877434
epoch 3300, loss 0.605935
epoch 3400, loss 0.469816
epoch 3500, loss 0.471418
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
9.3969 18.2827
32.9441 44.3314
33.7234 41.806
21.6939 36.0805
38.6549 15.8003
parameters: [ 10.01    2.055   1.684   4.728   3.531]. error: 0.146415785746.
----------------------------
epoch 0, loss 1.14484
epoch 100, loss 0.577424
epoch 200, loss 0.618498
epoch 300, loss 0.59617
epoch 400, loss 0.619015
epoch 500, loss 0.553914
epoch 600, loss 0.653053
epoch 700, loss 0.665579
epoch 800, loss 0.420642
epoch 900, loss 0.561882
epoch 1000, loss 0.674686
epoch 1100, loss 0.793778
epoch 1200, loss 0.710864
epoch 1300, loss 0.383002
epoch 1400, loss 0.40555
epoch 1500, loss 0.462264
epoch 1600, loss 0.560884
epoch 1700, loss 0.610406
epoch 1800, loss 0.616954
epoch 1900, loss 0.650089
epoch 2000, loss 0.746305
epoch 2100, loss 0.284379
epoch 2200, loss 0.41613
epoch 2300, loss 0.418927
epoch 2400, loss 0.681143
epoch 2500, loss 0.821499
epoch 2600, loss 0.459934
epoch 2700, loss 0.36125
epoch 2800, loss 0.461825
epoch 2900, loss 0.281371
epoch 3000, loss 0.582534
epoch 3100, loss 0.450985
epoch 3200, loss 0.423099
epoch 3300, loss 0.361841
epoch 3400, loss 0.582758
epoch 3500, loss 0.274884
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
109.588 46.6841
127.381 46.6841
259.052 69.1568
116.598 46.8133
13.2248 20.9491
parameters: [ 10.01    1.857   1.684   4.728   3.531]. error: 0.303150542901.
----------------------------
epoch 0, loss 1.17881
epoch 100, loss 1.42193
epoch 200, loss 0.79278
epoch 300, loss 0.679055
epoch 400, loss 0.830996
epoch 500, loss 0.547642
epoch 600, loss 0.578133
epoch 700, loss 0.882041
epoch 800, loss 0.724473
epoch 900, loss 0.516776
epoch 1000, loss 0.763076
epoch 1100, loss 0.370249
epoch 1200, loss 0.770429
epoch 1300, loss 0.686752
epoch 1400, loss 0.61483
epoch 1500, loss 0.644311
epoch 1600, loss 0.621897
epoch 1700, loss 0.555795
epoch 1800, loss 0.452435
epoch 1900, loss 0.650531
epoch 2000, loss 0.603986
epoch 2100, loss 0.564014
epoch 2200, loss 0.399965
epoch 2300, loss 1.32704
epoch 2400, loss 1.40223
epoch 2500, loss 0.594909
epoch 2600, loss 0.652731
epoch 2700, loss 0.475347
epoch 2800, loss 0.501407
epoch 2900, loss 0.709265
epoch 3000, loss 0.438333
epoch 3100, loss 0.576405
epoch 3200, loss 0.722359
epoch 3300, loss 0.483201
epoch 3400, loss 0.627123
epoch 3500, loss 0.458736
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
13.842 43.0439
282.053 189.709
57.0616 50.387
31.6796 42.0746
28.3521 50.7463
parameters: [ 10.01    1.924   1.684   4.728   3.531]. error: 0.19747533646.
----------------------------
epoch 0, loss 1.41727
epoch 100, loss 1.06972
epoch 200, loss 0.848213
epoch 300, loss 0.9527
epoch 400, loss 0.691436
epoch 500, loss 0.766475
epoch 600, loss 0.733313
epoch 700, loss 0.543924
epoch 800, loss 0.63102
epoch 900, loss 0.432348
epoch 1000, loss 0.685111
epoch 1100, loss 0.541548
epoch 1200, loss 0.636194
epoch 1300, loss 0.712961
epoch 1400, loss 0.480346
epoch 1500, loss 0.712091
epoch 1600, loss 0.789462
epoch 1700, loss 0.484585
epoch 1800, loss 0.941713
epoch 1900, loss 0.457957
epoch 2000, loss 0.337753
epoch 2100, loss 0.364523
epoch 2200, loss 0.371202
epoch 2300, loss 0.389641
epoch 2400, loss 0.34627
epoch 2500, loss 0.432217
epoch 2600, loss 0.599805
epoch 2700, loss 0.565703
epoch 2800, loss 0.389373
epoch 2900, loss 0.501827
epoch 3000, loss 0.584272
epoch 3100, loss 0.858296
epoch 3200, loss 0.581655
epoch 3300, loss 0.547307
epoch 3400, loss 0.679131
epoch 3500, loss 0.468527
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
3167.53 375.805
56.7553 36.0463
32.9279 65.826
9.3969 15.0967
64.3569 55.3422
parameters: [ 10.01    2.      1.684   4.728   3.531]. error: 2.11901738526.
----------------------------
epoch 0, loss 1.34463
epoch 100, loss 0.569019
epoch 200, loss 1.22639
epoch 300, loss 0.476927
epoch 400, loss 0.701559
epoch 500, loss 0.648012
epoch 600, loss 0.565467
epoch 700, loss 0.609357
epoch 800, loss 0.765351
epoch 900, loss 0.414491
epoch 1000, loss 0.710318
epoch 1100, loss 0.543239
epoch 1200, loss 0.524159
epoch 1300, loss 0.401533
epoch 1400, loss 0.745873
epoch 1500, loss 0.575476
epoch 1600, loss 0.662178
epoch 1700, loss 0.354543
epoch 1800, loss 0.431872
epoch 1900, loss 0.697536
epoch 2000, loss 0.396767
epoch 2100, loss 0.63824
epoch 2200, loss 0.500265
epoch 2300, loss 0.553102
epoch 2400, loss 0.585195
epoch 2500, loss 0.45202
epoch 2600, loss 0.276704
epoch 2700, loss 0.552873
epoch 2800, loss 0.683316
epoch 2900, loss 0.367046
epoch 3000, loss 0.707004
epoch 3100, loss 0.349446
epoch 3200, loss 0.512287
epoch 3300, loss 0.421898
epoch 3400, loss 0.529512
epoch 3500, loss 0.673673
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
127.381 56.0277
3.22686 15.3461
13.2248 18.4249
305.167 45.7975
282.053 308.183
parameters: [ 10.01    1.95    1.684   4.728   3.531]. error: 1.63936557132.
----------------------------
epoch 0, loss 1.53365
epoch 100, loss 0.796159
epoch 200, loss 0.484307
epoch 300, loss 0.80626
epoch 400, loss 0.73895
epoch 500, loss 1.0863
epoch 600, loss 0.598449
epoch 700, loss 0.536767
epoch 800, loss 0.641869
epoch 900, loss 0.609498
epoch 1000, loss 0.570254
epoch 1100, loss 0.39918
epoch 1200, loss 0.508101
epoch 1300, loss 0.5851
epoch 1400, loss 0.357042
epoch 1500, loss 0.473669
epoch 1600, loss 0.393907
epoch 1700, loss 0.408589
epoch 1800, loss 0.67428
epoch 1900, loss 0.634059
epoch 2000, loss 0.536604
epoch 2100, loss 0.678131
epoch 2200, loss 0.633149
epoch 2300, loss 0.39865
epoch 2400, loss 0.470825
epoch 2500, loss 0.453687
epoch 2600, loss 0.493047
epoch 2700, loss 0.395648
epoch 2800, loss 0.599996
epoch 2900, loss 0.601737
epoch 3000, loss 0.639424
epoch 3100, loss 0.634872
epoch 3200, loss 0.489586
epoch 3300, loss 0.688262
epoch 3400, loss 0.574589
epoch 3500, loss 0.546483
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
32.9279 81.0146
32.0605 57.0833
127.381 79.1995
38.4634 113.227
831.403 189.894
parameters: [ 10.01    1.979   1.684   4.728   3.531]. error: 0.549777745095.
----------------------------
epoch 0, loss 1.22912
epoch 100, loss 0.804709
epoch 200, loss 0.65012
epoch 300, loss 0.745217
epoch 400, loss 0.578657
epoch 500, loss 0.688077
epoch 600, loss 0.584584
epoch 700, loss 0.564412
epoch 800, loss 0.499032
epoch 900, loss 0.39961
epoch 1000, loss 0.781651
epoch 1100, loss 0.513067
epoch 1200, loss 0.598018
epoch 1300, loss 0.473331
epoch 1400, loss 0.572061
epoch 1500, loss 0.56677
epoch 1600, loss 0.360565
epoch 1700, loss 0.647354
epoch 1800, loss 0.71955
epoch 1900, loss 0.158076
epoch 2000, loss 0.628694
epoch 2100, loss 0.537871
epoch 2200, loss 0.44968
epoch 2300, loss 0.51512
epoch 2400, loss 0.58022
epoch 2500, loss 0.339689
epoch 2600, loss 0.633759
epoch 2700, loss 0.639345
epoch 2800, loss 0.465649
epoch 2900, loss 0.476227
epoch 3000, loss 0.490229
epoch 3100, loss 0.557943
epoch 3200, loss 0.499198
epoch 3300, loss 0.658673
epoch 3400, loss 0.80149
epoch 3500, loss 0.467701
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
47.4619 74.5865
28.3521 71.2214
116.598 74.5865
19.4471 35.451
14.1268 21.5378
parameters: [ 10.01    1.96    1.684   4.728   3.531]. error: 0.13056877618.
----------------------------
epoch 0, loss 0.968614
epoch 100, loss 0.786159
epoch 200, loss 0.555718
epoch 300, loss 0.836781
epoch 400, loss 0.449326
epoch 500, loss 0.539864
epoch 600, loss 0.586203
epoch 700, loss 0.603688
epoch 800, loss 0.669468
epoch 900, loss 0.741792
epoch 1000, loss 0.634121
epoch 1100, loss 0.439833
epoch 1200, loss 0.338479
epoch 1300, loss 0.373405
epoch 1400, loss 0.518023
epoch 1500, loss 0.509384
epoch 1600, loss 0.451358
epoch 1700, loss 0.628173
epoch 1800, loss 0.385014
epoch 1900, loss 0.483905
epoch 2000, loss 0.754987
epoch 2100, loss 0.256666
epoch 2200, loss 0.608729
epoch 2300, loss 0.287567
epoch 2400, loss 0.579748
epoch 2500, loss 0.58078
epoch 2600, loss 0.367657
epoch 2700, loss 0.326004
epoch 2800, loss 0.576823
epoch 2900, loss 0.732179
epoch 3000, loss 0.519629
epoch 3100, loss 0.689042
epoch 3200, loss 0.261057
epoch 3300, loss 0.685176
epoch 3400, loss 0.508725
epoch 3500, loss 0.764588
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
89.7385 352.356
94.9786 90.0933
2.37471 22.5273
13.842 34.1295
70.2845 89.1756
parameters: [ 10.01    1.971   1.684   4.728   3.531]. error: 2.78311130571.
----------------------------
epoch 0, loss 0.588368
epoch 100, loss 0.685003
epoch 200, loss 0.941467
epoch 300, loss 0.920826
epoch 400, loss 0.6434
epoch 500, loss 0.520493
epoch 600, loss 1.12955
epoch 700, loss 0.606941
epoch 800, loss 0.575139
epoch 900, loss 0.591442
epoch 1000, loss 0.600263
epoch 1100, loss 0.73947
epoch 1200, loss 0.294349
epoch 1300, loss 0.592766
epoch 1400, loss 0.507805
epoch 1500, loss 0.458163
epoch 1600, loss 0.46085
epoch 1700, loss 0.511237
epoch 1800, loss 0.528036
epoch 1900, loss 0.54679
epoch 2000, loss 0.322803
epoch 2100, loss 0.599541
epoch 2200, loss 0.591076
epoch 2300, loss 0.71721
epoch 2400, loss 0.802867
epoch 2500, loss 0.378489
epoch 2600, loss 0.409028
epoch 2700, loss 0.542991
epoch 2800, loss 0.504386
epoch 2900, loss 0.651306
epoch 3000, loss 0.519201
epoch 3100, loss 0.584564
epoch 3200, loss 0.525067
epoch 3300, loss 0.410328
epoch 3400, loss 0.467283
epoch 3500, loss 0.581489
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
126.871 404.791
282.053 396.028
32.0605 127.581
112.36 83.4581
47.4619 74.262
parameters: [ 10.01    1.966   1.684   4.728   3.531]. error: 0.33692238731.
----------------------------
epoch 0, loss 1.41846
epoch 100, loss 1.61245
epoch 200, loss 0.599345
epoch 300, loss 0.716502
epoch 400, loss 0.962996
epoch 500, loss 0.458561
epoch 600, loss 0.913458
epoch 700, loss 0.560996
epoch 800, loss 0.898417
epoch 900, loss 0.33143
epoch 1000, loss 0.60654
epoch 1100, loss 0.768575
epoch 1200, loss 0.926382
epoch 1300, loss 0.888851
epoch 1400, loss 1.00117
epoch 1500, loss 0.797992
epoch 1600, loss 0.87063
epoch 1700, loss 0.631882
epoch 1800, loss 0.581902
epoch 1900, loss 0.520807
epoch 2000, loss 0.630686
epoch 2100, loss 0.612643
epoch 2200, loss 0.737826
epoch 2300, loss 0.982615
epoch 2400, loss 1.01177
epoch 2500, loss 0.455983
epoch 2600, loss 0.586723
epoch 2700, loss 0.609384
epoch 2800, loss 0.698773
epoch 2900, loss 1.03999
epoch 3000, loss 0.892877
epoch 3100, loss 0.841526
epoch 3200, loss 0.878557
epoch 3300, loss 0.611344
epoch 3400, loss 0.739939
epoch 3500, loss 0.450929
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
70.3904 88.6421
45.3756 67.91
112.36 88.6421
89.7385 128.287
57.0616 41.7926
parameters: [ 10.01    1.966   2.684   4.728   3.531]. error: 0.0491845092674.
----------------------------
epoch 0, loss 1.06248
epoch 100, loss 1.08095
epoch 200, loss 1.46444
epoch 300, loss 0.994927
epoch 400, loss 1.35577
epoch 500, loss 1.39456
epoch 600, loss 1.81171
epoch 700, loss 1.51335
epoch 800, loss 1.10233
epoch 900, loss 1.6473
epoch 1000, loss 0.964097
epoch 1100, loss 1.13092
epoch 1200, loss 1.64174
epoch 1300, loss 1.37745
epoch 1400, loss 1.74908
epoch 1500, loss 1.16388
epoch 1600, loss 1.5986
epoch 1700, loss 1.62547
epoch 1800, loss 1.31219
epoch 1900, loss 1.26997
epoch 2000, loss 0.73193
epoch 2100, loss 0.980532
epoch 2200, loss 0.687808
epoch 2300, loss 0.892679
epoch 2400, loss 1.3074
epoch 2500, loss 1.46608
epoch 2600, loss 1.20846
epoch 2700, loss 0.340137
epoch 2800, loss 1.14416
epoch 2900, loss 0.764551
epoch 3000, loss 0.991591
epoch 3100, loss 0.913794
epoch 3200, loss 1.2688
epoch 3300, loss 1.46358
epoch 3400, loss 1.16258
epoch 3500, loss 1.16614
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
89.2785 42.0523
6.15658 39.6605
67.5897 44.0939
586.598 41.3011
71.8482 42.1066
parameters: [ 10.01    1.966   4.302   4.728   3.531]. error: 8.65563544966.
----------------------------
epoch 0, loss 1.53079
epoch 100, loss 1.42843
epoch 200, loss 0.756963
epoch 300, loss 0.611592
epoch 400, loss 1.39065
epoch 500, loss 0.84095
epoch 600, loss 0.76266
epoch 700, loss 0.649081
epoch 800, loss 0.611492
epoch 900, loss 1.11083
epoch 1000, loss 0.670003
epoch 1100, loss 0.436575
epoch 1200, loss 0.800671
epoch 1300, loss 0.837876
epoch 1400, loss 0.580303
epoch 1500, loss 0.555202
epoch 1600, loss 0.515192
epoch 1700, loss 0.681399
epoch 1800, loss 0.781386
epoch 1900, loss 0.708101
epoch 2000, loss 0.761601
epoch 2100, loss 0.515125
epoch 2200, loss 0.381335
epoch 2300, loss 0.462067
epoch 2400, loss 0.408463
epoch 2500, loss 0.563019
epoch 2600, loss 0.531699
epoch 2700, loss 0.893717
epoch 2800, loss 0.695052
epoch 2900, loss 0.322489
epoch 3000, loss 0.855876
epoch 3100, loss 0.866901
epoch 3200, loss 0.77244
epoch 3300, loss 0.89638
epoch 3400, loss 0.380165
epoch 3500, loss 0.706225
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
244.06 127.196
109.588 63.0716
13.842 37.054
1321.38 667.674
38.6549 22.7794
parameters: [ 10.01    1.966   2.684   4.728   3.531]. error: 0.172345382335.
----------------------------
epoch 0, loss 0.946104
epoch 100, loss 1.22989
epoch 200, loss 0.76558
epoch 300, loss 1.18943
epoch 400, loss 1.41242
epoch 500, loss 0.999448
epoch 600, loss 1.10617
epoch 700, loss 0.94051
epoch 800, loss 0.981937
epoch 900, loss 0.833351
epoch 1000, loss 1.17136
epoch 1100, loss 0.960278
epoch 1200, loss 1.3165
epoch 1300, loss 1.09879
epoch 1400, loss 1.058
epoch 1500, loss 0.982742
epoch 1600, loss 1.07664
epoch 1700, loss 1.24165
epoch 1800, loss 1.39779
epoch 1900, loss 1.07123
epoch 2000, loss 0.840186
epoch 2100, loss 0.97103
epoch 2200, loss 0.88538
epoch 2300, loss 0.886103
epoch 2400, loss 0.942751
epoch 2500, loss 0.866409
epoch 2600, loss 1.03821
epoch 2700, loss 1.37231
epoch 2800, loss 0.738569
epoch 2900, loss 0.61285
epoch 3000, loss 1.49766
epoch 3100, loss 1.14921
epoch 3200, loss 0.734178
epoch 3300, loss 1.07345
epoch 3400, loss 0.608871
epoch 3500, loss 0.914429
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
19.4471 45.6987
33.8136 45.9234
194.962 91.2382
28.3521 76.8156
10.5701 43.509
parameters: [ 10.01    1.966   3.302   4.728   3.531]. error: 0.410500576028.
----------------------------
epoch 0, loss 0.830122
epoch 100, loss 0.712255
epoch 200, loss 0.752541
epoch 300, loss 1.54036
epoch 400, loss 1.06781
epoch 500, loss 0.579845
epoch 600, loss 1.22517
epoch 700, loss 0.666312
epoch 800, loss 0.767466
epoch 900, loss 1.04722
epoch 1000, loss 0.705281
epoch 1100, loss 0.465825
epoch 1200, loss 0.61181
epoch 1300, loss 0.664779
epoch 1400, loss 0.850545
epoch 1500, loss 0.647723
epoch 1600, loss 0.708269
epoch 1700, loss 0.866982
epoch 1800, loss 0.543051
epoch 1900, loss 0.533632
epoch 2000, loss 0.869769
epoch 2100, loss 0.992147
epoch 2200, loss 0.738102
epoch 2300, loss 0.820832
epoch 2400, loss 0.53147
epoch 2500, loss 0.493782
epoch 2600, loss 0.555771
epoch 2700, loss 0.612621
epoch 2800, loss 0.686669
epoch 2900, loss 0.674106
epoch 3000, loss 0.427553
epoch 3100, loss 0.507525
epoch 3200, loss 0.778919
epoch 3300, loss 0.817344
epoch 3400, loss 0.286309
epoch 3500, loss 0.734694
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
246.534 52.8271
57.0616 63.3173
13.9704 42.578
101.017 246.155
1321.38 457.296
parameters: [ 10.01    1.966   2.302   4.728   3.531]. error: 0.632651108158.
----------------------------
epoch 0, loss 1.25827
epoch 100, loss 1.24892
epoch 200, loss 0.737532
epoch 300, loss 0.952484
epoch 400, loss 0.97122
epoch 500, loss 1.37673
epoch 600, loss 1.08887
epoch 700, loss 0.893208
epoch 800, loss 1.32335
epoch 900, loss 1.24746
epoch 1000, loss 1.11364
epoch 1100, loss 1.28806
epoch 1200, loss 1.05451
epoch 1300, loss 1.10582
epoch 1400, loss 1.02046
epoch 1500, loss 1.1834
epoch 1600, loss 1.24189
epoch 1700, loss 0.816793
epoch 1800, loss 1.08385
epoch 1900, loss 0.815105
epoch 2000, loss 1.37043
epoch 2100, loss 1.12552
epoch 2200, loss 1.03209
epoch 2300, loss 0.95739
epoch 2400, loss 0.977405
epoch 2500, loss 1.11234
epoch 2600, loss 1.07786
epoch 2700, loss 1.38312
epoch 2800, loss 0.779555
epoch 2900, loss 1.40315
epoch 3000, loss 0.832995
epoch 3100, loss 1.06631
epoch 3200, loss 0.917812
epoch 3300, loss 1.40483
epoch 3400, loss 1.02105
epoch 3500, loss 0.898856
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
43.9272 55.2516
10.5701 54.2462
109.588 61.6415
19.4471 54.8958
48.9224 54.8764
parameters: [ 10.01    1.966   2.871   4.728   3.531]. error: 0.638795887003.
----------------------------
epoch 0, loss 1.43072
epoch 100, loss 0.97302
epoch 200, loss 1.35182
epoch 300, loss 0.72993
epoch 400, loss 1.18327
epoch 500, loss 1.14929
epoch 600, loss 0.89646
epoch 700, loss 1.30579
epoch 800, loss 1.10212
epoch 900, loss 0.726969
epoch 1000, loss 1.11203
epoch 1100, loss 0.665232
epoch 1200, loss 0.596192
epoch 1300, loss 1.01938
epoch 1400, loss 0.557053
epoch 1500, loss 0.636142
epoch 1600, loss 0.576839
epoch 1700, loss 0.43799
epoch 1800, loss 0.510718
epoch 1900, loss 0.361329
epoch 2000, loss 0.681443
epoch 2100, loss 0.861101
epoch 2200, loss 0.549412
epoch 2300, loss 0.482582
epoch 2400, loss 0.421427
epoch 2500, loss 0.519857
epoch 2600, loss 0.732533
epoch 2700, loss 0.584239
epoch 2800, loss 0.624105
epoch 2900, loss 1.04743
epoch 3000, loss 0.314852
epoch 3100, loss 0.700815
epoch 3200, loss 0.454745
epoch 3300, loss 0.740912
epoch 3400, loss 0.500408
epoch 3500, loss 0.749287
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
57.0616 52.7024
47.6327 40.7798
282.053 146.835
33.8136 41.4275
79.3243 23.5881
parameters: [ 10.01    1.966   2.674   4.728   3.531]. error: 0.224002143558.
----------------------------
epoch 0, loss 0.715089
epoch 100, loss 0.520245
epoch 200, loss 0.893368
epoch 300, loss 0.882814
epoch 400, loss 0.986666
epoch 500, loss 1.04172
epoch 600, loss 0.938825
epoch 700, loss 0.778159
epoch 800, loss 0.877348
epoch 900, loss 0.748053
epoch 1000, loss 0.704406
epoch 1100, loss 0.785286
epoch 1200, loss 0.846254
epoch 1300, loss 1.13342
epoch 1400, loss 0.917789
epoch 1500, loss 0.676669
epoch 1600, loss 0.571581
epoch 1700, loss 0.76871
epoch 1800, loss 0.945963
epoch 1900, loss 0.810828
epoch 2000, loss 0.587198
epoch 2100, loss 0.574947
epoch 2200, loss 0.666349
epoch 2300, loss 0.842433
epoch 2400, loss 0.6867
epoch 2500, loss 0.51857
epoch 2600, loss 0.608452
epoch 2700, loss 0.751238
epoch 2800, loss 0.981151
epoch 2900, loss 0.615617
epoch 3000, loss 0.784517
epoch 3100, loss 0.626969
epoch 3200, loss 0.923093
epoch 3300, loss 1.04005
epoch 3400, loss 0.533329
epoch 3500, loss 1.18214
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
101.017 146.266
101.017 146.266
32.9279 78.2037
89.7385 256.625
460.913 52.333
parameters: [ 10.01    1.966   2.755   4.728   3.531]. error: 2.440298025.
----------------------------
epoch 0, loss 0.984478
epoch 100, loss 0.791755
epoch 200, loss 0.866942
epoch 300, loss 1.04946
epoch 400, loss 1.07054
epoch 500, loss 0.732829
epoch 600, loss 1.22185
epoch 700, loss 0.912562
epoch 800, loss 1.02277
epoch 900, loss 0.875654
epoch 1000, loss 0.885752
epoch 1100, loss 1.04225
epoch 1200, loss 1.8353
epoch 1300, loss 0.827875
epoch 1400, loss 1.05228
epoch 1500, loss 0.648938
epoch 1600, loss 1.21157
epoch 1700, loss 0.726327
epoch 1800, loss 0.55382
epoch 1900, loss 0.86063
epoch 2000, loss 1.22068
epoch 2100, loss 0.8952
epoch 2200, loss 0.818925
epoch 2300, loss 1.05954
epoch 2400, loss 0.72004
epoch 2500, loss 0.590468
epoch 2600, loss 0.814712
epoch 2700, loss 1.39562
epoch 2800, loss 0.686223
epoch 2900, loss 0.808317
epoch 3000, loss 0.725773
epoch 3100, loss 0.537961
epoch 3200, loss 0.799696
epoch 3300, loss 0.808221
epoch 3400, loss 0.970473
epoch 3500, loss 0.533451
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
38.6549 29.9044
106.094 45.8834
39.4136 37.0393
25.6565 45.8816
23.1269 51.0169
parameters: [ 10.01    1.966   2.711   4.728   3.531]. error: 0.153575588528.
----------------------------
epoch 0, loss 1.48741
epoch 100, loss 0.855197
epoch 200, loss 0.615469
epoch 300, loss 1.14476
epoch 400, loss 0.753951
epoch 500, loss 0.652069
epoch 600, loss 1.10876
epoch 700, loss 0.817508
epoch 800, loss 0.84398
epoch 900, loss 0.643621
epoch 1000, loss 0.953479
epoch 1100, loss 0.566442
epoch 1200, loss 0.71453
epoch 1300, loss 0.644221
epoch 1400, loss 0.826425
epoch 1500, loss 0.793915
epoch 1600, loss 0.612104
epoch 1700, loss 0.625243
epoch 1800, loss 0.955441
epoch 1900, loss 0.771217
epoch 2000, loss 0.822804
epoch 2100, loss 0.666955
epoch 2200, loss 0.794484
epoch 2300, loss 1.18207
epoch 2400, loss 0.653211
epoch 2500, loss 0.933715
epoch 2600, loss 0.457923
epoch 2700, loss 0.913763
epoch 2800, loss 0.673895
epoch 2900, loss 0.828414
epoch 3000, loss 0.588319
epoch 3100, loss 0.54808
epoch 3200, loss 0.910874
epoch 3300, loss 0.803536
epoch 3400, loss 0.702582
epoch 3500, loss 0.951654
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
3167.53 125.26
28.3521 43.3429
57.0616 67.0173
89.7385 132.868
20.2755 51.8785
parameters: [ 10.01    1.966   2.721   4.728   3.531]. error: 32.2612951076.
----------------------------
epoch 0, loss 1.13263
epoch 100, loss 1.12211
epoch 200, loss 0.772201
epoch 300, loss 0.53692
epoch 400, loss 0.779146
epoch 500, loss 1.11043
epoch 600, loss 0.917518
epoch 700, loss 1.05515
epoch 800, loss 0.825701
epoch 900, loss 1.28418
epoch 1000, loss 0.729214
epoch 1100, loss 1.00172
epoch 1200, loss 1.23749
epoch 1300, loss 0.768766
epoch 1400, loss 1.07731
epoch 1500, loss 1.12037
epoch 1600, loss 1.0942
epoch 1700, loss 0.781722
epoch 1800, loss 0.751709
epoch 1900, loss 0.470204
epoch 2000, loss 0.582716
epoch 2100, loss 0.668653
epoch 2200, loss 0.837713
epoch 2300, loss 1.32661
epoch 2400, loss 0.874425
epoch 2500, loss 0.545414
epoch 2600, loss 1.11727
epoch 2700, loss 0.65228
epoch 2800, loss 0.662724
epoch 2900, loss 0.846433
epoch 3000, loss 1.26049
epoch 3100, loss 0.627357
epoch 3200, loss 0.564472
epoch 3300, loss 1.05547
epoch 3400, loss 0.524141
epoch 3500, loss 0.615289
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
2.37471 33.6711
94.9786 63.1988
116.598 65.9414
10.5701 36.5549
3.22686 33.83
parameters: [ 10.01    1.966   2.701   4.728   3.531]. error: 7.61194435769.
----------------------------
epoch 0, loss 1.63285
epoch 100, loss 1.62579
epoch 200, loss 1.22008
epoch 300, loss 1.39751
epoch 400, loss 0.980674
epoch 500, loss 0.795405
epoch 600, loss 0.632038
epoch 700, loss 0.960913
epoch 800, loss 0.627377
epoch 900, loss 1.40161
epoch 1000, loss 0.744814
epoch 1100, loss 0.993404
epoch 1200, loss 0.496595
epoch 1300, loss 0.750672
epoch 1400, loss 0.706027
epoch 1500, loss 0.723584
epoch 1600, loss 0.78549
epoch 1700, loss 0.831352
epoch 1800, loss 0.783082
epoch 1900, loss 1.00382
epoch 2000, loss 0.741296
epoch 2100, loss 0.678921
epoch 2200, loss 0.810843
epoch 2300, loss 0.779177
epoch 2400, loss 0.80445
epoch 2500, loss 0.465707
epoch 2600, loss 0.583314
epoch 2700, loss 0.595091
epoch 2800, loss 0.770387
epoch 2900, loss 0.406365
epoch 3000, loss 0.576673
epoch 3100, loss 0.656032
epoch 3200, loss 0.867239
epoch 3300, loss 0.807511
epoch 3400, loss 0.747319
epoch 3500, loss 0.460631
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
101.017 127.238
28.7444 51.6125
70.3904 82.4121
244.06 172.765
36.7438 84.8612
parameters: [ 10.01    1.966   2.711   4.728   3.531]. error: 0.104780636273.
----------------------------
epoch 0, loss 0.883618
epoch 100, loss 0.893728
epoch 200, loss 1.07985
epoch 300, loss 1.03441
epoch 400, loss 0.898127
epoch 500, loss 0.936257
epoch 600, loss 0.795265
epoch 700, loss 1.07292
epoch 800, loss 0.778387
epoch 900, loss 1.29202
epoch 1000, loss 0.702795
epoch 1100, loss 0.770334
epoch 1200, loss 0.730685
epoch 1300, loss 0.935945
epoch 1400, loss 0.915823
epoch 1500, loss 0.846123
epoch 1600, loss 0.989545
epoch 1700, loss 0.596008
epoch 1800, loss 0.618693
epoch 1900, loss 0.562881
epoch 2000, loss 0.64786
epoch 2100, loss 0.607057
epoch 2200, loss 0.702141
epoch 2300, loss 0.592488
epoch 2400, loss 0.595899
epoch 2500, loss 0.531049
epoch 2600, loss 0.794252
epoch 2700, loss 0.663842
epoch 2800, loss 0.648373
epoch 2900, loss 0.726116
epoch 3000, loss 0.779507
epoch 3100, loss 0.658812
epoch 3200, loss 0.698661
epoch 3300, loss 0.707878
epoch 3400, loss 0.490012
epoch 3500, loss 0.7248
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
13.2248 30.0724
22.953 30.1926
116.598 68.6824
32.9279 67.0053
20.2734 36.6214
parameters: [ 10.01    1.966   2.711   5.728   3.531]. error: 0.115523259124.
----------------------------
epoch 0, loss 1.92134
epoch 100, loss 1.17508
epoch 200, loss 1.01683
epoch 300, loss 0.876446
epoch 400, loss 0.737553
epoch 500, loss 1.03716
epoch 600, loss 1.34957
epoch 700, loss 0.898329
epoch 800, loss 0.93141
epoch 900, loss 0.665165
epoch 1000, loss 1.13438
epoch 1100, loss 0.531932
epoch 1200, loss 1.33497
epoch 1300, loss 0.499312
epoch 1400, loss 0.88731
epoch 1500, loss 1.07397
epoch 1600, loss 0.993635
epoch 1700, loss 0.612124
epoch 1800, loss 1.14136
epoch 1900, loss 0.870394
epoch 2000, loss 0.627909
epoch 2100, loss 0.648065
epoch 2200, loss 0.891737
epoch 2300, loss 0.80868
epoch 2400, loss 0.29227
epoch 2500, loss 0.629797
epoch 2600, loss 0.43386
epoch 2700, loss 0.529114
epoch 2800, loss 0.538786
epoch 2900, loss 0.532676
epoch 3000, loss 0.956125
epoch 3100, loss 0.828675
epoch 3200, loss 0.492851
epoch 3300, loss 0.891728
epoch 3400, loss 0.37476
epoch 3500, loss 0.591492
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
101.017 209.706
57.0616 59.6704
246.534 89.7588
38.304 70.6109
67.5897 106.744
parameters: [ 10.01    1.966   2.711   3.11    3.531]. error: 0.187119436811.
----------------------------
epoch 0, loss 1.13094
epoch 100, loss 1.26287
epoch 200, loss 0.813656
epoch 300, loss 0.783966
epoch 400, loss 0.960859
epoch 500, loss 0.837361
epoch 600, loss 1.12712
epoch 700, loss 0.939051
epoch 800, loss 1.14972
epoch 900, loss 1.19428
epoch 1000, loss 0.900537
epoch 1100, loss 0.60561
epoch 1200, loss 0.777315
epoch 1300, loss 0.722829
epoch 1400, loss 0.834282
epoch 1500, loss 1.31341
epoch 1600, loss 0.730736
epoch 1700, loss 1.04396
epoch 1800, loss 0.993976
epoch 1900, loss 0.81013
epoch 2000, loss 0.627118
epoch 2100, loss 0.504685
epoch 2200, loss 0.625055
epoch 2300, loss 0.433009
epoch 2400, loss 0.639019
epoch 2500, loss 0.817052
epoch 2600, loss 0.63316
epoch 2700, loss 0.753548
epoch 2800, loss 0.755805
epoch 2900, loss 0.571928
epoch 3000, loss 0.650349
epoch 3100, loss 0.836911
epoch 3200, loss 0.464164
epoch 3300, loss 0.604886
epoch 3400, loss 0.683511
epoch 3500, loss 0.858995
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
28.3521 69.2501
21.6939 42.1343
21.6939 42.1343
259.052 90.9323
32.9279 97.2136
parameters: [ 10.01    1.966   2.711   4.728   3.531]. error: 0.286749375096.
----------------------------
epoch 0, loss 1.8875
epoch 100, loss 1.33929
epoch 200, loss 1.46669
epoch 300, loss 1.41062
epoch 400, loss 1.00922
epoch 500, loss 1.09129
epoch 600, loss 1.15073
epoch 700, loss 0.89555
epoch 800, loss 1.24659
epoch 900, loss 0.776116
epoch 1000, loss 0.755865
epoch 1100, loss 0.807088
epoch 1200, loss 0.633233
epoch 1300, loss 1.49205
epoch 1400, loss 0.883336
epoch 1500, loss 0.903819
epoch 1600, loss 1.04738
epoch 1700, loss 1.5143
epoch 1800, loss 0.98098
epoch 1900, loss 1.01053
epoch 2000, loss 0.833569
epoch 2100, loss 1.04998
epoch 2200, loss 0.771003
epoch 2300, loss 1.24504
epoch 2400, loss 0.580393
epoch 2500, loss 0.942384
epoch 2600, loss 0.482149
epoch 2700, loss 0.539608
epoch 2800, loss 0.820552
epoch 2900, loss 0.667717
epoch 3000, loss 0.765716
epoch 3100, loss 0.511481
epoch 3200, loss 0.686478
epoch 3300, loss 0.634849
epoch 3400, loss 0.63455
epoch 3500, loss 0.515853
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
89.2785 49.6854
3.22686 25.2786
89.7385 206.227
22.953 46.8124
20.2755 57.3668
parameters: [ 10.01    1.966   2.711   4.11    3.531]. error: 1.76092775415.
----------------------------
epoch 0, loss 1.13326
epoch 100, loss 0.69221
epoch 200, loss 0.902683
epoch 300, loss 0.770825
epoch 400, loss 0.877865
epoch 500, loss 0.677205
epoch 600, loss 0.736201
epoch 700, loss 0.896557
epoch 800, loss 0.586821
epoch 900, loss 1.27673
epoch 1000, loss 0.86339
epoch 1100, loss 1.02601
epoch 1200, loss 0.927339
epoch 1300, loss 0.779707
epoch 1400, loss 0.920246
epoch 1500, loss 0.560266
epoch 1600, loss 0.831067
epoch 1700, loss 0.78573
epoch 1800, loss 0.750222
epoch 1900, loss 0.762339
epoch 2000, loss 0.756554
epoch 2100, loss 0.594597
epoch 2200, loss 0.778174
epoch 2300, loss 0.493799
epoch 2400, loss 0.813886
epoch 2500, loss 0.778085
epoch 2600, loss 0.582976
epoch 2700, loss 0.356518
epoch 2800, loss 0.865277
epoch 2900, loss 0.360243
epoch 3000, loss 0.853894
epoch 3100, loss 0.860302
epoch 3200, loss 0.573568
epoch 3300, loss 0.490934
epoch 3400, loss 0.617233
epoch 3500, loss 0.67499
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
209.705 62.6473
13.9704 41.9645
14.1268 34.4717
32.9279 94.7908
70.3904 105.622
parameters: [ 10.01    1.966   2.711   5.11    3.531]. error: 0.361386723103.
----------------------------
epoch 0, loss 1.34766
epoch 100, loss 0.860734
epoch 200, loss 1.04821
epoch 300, loss 0.7543
epoch 400, loss 0.761894
epoch 500, loss 1.13712
epoch 600, loss 0.703042
epoch 700, loss 0.517128
epoch 800, loss 0.755122
epoch 900, loss 0.802239
epoch 1000, loss 0.940576
epoch 1100, loss 0.83377
epoch 1200, loss 0.55072
epoch 1300, loss 0.667197
epoch 1400, loss 0.553993
epoch 1500, loss 1.01557
epoch 1600, loss 0.362084
epoch 1700, loss 0.604832
epoch 1800, loss 0.666257
epoch 1900, loss 0.688509
epoch 2000, loss 0.667968
epoch 2100, loss 0.831399
epoch 2200, loss 0.59376
epoch 2300, loss 0.536405
epoch 2400, loss 0.667929
epoch 2500, loss 0.610721
epoch 2600, loss 0.512457
epoch 2700, loss 0.833599
epoch 2800, loss 1.01418
epoch 2900, loss 0.746984
epoch 3000, loss 0.827672
epoch 3100, loss 0.533087
epoch 3200, loss 0.549951
epoch 3300, loss 0.355291
epoch 3400, loss 0.531921
epoch 3500, loss 0.806944
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
305.167 25.3649
20.2755 46.4348
162.436 102.087
19.4471 43.5605
13.9704 47.5802
parameters: [ 10.01    1.966   2.711   4.881   3.531]. error: 5.23472093311.
----------------------------
epoch 0, loss 1.60695
epoch 100, loss 1.3284
epoch 200, loss 1.43316
epoch 300, loss 0.665245
epoch 400, loss 0.918355
epoch 500, loss 0.783051
epoch 600, loss 0.593919
epoch 700, loss 0.7255
epoch 800, loss 0.719891
epoch 900, loss 0.779745
epoch 1000, loss 0.733167
epoch 1100, loss 0.72238
epoch 1200, loss 0.834954
epoch 1300, loss 0.979658
epoch 1400, loss 1.16197
epoch 1500, loss 0.590922
epoch 1600, loss 0.875352
epoch 1700, loss 0.548804
epoch 1800, loss 0.498579
epoch 1900, loss 0.859265
epoch 2000, loss 0.492771
epoch 2100, loss 0.346898
epoch 2200, loss 0.538888
epoch 2300, loss 0.597206
epoch 2400, loss 1.03577
epoch 2500, loss 0.606602
epoch 2600, loss 0.459476
epoch 2700, loss 0.764269
epoch 2800, loss 0.622775
epoch 2900, loss 0.393307
epoch 3000, loss 0.475759
epoch 3100, loss 0.752793
epoch 3200, loss 0.62303
epoch 3300, loss 0.852131
epoch 3400, loss 0.747814
epoch 3500, loss 0.473765
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
79.3243 26.9154
40.0937 40.8972
94.9786 74.9066
36.7438 86.0012
1.11386 23.3653
parameters: [ 10.01    1.966   2.711   4.492   3.531]. error: 20.3027278268.
----------------------------
epoch 0, loss 1.39289
epoch 100, loss 1.22139
epoch 200, loss 1.20658
epoch 300, loss 0.441497
epoch 400, loss 0.674218
epoch 500, loss 0.817007
epoch 600, loss 0.7267
epoch 700, loss 0.578118
epoch 800, loss 0.487598
epoch 900, loss 0.876274
epoch 1000, loss 0.687667
epoch 1100, loss 0.852065
epoch 1200, loss 0.958719
epoch 1300, loss 0.614419
epoch 1400, loss 0.960196
epoch 1500, loss 0.535597
epoch 1600, loss 0.539171
epoch 1700, loss 0.811079
epoch 1800, loss 0.375689
epoch 1900, loss 0.598295
epoch 2000, loss 0.882046
epoch 2100, loss 0.581098
epoch 2200, loss 0.692572
epoch 2300, loss 0.67821
epoch 2400, loss 0.599996
epoch 2500, loss 0.478858
epoch 2600, loss 0.563282
epoch 2700, loss 0.906142
epoch 2800, loss 0.711986
epoch 2900, loss 0.63143
epoch 3000, loss 0.761093
epoch 3100, loss 0.651793
epoch 3200, loss 0.788312
epoch 3300, loss 0.53759
epoch 3400, loss 0.47301
epoch 3500, loss 0.942358
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
2.37471 22.0305
605.821 199.222
146.624 73.9101
209.705 45.5105
13.7745 24.7244
parameters: [ 10.01    1.966   2.711   4.637   3.531]. error: 3.07716405529.
----------------------------
epoch 0, loss 1.63744
epoch 100, loss 1.198
epoch 200, loss 0.976635
epoch 300, loss 1.01519
epoch 400, loss 1.13919
epoch 500, loss 1.13634
epoch 600, loss 0.892586
epoch 700, loss 0.638238
epoch 800, loss 0.580831
epoch 900, loss 0.831181
epoch 1000, loss 0.685426
epoch 1100, loss 1.02737
epoch 1200, loss 1.04121
epoch 1300, loss 0.714903
epoch 1400, loss 0.482429
epoch 1500, loss 1.33615
epoch 1600, loss 1.16116
epoch 1700, loss 0.607453
epoch 1800, loss 1.01994
epoch 1900, loss 0.680321
epoch 2000, loss 1.06076
epoch 2100, loss 0.702239
epoch 2200, loss 0.968734
epoch 2300, loss 0.650656
epoch 2400, loss 0.659247
epoch 2500, loss 1.03883
epoch 2600, loss 0.774107
epoch 2700, loss 0.87025
epoch 2800, loss 1.0309
epoch 2900, loss 0.354325
epoch 3000, loss 0.983729
epoch 3100, loss 0.540751
epoch 3200, loss 0.83991
epoch 3300, loss 0.784997
epoch 3400, loss 0.739849
epoch 3500, loss 0.815723
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
244.06 161.825
33.8136 36.1349
10.5701 23.7027
2.37471 17.5989
33.7234 36.2195
parameters: [ 10.01    1.966   2.711   4.786   3.531]. error: 1.52310369774.
----------------------------
epoch 0, loss 1.82738
epoch 100, loss 1.05254
epoch 200, loss 0.909033
epoch 300, loss 0.761181
epoch 400, loss 0.702533
epoch 500, loss 1.1729
epoch 600, loss 0.763102
epoch 700, loss 1.10271
epoch 800, loss 0.869589
epoch 900, loss 0.903625
epoch 1000, loss 1.04163
epoch 1100, loss 0.676813
epoch 1200, loss 0.43526
epoch 1300, loss 0.921703
epoch 1400, loss 1.10197
epoch 1500, loss 0.906773
epoch 1600, loss 0.810982
epoch 1700, loss 0.706881
epoch 1800, loss 0.418674
epoch 1900, loss 1.03329
epoch 2000, loss 1.27259
epoch 2100, loss 0.644412
epoch 2200, loss 1.03045
epoch 2300, loss 0.753756
epoch 2400, loss 0.573887
epoch 2500, loss 0.672641
epoch 2600, loss 1.01687
epoch 2700, loss 0.745601
epoch 2800, loss 0.583929
epoch 2900, loss 0.426338
epoch 3000, loss 0.372859
epoch 3100, loss 0.572013
epoch 3200, loss 0.759536
epoch 3300, loss 0.38314
epoch 3400, loss 0.651749
epoch 3500, loss 0.410057
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
13.9704 45.9415
69.8093 75.3262
3.22686 22.5912
69.8093 75.3262
10.5701 36.3248
parameters: [ 10.01    1.966   2.711   4.693   3.531]. error: 1.30515017874.
----------------------------
epoch 0, loss 1.37657
epoch 100, loss 1.66266
epoch 200, loss 1.04478
epoch 300, loss 0.58005
epoch 400, loss 0.625043
epoch 500, loss 0.971488
epoch 600, loss 0.76255
epoch 700, loss 1.04957
epoch 800, loss 0.352471
epoch 900, loss 0.695453
epoch 1000, loss 0.885222
epoch 1100, loss 1.0053
epoch 1200, loss 0.453884
epoch 1300, loss 0.520987
epoch 1400, loss 0.692462
epoch 1500, loss 0.7165
epoch 1600, loss 0.589057
epoch 1700, loss 1.18795
epoch 1800, loss 0.934144
epoch 1900, loss 0.789222
epoch 2000, loss 0.825978
epoch 2100, loss 0.637605
epoch 2200, loss 0.874371
epoch 2300, loss 0.812638
epoch 2400, loss 0.766815
epoch 2500, loss 0.550718
epoch 2600, loss 0.632495
epoch 2700, loss 0.655454
epoch 2800, loss 0.909443
epoch 2900, loss 0.71588
epoch 3000, loss 0.480199
epoch 3100, loss 0.688398
epoch 3200, loss 0.699163
epoch 3300, loss 0.808482
epoch 3400, loss 0.551745
epoch 3500, loss 0.517218
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
831.403 103.011
38.6549 21.924
460.913 51.4448
28.3521 34.9986
32.9279 52.807
parameters: [ 10.01    1.966   2.711   4.75    3.531]. error: 2.43522655013.
----------------------------
epoch 0, loss 0.998906
epoch 100, loss 1.09072
epoch 200, loss 1.59607
epoch 300, loss 1.22709
epoch 400, loss 1.01314
epoch 500, loss 0.898674
epoch 600, loss 1.09414
epoch 700, loss 0.914643
epoch 800, loss 0.640353
epoch 900, loss 0.370869
epoch 1000, loss 1.09301
epoch 1100, loss 0.90999
epoch 1200, loss 0.432861
epoch 1300, loss 0.860728
epoch 1400, loss 0.779182
epoch 1500, loss 0.651939
epoch 1600, loss 1.03193
epoch 1700, loss 0.790018
epoch 1800, loss 0.922454
epoch 1900, loss 0.63406
epoch 2000, loss 0.688771
epoch 2100, loss 0.448054
epoch 2200, loss 0.577669
epoch 2300, loss 0.931754
epoch 2400, loss 0.514065
epoch 2500, loss 0.450765
epoch 2600, loss 0.921315
epoch 2700, loss 1.08501
epoch 2800, loss 0.609455
epoch 2900, loss 0.538703
epoch 3000, loss 0.546053
epoch 3100, loss 0.716262
epoch 3200, loss 0.863205
epoch 3300, loss 0.546644
epoch 3400, loss 0.910241
epoch 3500, loss 0.716475
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
28.7444 59.337
22.953 30.3824
70.2845 95.1522
64.3569 87.1007
32.9441 54.832
parameters: [ 10.01    1.966   2.711   4.714   3.531]. error: 0.0661862116382.
----------------------------
epoch 0, loss 0.953372
epoch 100, loss 1.45769
epoch 200, loss 1.15361
epoch 300, loss 0.96552
epoch 400, loss 0.56537
epoch 500, loss 0.979908
epoch 600, loss 0.848462
epoch 700, loss 1.32816
epoch 800, loss 1.11791
epoch 900, loss 1.26196
epoch 1000, loss 0.58798
epoch 1100, loss 1.09799
epoch 1200, loss 0.860906
epoch 1300, loss 0.770632
epoch 1400, loss 1.47511
epoch 1500, loss 0.703776
epoch 1600, loss 0.896248
epoch 1700, loss 1.02637
epoch 1800, loss 0.746291
epoch 1900, loss 0.905888
epoch 2000, loss 0.944481
epoch 2100, loss 0.857175
epoch 2200, loss 0.646571
epoch 2300, loss 0.581042
epoch 2400, loss 0.605727
epoch 2500, loss 0.777646
epoch 2600, loss 0.668508
epoch 2700, loss 0.509149
epoch 2800, loss 0.545946
epoch 2900, loss 0.893326
epoch 3000, loss 0.452931
epoch 3100, loss 0.794289
epoch 3200, loss 0.552436
epoch 3300, loss 0.724927
epoch 3400, loss 0.690589
epoch 3500, loss 0.967124
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
28.3521 30.9643
43.9272 32.3564
19.4471 38.616
244.06 87.6683
39.4136 38.616
parameters: [ 10.01    1.966   2.711   4.706   3.531]. error: 0.184873063516.
----------------------------
epoch 0, loss 1.32261
epoch 100, loss 1.34819
epoch 200, loss 1.40443
epoch 300, loss 1.23106
epoch 400, loss 1.22475
epoch 500, loss 1.10541
epoch 600, loss 0.78571
epoch 700, loss 1.39443
epoch 800, loss 1.21077
epoch 900, loss 0.997658
epoch 1000, loss 0.866186
epoch 1100, loss 0.557822
epoch 1200, loss 0.792225
epoch 1300, loss 0.864153
epoch 1400, loss 0.899498
epoch 1500, loss 1.12069
epoch 1600, loss 0.643656
epoch 1700, loss 0.535932
epoch 1800, loss 0.849197
epoch 1900, loss 0.896855
epoch 2000, loss 0.765891
epoch 2100, loss 1.15326
epoch 2200, loss 0.582988
epoch 2300, loss 0.751171
epoch 2400, loss 0.665914
epoch 2500, loss 0.719089
epoch 2600, loss 1.05147
epoch 2700, loss 1.20451
epoch 2800, loss 0.588713
epoch 2900, loss 0.619209
epoch 3000, loss 0.80791
epoch 3100, loss 0.604048
epoch 3200, loss 0.631171
epoch 3300, loss 0.925337
epoch 3400, loss 0.443753
epoch 3500, loss 0.7483
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
25.6565 35.7645
38.304 59.346
106.094 36.1963
38.4634 200.987
56.7553 32.1377
parameters: [ 10.01    1.966   2.711   4.715   3.531]. error: 0.771253607171.
----------------------------
epoch 0, loss 1.09289
epoch 100, loss 0.787044
epoch 200, loss 1.31026
epoch 300, loss 1.06554
epoch 400, loss 0.745309
epoch 500, loss 0.583253
epoch 600, loss 0.590899
epoch 700, loss 0.715901
epoch 800, loss 0.644595
epoch 900, loss 0.869634
epoch 1000, loss 0.592341
epoch 1100, loss 0.755764
epoch 1200, loss 1.05733
epoch 1300, loss 0.681195
epoch 1400, loss 0.895323
epoch 1500, loss 0.586325
epoch 1600, loss 0.653281
epoch 1700, loss 0.819443
epoch 1800, loss 0.831302
epoch 1900, loss 0.772558
epoch 2000, loss 0.771484
epoch 2100, loss 0.355696
epoch 2200, loss 0.619634
epoch 2300, loss 0.591089
epoch 2400, loss 0.848877
epoch 2500, loss 0.480366
epoch 2600, loss 0.53621
epoch 2700, loss 0.399741
epoch 2800, loss 0.536734
epoch 2900, loss 0.752555
epoch 3000, loss 0.559646
epoch 3100, loss 0.647378
epoch 3200, loss 0.566537
epoch 3300, loss 0.528269
epoch 3400, loss 0.702884
epoch 3500, loss 0.354723
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
31.6796 36.2544
13.842 37.2952
13.9704 37.6546
109.588 68.229
605.821 215.094
parameters: [ 10.01    1.966   2.711   4.714   3.531]. error: 0.252403184156.
----------------------------
epoch 0, loss 1.8426
epoch 100, loss 1.20218
epoch 200, loss 0.755275
epoch 300, loss 0.903035
epoch 400, loss 1.31438
epoch 500, loss 1.05685
epoch 600, loss 0.928472
epoch 700, loss 0.99412
epoch 800, loss 0.914225
epoch 900, loss 1.59387
epoch 1000, loss 1.56702
epoch 1100, loss 0.877268
epoch 1200, loss 1.09499
epoch 1300, loss 0.610491
epoch 1400, loss 0.886326
epoch 1500, loss 0.803728
epoch 1600, loss 1.1242
epoch 1700, loss 1.2542
epoch 1800, loss 1.09184
epoch 1900, loss 1.07773
epoch 2000, loss 0.974442
epoch 2100, loss 1.00855
epoch 2200, loss 1.04722
epoch 2300, loss 1.29863
epoch 2400, loss 0.470857
epoch 2500, loss 1.23941
epoch 2600, loss 0.871801
epoch 2700, loss 0.565854
epoch 2800, loss 0.717795
epoch 2900, loss 0.696396
epoch 3000, loss 0.680785
epoch 3100, loss 1.18372
epoch 3200, loss 0.859618
epoch 3300, loss 0.690587
epoch 3400, loss 0.617703
epoch 3500, loss 0.660481
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
31.6796 49.3591
38.304 105.8
162.436 107.967
13.842 48.9229
71.8482 147.892
parameters: [ 10.01    1.966   2.711   4.715   3.531]. error: 0.262610042769.
----------------------------
epoch 0, loss 1.16959
epoch 100, loss 1.0859
epoch 200, loss 1.48391
epoch 300, loss 1.02134
epoch 400, loss 0.858394
epoch 500, loss 0.738237
epoch 600, loss 0.741922
epoch 700, loss 0.774065
epoch 800, loss 1.33173
epoch 900, loss 0.684354
epoch 1000, loss 0.882189
epoch 1100, loss 0.79863
epoch 1200, loss 0.782123
epoch 1300, loss 0.568431
epoch 1400, loss 0.364696
epoch 1500, loss 0.576439
epoch 1600, loss 0.449141
epoch 1700, loss 0.947193
epoch 1800, loss 0.838385
epoch 1900, loss 1.14258
epoch 2000, loss 0.562616
epoch 2100, loss 0.838462
epoch 2200, loss 0.803238
epoch 2300, loss 0.601194
epoch 2400, loss 0.864973
epoch 2500, loss 0.498489
epoch 2600, loss 0.503274
epoch 2700, loss 0.662388
epoch 2800, loss 0.67816
epoch 2900, loss 0.981432
epoch 3000, loss 0.425524
epoch 3100, loss 0.834428
epoch 3200, loss 0.447794
epoch 3300, loss 0.593555
epoch 3400, loss 0.465113
epoch 3500, loss 0.815001
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
244.06 97.4317
37.0194 93.2693
47.6327 38.4615
14.1268 26.5865
48.9224 38.7853
parameters: [ 10.01    1.966   2.711   4.715   3.531]. error: 0.200065798632.
----------------------------
epoch 0, loss 1.08151
epoch 100, loss 0.950419
epoch 200, loss 0.477789
epoch 300, loss 0.810425
epoch 400, loss 0.974061
epoch 500, loss 1.32727
epoch 600, loss 0.907021
epoch 700, loss 1.3398
epoch 800, loss 0.828689
epoch 900, loss 1.70141
epoch 1000, loss 1.10502
epoch 1100, loss 1.32226
epoch 1200, loss 1.2923
epoch 1300, loss 0.846188
epoch 1400, loss 0.931732
epoch 1500, loss 0.759571
epoch 1600, loss 0.879644
epoch 1700, loss 0.387745
epoch 1800, loss 0.962886
epoch 1900, loss 0.44809
epoch 2000, loss 0.518112
epoch 2100, loss 0.519995
epoch 2200, loss 0.812859
epoch 2300, loss 0.931589
epoch 2400, loss 0.760027
epoch 2500, loss 0.76921
epoch 2600, loss 0.376243
epoch 2700, loss 0.554307
epoch 2800, loss 0.529872
epoch 2900, loss 0.525154
epoch 3000, loss 0.782039
epoch 3100, loss 0.471813
epoch 3200, loss 0.411188
epoch 3300, loss 1.11692
epoch 3400, loss 0.533479
epoch 3500, loss 0.39038
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
89.7385 219.579
116.598 64.683
20.2734 34.5372
16.4294 33.7044
6.15658 19.0244
parameters: [ 10.01    1.966   2.711   4.714   3.531]. error: 0.211479418182.
----------------------------
epoch 0, loss 1.46239
epoch 100, loss 0.549495
epoch 200, loss 0.844541
epoch 300, loss 0.823978
epoch 400, loss 0.912063
epoch 500, loss 0.547312
epoch 600, loss 0.594368
epoch 700, loss 0.620485
epoch 800, loss 0.612775
epoch 900, loss 0.564604
epoch 1000, loss 0.873084
epoch 1100, loss 0.782174
epoch 1200, loss 0.439577
epoch 1300, loss 0.523728
epoch 1400, loss 0.919288
epoch 1500, loss 0.694385
epoch 1600, loss 0.725718
epoch 1700, loss 0.598555
epoch 1800, loss 1.01321
epoch 1900, loss 0.835947
epoch 2000, loss 0.951768
epoch 2100, loss 0.416431
epoch 2200, loss 0.686335
epoch 2300, loss 0.637449
epoch 2400, loss 0.658537
epoch 2500, loss 0.604707
epoch 2600, loss 0.426642
epoch 2700, loss 0.515856
epoch 2800, loss 0.470375
epoch 2900, loss 0.62609
epoch 3000, loss 0.643502
epoch 3100, loss 0.546772
epoch 3200, loss 0.832348
epoch 3300, loss 0.753357
epoch 3400, loss 0.867468
epoch 3500, loss 0.7201
epoch 3600, loss 0.433744
epoch 3700, loss 0.800231
epoch 3800, loss 0.670735
epoch 3900, loss 0.409707
epoch 4000, loss 0.604843
epoch 4100, loss 1.02269
epoch 4200, loss 0.911244
epoch 4300, loss 0.47826
epoch 4400, loss 0.497396
epoch 4500, loss 0.861292
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
79.3243 18.8447
25.6565 120.782
101.017 655.999
28.7444 41.3827
116.598 84.2976
parameters: [ 10.01    1.966   2.711   4.714   4.531]. error: 1.43820695161.
----------------------------
epoch 0, loss 0.500794
epoch 100, loss 1.02324
epoch 200, loss 1.06301
epoch 300, loss 0.685957
epoch 400, loss 0.988267
epoch 500, loss 0.677503
epoch 600, loss 0.98653
epoch 700, loss 0.386066
epoch 800, loss 0.642437
epoch 900, loss 0.665534
epoch 1000, loss 0.925063
epoch 1100, loss 0.895839
epoch 1200, loss 0.782612
epoch 1300, loss 1.17994
epoch 1400, loss 0.89256
epoch 1500, loss 0.73218
epoch 1600, loss 0.628975
epoch 1700, loss 0.441022
epoch 1800, loss 0.853692
epoch 1900, loss 0.665627
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
70.3904 91.7148
13.7745 41.256
3167.53 211.74
69.8093 53.6791
6.15658 36.539
parameters: [ 10.01    1.966   2.711   4.714   1.913]. error: 9.51364150172.
----------------------------
epoch 0, loss 0.741194
epoch 100, loss 0.973536
epoch 200, loss 1.48449
epoch 300, loss 1.08471
epoch 400, loss 0.52404
epoch 500, loss 0.818082
epoch 600, loss 0.720415
epoch 700, loss 1.13185
epoch 800, loss 1.32418
epoch 900, loss 0.807404
epoch 1000, loss 1.23408
epoch 1100, loss 1.37068
epoch 1200, loss 0.793052
epoch 1300, loss 0.784171
epoch 1400, loss 1.20561
epoch 1500, loss 1.23719
epoch 1600, loss 0.748795
epoch 1700, loss 1.15282
epoch 1800, loss 0.974814
epoch 1900, loss 0.991547
epoch 2000, loss 0.445294
epoch 2100, loss 1.00042
epoch 2200, loss 0.720153
epoch 2300, loss 0.68035
epoch 2400, loss 0.773095
epoch 2500, loss 0.864412
epoch 2600, loss 1.03333
epoch 2700, loss 1.12266
epoch 2800, loss 1.02331
epoch 2900, loss 0.776829
epoch 3000, loss 0.85196
epoch 3100, loss 1.01848
epoch 3200, loss 1.02422
epoch 3300, loss 0.862317
epoch 3400, loss 1.48579
epoch 3500, loss 0.92946
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
13.9704 53.0303
194.962 70.1501
3.22686 52.6601
37.0194 56.6641
6.15658 51.3435
parameters: [ 10.01    1.966   2.711   4.714   3.531]. error: 10.8873594462.
----------------------------
epoch 0, loss 0.641065
epoch 100, loss 0.756862
epoch 200, loss 0.772463
epoch 300, loss 1.31698
epoch 400, loss 0.582461
epoch 500, loss 0.841138
epoch 600, loss 0.843076
epoch 700, loss 1.74801
epoch 800, loss 0.916266
epoch 900, loss 0.982633
epoch 1000, loss 0.939706
epoch 1100, loss 1.40486
epoch 1200, loss 0.712401
epoch 1300, loss 1.04513
epoch 1400, loss 0.985006
epoch 1500, loss 0.838114
epoch 1600, loss 0.691532
epoch 1700, loss 0.878849
epoch 1800, loss 0.578323
epoch 1900, loss 0.534263
epoch 2000, loss 0.93843
epoch 2100, loss 0.586927
epoch 2200, loss 0.385452
epoch 2300, loss 0.814246
epoch 2400, loss 1.09215
epoch 2500, loss 1.29499
epoch 2600, loss 0.847526
epoch 2700, loss 0.749263
epoch 2800, loss 0.558049
epoch 2900, loss 0.491044
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
14.1268 21.9006
126.871 158.217
38.304 79.5641
13.9704 34.3761
460.913 82.2817
parameters: [ 10.01    1.966   2.711   4.714   2.913]. error: 0.837635071365.
----------------------------
epoch 0, loss 0.614857
epoch 100, loss 0.826657
epoch 200, loss 0.947951
epoch 300, loss 1.50337
epoch 400, loss 1.06157
epoch 500, loss 1.20934
epoch 600, loss 1.03484
epoch 700, loss 0.954442
epoch 800, loss 0.676131
epoch 900, loss 0.961443
epoch 1000, loss 0.817142
epoch 1100, loss 0.709952
epoch 1200, loss 0.815696
epoch 1300, loss 0.63879
epoch 1400, loss 0.738181
epoch 1500, loss 0.984096
epoch 1600, loss 0.639377
epoch 1700, loss 0.430497
epoch 1800, loss 1.59102
epoch 1900, loss 0.763592
epoch 2000, loss 0.517607
epoch 2100, loss 1.07079
epoch 2200, loss 1.61393
epoch 2300, loss 1.00339
epoch 2400, loss 0.793166
epoch 2500, loss 0.957918
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
14.1268 44.5823
246.534 59.4863
112.36 66.7242
209.705 63.7414
1321.38 43.6872
parameters: [ 10.01    1.966   2.711   4.714   2.531]. error: 50.4908633819.
----------------------------
epoch 0, loss 1.11801
epoch 100, loss 0.886665
epoch 200, loss 0.851056
epoch 300, loss 0.66243
epoch 400, loss 1.43258
epoch 500, loss 0.961495
epoch 600, loss 1.04648
epoch 700, loss 1.15514
epoch 800, loss 1.62136
epoch 900, loss 1.05444
epoch 1000, loss 0.870421
epoch 1100, loss 1.06974
epoch 1200, loss 0.971819
epoch 1300, loss 0.620349
epoch 1400, loss 0.629341
epoch 1500, loss 1.31113
epoch 1600, loss 0.856074
epoch 1700, loss 1.06291
epoch 1800, loss 1.12389
epoch 1900, loss 1.05983
epoch 2000, loss 0.766249
epoch 2100, loss 1.11006
epoch 2200, loss 0.828811
epoch 2300, loss 0.712417
epoch 2400, loss 1.37251
epoch 2500, loss 0.63481
epoch 2600, loss 0.826047
epoch 2700, loss 1.15457
epoch 2800, loss 1.06006
epoch 2900, loss 0.880281
epoch 3000, loss 0.853634
epoch 3100, loss 0.891998
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
25.6565 30.029
36.7438 60.5812
20.2755 33.1433
194.962 139.244
43.9272 37.299
parameters: [ 10.01    1.966   2.711   4.714   3.166]. error: 0.0581019755114.
----------------------------
epoch 0, loss 1.63063
epoch 100, loss 1.04461
epoch 200, loss 0.797528
epoch 300, loss 0.780358
epoch 400, loss 0.821208
epoch 500, loss 0.865391
epoch 600, loss 0.804853
epoch 700, loss 0.718028
epoch 800, loss 1.25825
epoch 900, loss 0.616455
epoch 1000, loss 0.953785
epoch 1100, loss 1.28635
epoch 1200, loss 1.28702
epoch 1300, loss 0.737062
epoch 1400, loss 0.854144
epoch 1500, loss 1.03915
epoch 1600, loss 0.665621
epoch 1700, loss 0.798894
epoch 1800, loss 0.741914
epoch 1900, loss 0.785077
epoch 2000, loss 0.706897
epoch 2100, loss 0.933066
epoch 2200, loss 0.53682
epoch 2300, loss 0.406374
epoch 2400, loss 0.746314
epoch 2500, loss 0.562175
epoch 2600, loss 1.37424
epoch 2700, loss 0.784907
epoch 2800, loss 0.869484
epoch 2900, loss 0.674718
epoch 3000, loss 0.772561
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
605.821 104.282
36.7438 91.727
209.705 41.7175
67.5897 92.8095
127.381 84.9948
parameters: [ 10.01    1.966   2.711   4.714   3.068]. error: 0.911924192789.
----------------------------
epoch 0, loss 1.17229
epoch 100, loss 1.02818
epoch 200, loss 0.709138
epoch 300, loss 0.736713
epoch 400, loss 0.994122
epoch 500, loss 1.07575
epoch 600, loss 1.10894
epoch 700, loss 1.20944
epoch 800, loss 1.35093
epoch 900, loss 0.625767
epoch 1000, loss 1.08163
epoch 1100, loss 0.721551
epoch 1200, loss 0.949829
epoch 1300, loss 0.987696
epoch 1400, loss 1.12274
epoch 1500, loss 1.82229
epoch 1600, loss 1.09187
epoch 1700, loss 1.3379
epoch 1800, loss 0.971603
epoch 1900, loss 1.16363
epoch 2000, loss 1.28106
epoch 2100, loss 1.06636
epoch 2200, loss 0.642138
epoch 2300, loss 0.719448
epoch 2400, loss 1.10209
epoch 2500, loss 0.613518
epoch 2600, loss 0.610377
epoch 2700, loss 0.968102
epoch 2800, loss 1.29236
epoch 2900, loss 1.11583
epoch 3000, loss 0.802713
epoch 3100, loss 1.28385
epoch 3200, loss 1.15233
epoch 3300, loss 1.29818
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
40.0937 53.1965
194.962 56.3294
32.9279 63.5016
146.624 67.3814
47.4619 58.8969
parameters: [ 10.01    1.966   2.711   4.714   3.305]. error: 0.274511415898.
----------------------------
epoch 0, loss 2.46154
epoch 100, loss 1.34701
epoch 200, loss 0.647313
epoch 300, loss 1.92662
epoch 400, loss 0.957028
epoch 500, loss 1.08131
epoch 600, loss 1.14211
epoch 700, loss 0.956643
epoch 800, loss 0.612743
epoch 900, loss 0.813355
epoch 1000, loss 0.52305
epoch 1100, loss 1.00494
epoch 1200, loss 0.676807
epoch 1300, loss 0.585984
epoch 1400, loss 0.668927
epoch 1500, loss 0.550041
epoch 1600, loss 0.464573
epoch 1700, loss 0.651348
epoch 1800, loss 0.400308
epoch 1900, loss 1.05357
epoch 2000, loss 0.693341
epoch 2100, loss 0.611623
epoch 2200, loss 0.565316
epoch 2300, loss 0.63982
epoch 2400, loss 0.66294
epoch 2500, loss 0.487217
epoch 2600, loss 0.685511
epoch 2700, loss 0.373965
epoch 2800, loss 0.794477
epoch 2900, loss 0.894391
epoch 3000, loss 0.420604
epoch 3100, loss 0.617729
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
45.3756 73.9467
57.0616 46.8715
460.913 39.9745
32.9441 58.5875
9.3969 29.2219
parameters: [ 10.01    1.966   2.711   4.714   3.17 ]. error: 4.68482174922.
----------------------------
epoch 0, loss 2.08673
epoch 100, loss 1.29208
epoch 200, loss 1.04116
epoch 300, loss 1.18893
epoch 400, loss 0.713201
epoch 500, loss 0.982586
epoch 600, loss 1.23901
epoch 700, loss 1.16121
epoch 800, loss 0.738878
epoch 900, loss 0.750367
epoch 1000, loss 0.979159
epoch 1100, loss 0.852067
epoch 1200, loss 0.757592
epoch 1300, loss 1.18363
epoch 1400, loss 0.969452
epoch 1500, loss 0.527073
epoch 1600, loss 1.04746
epoch 1700, loss 0.885511
epoch 1800, loss 0.600806
epoch 1900, loss 1.31642
epoch 2000, loss 0.882155
epoch 2100, loss 0.842735
epoch 2200, loss 1.01855
epoch 2300, loss 1.35484
epoch 2400, loss 0.653153
epoch 2500, loss 1.12485
epoch 2600, loss 1.06069
epoch 2700, loss 1.55348
epoch 2800, loss 0.820441
epoch 2900, loss 1.08811
epoch 3000, loss 0.817684
epoch 3100, loss 0.74358
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
28.3521 55.8167
126.871 80.5746
116.598 74.1787
25.6565 50.5271
94.9786 75.2409
parameters: [ 10.01    1.966   2.711   4.714   3.129]. error: 0.0855383812673.
----------------------------
epoch 0, loss 1.53761
epoch 100, loss 0.83081
epoch 200, loss 0.997637
epoch 300, loss 0.776815
epoch 400, loss 0.907647
epoch 500, loss 0.809311
epoch 600, loss 0.601337
epoch 700, loss 1.20368
epoch 800, loss 0.564053
epoch 900, loss 0.842551
epoch 1000, loss 0.85046
epoch 1100, loss 0.789188
epoch 1200, loss 0.800509
epoch 1300, loss 0.583043
epoch 1400, loss 1.38922
epoch 1500, loss 0.639067
epoch 1600, loss 0.925203
epoch 1700, loss 0.809758
epoch 1800, loss 0.647727
epoch 1900, loss 0.736562
epoch 2000, loss 0.64293
epoch 2100, loss 0.806356
epoch 2200, loss 0.735506
epoch 2300, loss 0.561066
epoch 2400, loss 0.647809
epoch 2500, loss 0.600228
epoch 2600, loss 0.522808
epoch 2700, loss 0.673564
epoch 2800, loss 0.557482
epoch 2900, loss 0.471145
epoch 3000, loss 0.598829
epoch 3100, loss 0.789284
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
20.2755 39.2352
47.4619 63.0968
259.052 63.4543
20.2755 39.2352
162.436 69.875
parameters: [ 10.01    1.966   2.711   4.714   3.152]. error: 0.388846292299.
----------------------------
epoch 0, loss 2.53381
epoch 100, loss 0.629499
epoch 200, loss 0.868849
epoch 300, loss 0.557221
epoch 400, loss 1.07335
epoch 500, loss 0.521403
epoch 600, loss 0.586351
epoch 700, loss 0.644752
epoch 800, loss 0.600204
epoch 900, loss 0.752591
epoch 1000, loss 0.688551
epoch 1100, loss 0.67236
epoch 1200, loss 0.623994
epoch 1300, loss 0.550838
epoch 1400, loss 0.506303
epoch 1500, loss 0.78137
epoch 1600, loss 0.519866
epoch 1700, loss 1.00228
epoch 1800, loss 0.437467
epoch 1900, loss 0.498023
epoch 2000, loss 0.549509
epoch 2100, loss 0.744909
epoch 2200, loss 0.671333
epoch 2300, loss 0.531519
epoch 2400, loss 0.607263
epoch 2500, loss 0.499879
epoch 2600, loss 0.431064
epoch 2700, loss 0.557565
epoch 2800, loss 0.750206
epoch 2900, loss 0.647442
epoch 3000, loss 0.804221
epoch 3100, loss 0.51866
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
460.913 77.2563
116.598 66.5385
31.6796 36.2824
32.0605 126.663
209.705 39.9557
parameters: [ 10.01    1.966   2.711   4.714   3.161]. error: 1.1796257742.
----------------------------
epoch 0, loss 1.22774
epoch 100, loss 1.36259
epoch 200, loss 1.23577
epoch 300, loss 1.2177
epoch 400, loss 1.29147
epoch 500, loss 1.07525
epoch 600, loss 1.16858
epoch 700, loss 1.13463
epoch 800, loss 0.891609
epoch 900, loss 0.824411
epoch 1000, loss 1.15782
epoch 1100, loss 1.28504
epoch 1200, loss 1.17963
epoch 1300, loss 0.857481
epoch 1400, loss 0.985672
epoch 1500, loss 0.815378
epoch 1600, loss 0.747781
epoch 1700, loss 0.801175
epoch 1800, loss 1.59139
epoch 1900, loss 1.2243
epoch 2000, loss 1.15747
epoch 2100, loss 0.6143
epoch 2200, loss 0.938729
epoch 2300, loss 0.800086
epoch 2400, loss 0.790158
epoch 2500, loss 1.2902
epoch 2600, loss 0.883858
epoch 2700, loss 1.12979
epoch 2800, loss 0.866388
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
47.4619 44.0968
39.4136 40.3161
37.0194 38.8422
56.7553 40.6912
3167.53 40.181
parameters: [ 12.01    2.348   3.738   4.701   2.802]. error: 551.773628721.
----------------------------
epoch 0, loss 1.87477
epoch 100, loss 1.24578
epoch 200, loss 0.87948
epoch 300, loss 1.35712
epoch 400, loss 0.610258
epoch 500, loss 1.25299
epoch 600, loss 1.21466
epoch 700, loss 0.957104
epoch 800, loss 1.18559
epoch 900, loss 1.07627
epoch 1000, loss 0.967739
epoch 1100, loss 1.1248
epoch 1200, loss 0.926947
epoch 1300, loss 0.840898
epoch 1400, loss 0.796321
epoch 1500, loss 0.793969
epoch 1600, loss 0.885406
epoch 1700, loss 0.618377
epoch 1800, loss 0.723524
epoch 1900, loss 0.49386
epoch 2000, loss 0.913523
epoch 2100, loss 1.05752
epoch 2200, loss 0.894535
epoch 2300, loss 0.737642
epoch 2400, loss 0.722839
epoch 2500, loss 0.528659
epoch 2600, loss 0.612999
epoch 2700, loss 0.721907
epoch 2800, loss 0.864147
epoch 2900, loss 0.689773
epoch 3000, loss 0.64588
epoch 3100, loss 0.671643
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
67.5897 83.1209
234.37 98.2777
64.3569 87.4034
33.7234 38.7101
162.436 82.8209
parameters: [ 10.01    1.966   2.711   4.714   3.166]. error: 0.109319979019.
----------------------------
epoch 0, loss 1.40227
epoch 100, loss 1.45664
epoch 200, loss 0.811641
epoch 300, loss 0.871083
epoch 400, loss 0.982063
epoch 500, loss 0.695693
epoch 600, loss 0.590151
epoch 700, loss 0.740927
epoch 800, loss 0.827617
epoch 900, loss 0.959956
epoch 1000, loss 0.711143
epoch 1100, loss 0.966264
epoch 1200, loss 0.929491
epoch 1300, loss 0.778932
epoch 1400, loss 0.996257
epoch 1500, loss 0.61209
epoch 1600, loss 0.647113
epoch 1700, loss 0.709988
epoch 1800, loss 0.578674
epoch 1900, loss 0.805587
epoch 2000, loss 0.785289
epoch 2100, loss 0.65861
epoch 2200, loss 0.810458
epoch 2300, loss 0.57248
epoch 2400, loss 0.704005
epoch 2500, loss 0.700002
epoch 2600, loss 0.605359
epoch 2700, loss 0.443259
epoch 2800, loss 0.571472
epoch 2900, loss 1.08389
epoch 3000, loss 0.597289
epoch 3100, loss 0.956054
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
70.2845 68.165
28.3521 35.042
209.705 35.5336
32.0605 99.8876
246.534 25.9032
parameters: [ 11.01    1.966   2.711   4.714   3.166]. error: 2.96586642183.
----------------------------
epoch 0, loss 0.947667
epoch 100, loss 0.677863
epoch 200, loss 1.4883
epoch 300, loss 0.803528
epoch 400, loss 1.08896
epoch 500, loss 1.16387
epoch 600, loss 0.983
epoch 700, loss 1.08685
epoch 800, loss 1.90212
epoch 900, loss 1.09163
epoch 1000, loss 1.48571
epoch 1100, loss 1.35347
epoch 1200, loss 0.755836
epoch 1300, loss 0.639139
epoch 1400, loss 0.70341
epoch 1500, loss 0.636122
epoch 1600, loss 0.636999
epoch 1700, loss 0.689108
epoch 1800, loss 0.740563
epoch 1900, loss 0.920515
epoch 2000, loss 0.583204
epoch 2100, loss 0.613394
epoch 2200, loss 0.588571
epoch 2300, loss 0.891922
epoch 2400, loss 0.677625
epoch 2500, loss 0.501879
epoch 2600, loss 1.0158
epoch 2700, loss 0.818063
epoch 2800, loss 0.554744
epoch 2900, loss 1.10999
epoch 3000, loss 0.448275
epoch 3100, loss 0.639602
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
39.4136 43.6876
33.7234 44.0228
13.9704 42.9082
89.7385 349.681
47.6327 44.0228
parameters: [ 8.392  1.966  2.711  4.714  3.166]. error: 0.311909438147.
----------------------------
epoch 0, loss 1.02772
epoch 100, loss 1.15956
epoch 200, loss 0.866221
epoch 300, loss 1.29562
epoch 400, loss 1.25733
epoch 500, loss 0.862357
epoch 600, loss 0.873019
epoch 700, loss 1.07857
epoch 800, loss 0.888595
epoch 900, loss 1.23192
epoch 1000, loss 1.0235
epoch 1100, loss 0.586126
epoch 1200, loss 0.812878
epoch 1300, loss 0.79459
epoch 1400, loss 0.812742
epoch 1500, loss 0.645001
epoch 1600, loss 0.807775
epoch 1700, loss 0.668276
epoch 1800, loss 0.686634
epoch 1900, loss 0.782366
epoch 2000, loss 0.679521
epoch 2100, loss 0.846685
epoch 2200, loss 0.384099
epoch 2300, loss 0.669982
epoch 2400, loss 0.730294
epoch 2500, loss 0.535933
epoch 2600, loss 0.788614
epoch 2700, loss 0.658992
epoch 2800, loss 0.468929
epoch 2900, loss 0.60511
epoch 3000, loss 0.939921
epoch 3100, loss 0.564958
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
106.094 34.754
25.6565 49.2436
67.5897 48.7937
89.7385 183.987
162.436 48.4689
parameters: [ 10.01    1.966   2.711   4.714   3.166]. error: 0.265801285651.
----------------------------
epoch 0, loss 0.854083
epoch 100, loss 0.748461
epoch 200, loss 0.80306
epoch 300, loss 0.703863
epoch 400, loss 1.08536
epoch 500, loss 0.737229
epoch 600, loss 0.874467
epoch 700, loss 0.825469
epoch 800, loss 1.14512
epoch 900, loss 0.985689
epoch 1000, loss 0.956567
epoch 1100, loss 0.488538
epoch 1200, loss 1.17919
epoch 1300, loss 0.598345
epoch 1400, loss 0.785611
epoch 1500, loss 1.00144
epoch 1600, loss 1.25147
epoch 1700, loss 1.1259
epoch 1800, loss 0.913578
epoch 1900, loss 0.827485
epoch 2000, loss 0.944745
epoch 2100, loss 0.667913
epoch 2200, loss 1.22823
epoch 2300, loss 0.766737
epoch 2400, loss 1.09106
epoch 2500, loss 0.596169
epoch 2600, loss 0.802504
epoch 2700, loss 1.1509
epoch 2800, loss 1.38246
epoch 2900, loss 0.805466
epoch 3000, loss 1.09002
epoch 3100, loss 1.23552
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
13.9704 47.7873
16.4294 47.0415
94.9786 83.7124
234.37 46.2155
162.436 46.6075
parameters: [ 9.392  1.966  2.711  4.714  3.166]. error: 0.79554833245.
----------------------------
epoch 0, loss 1.68655
epoch 100, loss 1.26646
epoch 200, loss 0.911004
epoch 300, loss 0.97677
epoch 400, loss 0.747682
epoch 500, loss 0.790366
epoch 600, loss 0.924118
epoch 700, loss 1.0138
epoch 800, loss 0.864344
epoch 900, loss 0.655507
epoch 1000, loss 1.32292
epoch 1100, loss 1.04412
epoch 1200, loss 1.31432
epoch 1300, loss 0.482826
epoch 1400, loss 0.98688
epoch 1500, loss 0.76686
epoch 1600, loss 1.22661
epoch 1700, loss 0.701434
epoch 1800, loss 0.961633
epoch 1900, loss 0.869637
epoch 2000, loss 0.753726
epoch 2100, loss 0.877385
epoch 2200, loss 0.717905
epoch 2300, loss 1.0707
epoch 2400, loss 1.35536
epoch 2500, loss 0.740541
epoch 2600, loss 0.405537
epoch 2700, loss 0.448863
epoch 2800, loss 0.576818
epoch 2900, loss 0.842419
epoch 3000, loss 0.686068
epoch 3100, loss 0.677033
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
69.8093 71.4903
162.436 42.711
1321.38 42.7007
209.705 68.3235
305.167 87.4992
parameters: [ 10.392   1.966   2.711   4.714   3.166]. error: 53.2811137998.
----------------------------
epoch 0, loss 1.54684
epoch 100, loss 1.17779
epoch 200, loss 1.17678
epoch 300, loss 1.11278
epoch 400, loss 0.723985
epoch 500, loss 0.678453
epoch 600, loss 1.24516
epoch 700, loss 1.64368
epoch 800, loss 0.577542
epoch 900, loss 0.838901
epoch 1000, loss 0.768281
epoch 1100, loss 1.15449
epoch 1200, loss 0.959491
epoch 1300, loss 0.697561
epoch 1400, loss 0.619284
epoch 1500, loss 0.897351
epoch 1600, loss 0.77051
epoch 1700, loss 0.530408
epoch 1800, loss 0.529507
epoch 1900, loss 0.484173
epoch 2000, loss 0.600663
epoch 2100, loss 0.866284
epoch 2200, loss 0.71935
epoch 2300, loss 0.604858
epoch 2400, loss 0.773375
epoch 2500, loss 0.844142
epoch 2600, loss 0.421885
epoch 2700, loss 0.646827
epoch 2800, loss 0.531055
epoch 2900, loss 0.567844
epoch 3000, loss 0.675262
epoch 3100, loss 0.856701
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
96.1397 130.797
32.0605 79.9049
64.3569 95.4117
101.017 138.513
38.6549 25.0749
parameters: [ 9.704  1.966  2.711  4.714  3.166]. error: 0.127569865319.
----------------------------
epoch 0, loss 1.23501
epoch 100, loss 0.965157
epoch 200, loss 1.37242
epoch 300, loss 1.12086
epoch 400, loss 0.566925
epoch 500, loss 0.686201
epoch 600, loss 0.605232
epoch 700, loss 0.865799
epoch 800, loss 0.690086
epoch 900, loss 0.819144
epoch 1000, loss 0.994576
epoch 1100, loss 0.865472
epoch 1200, loss 0.591057
epoch 1300, loss 0.67269
epoch 1400, loss 0.94721
epoch 1500, loss 0.893016
epoch 1600, loss 0.650336
epoch 1700, loss 0.782354
epoch 1800, loss 0.952527
epoch 1900, loss 0.65817
epoch 2000, loss 0.580018
epoch 2100, loss 0.483682
epoch 2200, loss 0.791725
epoch 2300, loss 0.539775
epoch 2400, loss 0.570572
epoch 2500, loss 0.799228
epoch 2600, loss 0.531012
epoch 2700, loss 0.819017
epoch 2800, loss 0.59875
epoch 2900, loss 1.01358
epoch 3000, loss 0.717633
epoch 3100, loss 0.600654
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
21.6939 49.6152
48.9224 45.9421
3.22686 28.0529
43.9272 70.0853
1321.38 152.859
parameters: [ 9.803  1.966  2.711  4.714  3.166]. error: 4.42549925498.
----------------------------
epoch 0, loss 1.36652
epoch 100, loss 1.14036
epoch 200, loss 1.46899
epoch 300, loss 1.27012
epoch 400, loss 1.08481
epoch 500, loss 1.18289
epoch 600, loss 1.27123
epoch 700, loss 1.57545
epoch 800, loss 0.869634
epoch 900, loss 0.977781
epoch 1000, loss 1.10092
epoch 1100, loss 0.816662
epoch 1200, loss 0.862633
epoch 1300, loss 0.682226
epoch 1400, loss 1.27508
epoch 1500, loss 0.747015
epoch 1600, loss 1.00463
epoch 1700, loss 0.744694
epoch 1800, loss 0.961056
epoch 1900, loss 1.00258
epoch 2000, loss 0.712656
epoch 2100, loss 0.624652
epoch 2200, loss 1.20902
epoch 2300, loss 0.938036
epoch 2400, loss 0.795982
epoch 2500, loss 0.52449
epoch 2600, loss 0.848005
epoch 2700, loss 0.612011
epoch 2800, loss 0.585742
epoch 2900, loss 0.580736
epoch 3000, loss 0.485866
epoch 3100, loss 0.552876
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
13.7745 21.6318
28.3521 35.3628
38.6549 29.4873
38.4634 167.036
13.7745 21.6318
parameters: [ 9.585  1.966  2.711  4.714  3.166]. error: 0.41268730697.
----------------------------
epoch 0, loss 1.25647
epoch 100, loss 0.803585
epoch 200, loss 1.24779
epoch 300, loss 0.932572
epoch 400, loss 0.445715
epoch 500, loss 0.828191
epoch 600, loss 0.713599
epoch 700, loss 0.607617
epoch 800, loss 0.736658
epoch 900, loss 1.08818
epoch 1000, loss 0.866594
epoch 1100, loss 0.625259
epoch 1200, loss 0.721015
epoch 1300, loss 0.552737
epoch 1400, loss 0.551789
epoch 1500, loss 0.666294
epoch 1600, loss 0.665023
epoch 1700, loss 0.638407
epoch 1800, loss 0.520501
epoch 1900, loss 0.548735
epoch 2000, loss 0.364059
epoch 2100, loss 0.568812
epoch 2200, loss 0.814053
epoch 2300, loss 0.624153
epoch 2400, loss 0.694204
epoch 2500, loss 0.733808
epoch 2600, loss 0.533679
epoch 2700, loss 0.788886
epoch 2800, loss 0.30678
epoch 2900, loss 0.399476
epoch 3000, loss 0.46192
epoch 3100, loss 0.561775
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
38.4634 359.145
234.37 76.8479
460.913 90.4656
22.953 28.4478
1.11386 20.545
parameters: [ 9.659  1.966  2.711  4.714  3.166]. error: 15.1972050237.
----------------------------
epoch 0, loss 0.999666
epoch 100, loss 1.05835
epoch 200, loss 1.09536
epoch 300, loss 1.07055
epoch 400, loss 0.925917
epoch 500, loss 0.948018
epoch 600, loss 0.953179
epoch 700, loss 0.736906
epoch 800, loss 0.759091
epoch 900, loss 0.994015
epoch 1000, loss 1.01515
epoch 1100, loss 1.31001
epoch 1200, loss 1.02981
epoch 1300, loss 0.856807
epoch 1400, loss 0.55107
epoch 1500, loss 0.727733
epoch 1600, loss 1.39794
epoch 1700, loss 0.854389
epoch 1800, loss 1.0084
epoch 1900, loss 0.683971
epoch 2000, loss 0.5102
epoch 2100, loss 0.71024
epoch 2200, loss 0.501254
epoch 2300, loss 1.09028
epoch 2400, loss 0.648229
epoch 2500, loss 0.679765
epoch 2600, loss 0.789582
epoch 2700, loss 0.730113
epoch 2800, loss 0.55888
epoch 2900, loss 0.785331
epoch 3000, loss 0.767039
epoch 3100, loss 0.472295
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
89.2785 36.4288
37.0194 102.256
14.1268 16.5366
94.9786 56.6443
40.0937 38.5144
parameters: [ 9.742  1.966  2.711  4.714  3.166]. error: 0.220836143682.
----------------------------
epoch 0, loss 1.85395
epoch 100, loss 0.851026
epoch 200, loss 0.843323
epoch 300, loss 0.532283
epoch 400, loss 0.934933
epoch 500, loss 0.787301
epoch 600, loss 0.830193
epoch 700, loss 0.656314
epoch 800, loss 1.08822
epoch 900, loss 1.22011
epoch 1000, loss 1.25475
epoch 1100, loss 1.09052
epoch 1200, loss 1.0078
epoch 1300, loss 0.750435
epoch 1400, loss 0.897511
epoch 1500, loss 1.37312
epoch 1600, loss 0.928562
epoch 1700, loss 0.8419
epoch 1800, loss 0.712476
epoch 1900, loss 1.02371
epoch 2000, loss 1.34709
epoch 2100, loss 0.86171
epoch 2200, loss 0.887413
epoch 2300, loss 1.46583
epoch 2400, loss 1.36529
epoch 2500, loss 1.15231
epoch 2600, loss 1.34512
epoch 2700, loss 1.14696
epoch 2800, loss 0.918928
epoch 2900, loss 0.416536
epoch 3000, loss 0.97268
epoch 3100, loss 0.645146
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
13.7745 54.2352
28.7444 85.519
106.094 52.8866
47.6327 53.8666
70.2845 76.8595
parameters: [ 9.687  1.966  2.711  4.714  3.166]. error: 0.364617979417.
----------------------------
epoch 0, loss 0.866763
epoch 100, loss 1.0077
epoch 200, loss 0.714957
epoch 300, loss 0.981656
epoch 400, loss 0.795019
epoch 500, loss 0.84378
epoch 600, loss 1.2702
epoch 700, loss 0.787661
epoch 800, loss 1.03057
epoch 900, loss 0.877739
epoch 1000, loss 1.19814
epoch 1100, loss 0.671016
epoch 1200, loss 1.19022
epoch 1300, loss 0.520212
epoch 1400, loss 0.718097
epoch 1500, loss 0.683051
epoch 1600, loss 0.844059
epoch 1700, loss 0.592732
epoch 1800, loss 1.01498
epoch 1900, loss 0.610001
epoch 2000, loss 0.901713
epoch 2100, loss 0.926092
epoch 2200, loss 0.816546
epoch 2300, loss 0.599534
epoch 2400, loss 0.917199
epoch 2500, loss 1.02959
epoch 2600, loss 0.648636
epoch 2700, loss 0.935911
epoch 2800, loss 0.722586
epoch 2900, loss 0.909836
epoch 3000, loss 0.608427
epoch 3100, loss 0.686944
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
20.2755 51.9669
1.11386 28.7475
101.017 120.208
56.7553 49.7874
25.6565 65.8356
parameters: [ 9.719  1.966  2.711  4.714  3.166]. error: 33.8533428797.
----------------------------
epoch 0, loss 0.999946
epoch 100, loss 1.20101
epoch 200, loss 0.79491
epoch 300, loss 0.941032
epoch 400, loss 0.508299
epoch 500, loss 0.450335
epoch 600, loss 0.877805
epoch 700, loss 0.696976
epoch 800, loss 0.871702
epoch 900, loss 0.732007
epoch 1000, loss 0.605441
epoch 1100, loss 0.524419
epoch 1200, loss 0.587865
epoch 1300, loss 0.774952
epoch 1400, loss 0.543286
epoch 1500, loss 0.735686
epoch 1600, loss 0.387793
epoch 1700, loss 0.772847
epoch 1800, loss 0.77919
epoch 1900, loss 0.587516
epoch 2000, loss 0.635665
epoch 2100, loss 0.399962
epoch 2200, loss 0.623167
epoch 2300, loss 0.73316
epoch 2400, loss 0.48052
epoch 2500, loss 0.616023
epoch 2600, loss 0.647816
epoch 2700, loss 0.462043
epoch 2800, loss 0.842358
epoch 2900, loss 0.496745
epoch 3000, loss 0.563054
epoch 3100, loss 0.473895
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
2.37471 28.5628
9.3969 30.4886
586.598 46.7483
39.4136 35.1952
1.11386 28.5628
parameters: [ 9.697  1.966  2.711  4.714  3.166]. error: 38.8760866093.
----------------------------
epoch 0, loss 0.557957
epoch 100, loss 0.793191
epoch 200, loss 1.14368
epoch 300, loss 0.912775
epoch 400, loss 0.81854
epoch 500, loss 1.03875
epoch 600, loss 0.852203
epoch 700, loss 1.15065
epoch 800, loss 0.858993
epoch 900, loss 1.21668
epoch 1000, loss 0.851971
epoch 1100, loss 0.961576
epoch 1200, loss 0.805731
epoch 1300, loss 0.658983
epoch 1400, loss 1.28728
epoch 1500, loss 1.30005
epoch 1600, loss 1.08852
epoch 1700, loss 0.517342
epoch 1800, loss 1.40201
epoch 1900, loss 0.733142
epoch 2000, loss 0.669961
epoch 2100, loss 0.806622
epoch 2200, loss 0.948806
epoch 2300, loss 0.722467
epoch 2400, loss 0.736712
epoch 2500, loss 0.999915
epoch 2600, loss 0.652256
epoch 2700, loss 0.753096
epoch 2800, loss 0.663603
epoch 2900, loss 0.51862
epoch 3000, loss 0.463619
epoch 3100, loss 0.948355
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
25.6565 52.5574
64.3569 68.0538
112.36 79.6916
9.3969 34.7253
194.962 104.087
parameters: [ 9.71   1.966  2.711  4.714  3.166]. error: 0.310530294012.
----------------------------
epoch 0, loss 1.56541
epoch 100, loss 1.27546
epoch 200, loss 1.009
epoch 300, loss 0.894773
epoch 400, loss 0.77877
epoch 500, loss 0.941922
epoch 600, loss 0.808107
epoch 700, loss 1.14159
epoch 800, loss 1.14932
epoch 900, loss 0.895347
epoch 1000, loss 0.97223
epoch 1100, loss 0.642931
epoch 1200, loss 0.858269
epoch 1300, loss 0.759727
epoch 1400, loss 0.609756
epoch 1500, loss 0.978797
epoch 1600, loss 0.910735
epoch 1700, loss 0.3545
epoch 1800, loss 0.888679
epoch 1900, loss 0.740565
epoch 2000, loss 0.538866
epoch 2100, loss 0.613466
epoch 2200, loss 0.880721
epoch 2300, loss 0.689494
epoch 2400, loss 0.674558
epoch 2500, loss 0.878914
epoch 2600, loss 0.687815
epoch 2700, loss 0.889995
epoch 2800, loss 0.399562
epoch 2900, loss 1.2596
epoch 3000, loss 0.99387
epoch 3100, loss 0.792225
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
246.534 56.8963
94.9786 56.4613
71.133 25.0002
53.6961 33.7307
67.5897 82.8962
parameters: [ 9.701  1.966  2.711  4.714  3.166]. error: 0.407483013071.
----------------------------
epoch 0, loss 0.877701
epoch 100, loss 1.19037
epoch 200, loss 1.11067
epoch 300, loss 0.545483
epoch 400, loss 0.571802
epoch 500, loss 0.950099
epoch 600, loss 0.85946
epoch 700, loss 0.731849
epoch 800, loss 0.760928
epoch 900, loss 1.30379
epoch 1000, loss 0.870585
epoch 1100, loss 0.694957
epoch 1200, loss 1.01744
epoch 1300, loss 0.955464
epoch 1400, loss 0.954159
epoch 1500, loss 0.722678
epoch 1600, loss 0.573822
epoch 1700, loss 1.09242
epoch 1800, loss 0.629136
epoch 1900, loss 0.872376
epoch 2000, loss 0.733729
epoch 2100, loss 0.704818
epoch 2200, loss 0.644047
epoch 2300, loss 0.693639
epoch 2400, loss 0.74936
epoch 2500, loss 0.526501
epoch 2600, loss 0.790246
epoch 2700, loss 0.857258
epoch 2800, loss 0.718674
epoch 2900, loss 0.945505
epoch 3000, loss 0.374575
epoch 3100, loss 0.410961
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
69.8093 51.5243
16.4294 38.9909
1321.38 163.256
69.8093 51.5243
25.6565 54.4991
parameters: [ 9.704  1.966  2.711  4.714  3.166]. error: 1.9505591861.
----------------------------
epoch 0, loss 0.846992
epoch 100, loss 1.16722
epoch 200, loss 0.881987
epoch 300, loss 1.46826
epoch 400, loss 0.645683
epoch 500, loss 1.44735
epoch 600, loss 0.998543
epoch 700, loss 0.599106
epoch 800, loss 1.34971
epoch 900, loss 0.698329
epoch 1000, loss 1.02757
epoch 1100, loss 1.26091
epoch 1200, loss 0.947305
epoch 1300, loss 1.20405
epoch 1400, loss 0.962975
epoch 1500, loss 1.27135
epoch 1600, loss 1.24151
epoch 1700, loss 1.08556
epoch 1800, loss 1.17294
epoch 1900, loss 0.96053
epoch 2000, loss 1.31659
epoch 2100, loss 1.281
epoch 2200, loss 0.82857
epoch 2300, loss 0.946232
epoch 2400, loss 0.914743
epoch 2500, loss 1.10775
epoch 2600, loss 0.949094
epoch 2700, loss 0.982502
epoch 2800, loss 0.936024
epoch 2900, loss 0.699153
epoch 3000, loss 0.868472
epoch 3100, loss 0.961185
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
1321.38 50.0533
112.36 68.3784
101.017 49.5912
33.8136 49.8272
53.6961 49.5659
parameters: [ 9.704  2.966  2.711  4.714  3.166]. error: 35.8352784082.
----------------------------
epoch 0, loss 1.65434
epoch 100, loss 1.38433
epoch 200, loss 0.879405
epoch 300, loss 1.40961
epoch 400, loss 1.34188
epoch 500, loss 0.733501
epoch 600, loss 1.52766
epoch 700, loss 0.921548
epoch 800, loss 0.627865
epoch 900, loss 0.927321
epoch 1000, loss 0.761259
epoch 1100, loss 0.703691
epoch 1200, loss 0.979275
epoch 1300, loss 1.13246
epoch 1400, loss 0.779893
epoch 1500, loss 1.04075
epoch 1600, loss 0.885123
epoch 1700, loss 0.646704
epoch 1800, loss 1.0249
epoch 1900, loss 0.627013
epoch 2000, loss 1.20445
epoch 2100, loss 0.48074
epoch 2200, loss 0.667088
epoch 2300, loss 0.768626
epoch 2400, loss 0.730959
epoch 2500, loss 0.663879
epoch 2600, loss 0.555512
epoch 2700, loss 0.738039
epoch 2800, loss 0.541445
epoch 2900, loss 0.396183
epoch 3000, loss 0.675115
epoch 3100, loss 0.372605
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
47.6327 41.3207
70.2845 131.48
586.598 22.6918
460.913 110.853
70.2845 131.48
parameters: [ 9.704  0.348  2.711  4.714  3.166]. error: 34.0242487661.
----------------------------
epoch 0, loss 1.20819
epoch 100, loss 0.854751
epoch 200, loss 1.13062
epoch 300, loss 0.952144
epoch 400, loss 1.06684
epoch 500, loss 0.994484
epoch 600, loss 0.765954
epoch 700, loss 0.892144
epoch 800, loss 0.9451
epoch 900, loss 0.858913
epoch 1000, loss 1.06235
epoch 1100, loss 0.876768
epoch 1200, loss 1.00852
epoch 1300, loss 0.796675
epoch 1400, loss 0.476391
epoch 1500, loss 0.987979
epoch 1600, loss 0.809786
epoch 1700, loss 0.814248
epoch 1800, loss 0.988516
epoch 1900, loss 0.774591
epoch 2000, loss 0.823901
epoch 2100, loss 0.896891
epoch 2200, loss 0.777797
epoch 2300, loss 0.765565
epoch 2400, loss 0.641418
epoch 2500, loss 0.790375
epoch 2600, loss 0.735105
epoch 2700, loss 1.12509
epoch 2800, loss 0.777983
epoch 2900, loss 0.986843
epoch 3000, loss 0.75899
epoch 3100, loss 0.96641
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
112.36 61.0057
21.6939 44.442
1.11386 33.5728
39.4136 51.7578
28.3521 73.4396
parameters: [ 9.704  1.966  2.711  4.714  3.166]. error: 49.9221643434.
----------------------------
epoch 0, loss 1.27821
epoch 100, loss 1.40639
epoch 200, loss 1.2564
epoch 300, loss 1.28888
epoch 400, loss 1.05328
epoch 500, loss 0.867945
epoch 600, loss 1.39469
epoch 700, loss 0.636479
epoch 800, loss 0.754698
epoch 900, loss 0.901065
epoch 1000, loss 1.32915
epoch 1100, loss 1.0696
epoch 1200, loss 1.10288
epoch 1300, loss 0.357305
epoch 1400, loss 0.267669
epoch 1500, loss 0.464523
epoch 1600, loss 0.938551
epoch 1700, loss 0.526003
epoch 1800, loss 0.627407
epoch 1900, loss 0.72748
epoch 2000, loss 0.428596
epoch 2100, loss 0.474021
epoch 2200, loss 0.543732
epoch 2300, loss 0.501324
epoch 2400, loss 0.45112
epoch 2500, loss 0.809386
epoch 2600, loss 0.608901
epoch 2700, loss 0.63555
epoch 2800, loss 0.824989
epoch 2900, loss 0.762275
epoch 3000, loss 0.592054
epoch 3100, loss 0.814847
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
146.624 55.3643
16.4294 35.4403
67.5897 72.462
112.36 66.7513
64.3569 65.5711
parameters: [ 9.704  1.348  2.711  4.714  3.166]. error: 0.182483190788.
----------------------------
epoch 0, loss 1.50346
epoch 100, loss 1.20091
epoch 200, loss 0.761041
epoch 300, loss 1.07538
epoch 400, loss 0.471896
epoch 500, loss 0.480395
epoch 600, loss 0.434413
epoch 700, loss 0.673496
epoch 800, loss 0.733856
epoch 900, loss 0.934037
epoch 1000, loss 0.614595
epoch 1100, loss 0.539199
epoch 1200, loss 0.703788
epoch 1300, loss 0.588912
epoch 1400, loss 0.544494
epoch 1500, loss 0.470551
epoch 1600, loss 0.528447
epoch 1700, loss 0.826083
epoch 1800, loss 0.555179
epoch 1900, loss 0.946761
epoch 2000, loss 0.390921
epoch 2100, loss 0.849603
epoch 2200, loss 0.445925
epoch 2300, loss 0.556925
epoch 2400, loss 0.371221
epoch 2500, loss 0.58157
epoch 2600, loss 0.582094
epoch 2700, loss 0.758538
epoch 2800, loss 0.386121
epoch 2900, loss 0.735413
epoch 3000, loss 0.734174
epoch 3100, loss 0.782033
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
112.36 82.8708
16.4294 39.5039
38.304 51.9026
259.052 70.908
47.6327 46.4197
parameters: [ 9.704  0.966  2.711  4.714  3.166]. error: 0.344760596171.
----------------------------
epoch 0, loss 1.76427
epoch 100, loss 1.7894
epoch 200, loss 1.14233
epoch 300, loss 0.740628
epoch 400, loss 0.956095
epoch 500, loss 0.827078
epoch 600, loss 1.07998
epoch 700, loss 0.826485
epoch 800, loss 1.21879
epoch 900, loss 0.704246
epoch 1000, loss 0.973042
epoch 1100, loss 0.707505
epoch 1200, loss 1.28631
epoch 1300, loss 1.16082
epoch 1400, loss 1.12839
epoch 1500, loss 0.814275
epoch 1600, loss 0.67782
epoch 1700, loss 1.02327
epoch 1800, loss 0.771298
epoch 1900, loss 0.735592
epoch 2000, loss 0.939555
epoch 2100, loss 0.497954
epoch 2200, loss 0.616142
epoch 2300, loss 0.523862
epoch 2400, loss 0.937483
epoch 2500, loss 0.65583
epoch 2600, loss 0.927599
epoch 2700, loss 0.715771
epoch 2800, loss 0.546829
epoch 2900, loss 0.659154
epoch 3000, loss 0.612373
epoch 3100, loss 0.667996
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
47.4619 84.394
31.6796 40.7038
28.7444 49.548
14.1268 28.2153
22.953 33.5129
parameters: [ 9.704  1.159  2.711  4.714  3.166]. error: 0.0617207565131.
----------------------------
epoch 0, loss 0.864721
epoch 100, loss 1.21056
epoch 200, loss 1.06925
epoch 300, loss 0.839324
epoch 400, loss 1.07779
epoch 500, loss 0.941934
epoch 600, loss 1.02935
epoch 700, loss 0.792075
epoch 800, loss 0.690042
epoch 900, loss 0.825011
epoch 1000, loss 1.0351
epoch 1100, loss 0.574632
epoch 1200, loss 0.402733
epoch 1300, loss 0.645088
epoch 1400, loss 0.772618
epoch 1500, loss 0.400072
epoch 1600, loss 0.492421
epoch 1700, loss 0.639642
epoch 1800, loss 0.418408
epoch 1900, loss 0.553471
epoch 2000, loss 0.464783
epoch 2100, loss 0.507192
epoch 2200, loss 0.335494
epoch 2300, loss 0.454166
epoch 2400, loss 0.506946
epoch 2500, loss 0.557722
epoch 2600, loss 0.950564
epoch 2700, loss 0.397694
epoch 2800, loss 0.492145
epoch 2900, loss 0.467925
epoch 3000, loss 0.451969
epoch 3100, loss 0.398841
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
146.624 68.6422
13.2248 21.0504
33.7234 32.1563
43.9272 16.985
101.017 144.697
parameters: [ 9.704  1.195  2.711  4.714  3.166]. error: 0.139528836958.
----------------------------
epoch 0, loss 0.704618
epoch 100, loss 0.818784
epoch 200, loss 0.875201
epoch 300, loss 0.56025
epoch 400, loss 0.649792
epoch 500, loss 0.916158
epoch 600, loss 0.877648
epoch 700, loss 0.842208
epoch 800, loss 0.807412
epoch 900, loss 0.933836
epoch 1000, loss 0.496845
epoch 1100, loss 0.621192
epoch 1200, loss 0.588922
epoch 1300, loss 0.672626
epoch 1400, loss 0.883818
epoch 1500, loss 0.770986
epoch 1600, loss 0.895995
epoch 1700, loss 0.987785
epoch 1800, loss 0.866751
epoch 1900, loss 0.644943
epoch 2000, loss 0.609345
epoch 2100, loss 0.832693
epoch 2200, loss 0.96385
epoch 2300, loss 0.645551
epoch 2400, loss 0.831966
epoch 2500, loss 0.619822
epoch 2600, loss 0.804258
epoch 2700, loss 0.528728
epoch 2800, loss 0.815394
epoch 2900, loss 0.932023
epoch 3000, loss 0.478235
epoch 3100, loss 0.498273
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
38.304 66.4136
96.1397 112.768
1.11386 35.6796
2.37471 35.6796
47.6327 51.1082
parameters: [ 9.704  1.085  2.711  4.714  3.166]. error: 58.0811292301.
----------------------------
epoch 0, loss 1.37796
epoch 100, loss 1.07668
epoch 200, loss 1.40727
epoch 300, loss 0.615935
epoch 400, loss 0.623587
epoch 500, loss 0.633762
epoch 600, loss 0.541727
epoch 700, loss 0.756151
epoch 800, loss 0.337896
epoch 900, loss 0.702335
epoch 1000, loss 0.517862
epoch 1100, loss 0.593826
epoch 1200, loss 0.523469
epoch 1300, loss 0.431494
epoch 1400, loss 0.515476
epoch 1500, loss 0.690985
epoch 1600, loss 0.417182
epoch 1700, loss 0.563796
epoch 1800, loss 0.413762
epoch 1900, loss 0.853805
epoch 2000, loss 0.38533
epoch 2100, loss 0.477625
epoch 2200, loss 0.570166
epoch 2300, loss 0.368154
epoch 2400, loss 0.542067
epoch 2500, loss 0.535031
epoch 2600, loss 0.588404
epoch 2700, loss 0.440396
epoch 2800, loss 0.4171
epoch 2900, loss 0.522133
epoch 3000, loss 0.458507
epoch 3100, loss 0.600098
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
19.4471 26.9903
605.821 244.817
101.017 232.397
3167.53 465.868
70.3904 120.843
parameters: [ 9.704  1.131  2.711  4.714  3.166]. error: 1.28571722431.
----------------------------
epoch 0, loss 1.18983
epoch 100, loss 0.716784
epoch 200, loss 0.698766
epoch 300, loss 0.448382
epoch 400, loss 0.586877
epoch 500, loss 0.419804
epoch 600, loss 0.828113
epoch 700, loss 0.781273
epoch 800, loss 0.755739
epoch 900, loss 0.618571
epoch 1000, loss 0.297112
epoch 1100, loss 0.55484
epoch 1200, loss 0.513867
epoch 1300, loss 0.566013
epoch 1400, loss 0.568868
epoch 1500, loss 0.759461
epoch 1600, loss 0.406547
epoch 1700, loss 0.487834
epoch 1800, loss 0.549001
epoch 1900, loss 0.566441
epoch 2000, loss 0.459091
epoch 2100, loss 0.464291
epoch 2200, loss 0.35235
epoch 2300, loss 0.43579
epoch 2400, loss 0.33484
epoch 2500, loss 0.61718
epoch 2600, loss 0.490105
epoch 2700, loss 0.48303
epoch 2800, loss 0.498516
epoch 2900, loss 0.640332
epoch 3000, loss 0.498198
epoch 3100, loss 0.367776
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
116.598 71.4133
1.11386 21.417
31.6796 38.9905
14.1268 23.8855
33.7234 36.6659
parameters: [ 9.704  1.173  2.711  4.714  3.166]. error: 16.2455125833.
----------------------------
epoch 0, loss 0.89903
epoch 100, loss 1.05829
epoch 200, loss 1.20808
epoch 300, loss 0.953711
epoch 400, loss 0.763866
epoch 500, loss 1.03927
epoch 600, loss 0.473457
epoch 700, loss 1.14848
epoch 800, loss 1.47111
epoch 900, loss 0.91738
epoch 1000, loss 1.4834
epoch 1100, loss 0.760402
epoch 1200, loss 0.852333
epoch 1300, loss 1.07507
epoch 1400, loss 0.91967
epoch 1500, loss 0.796808
epoch 1600, loss 0.87408
epoch 1700, loss 0.942044
epoch 1800, loss 0.803314
epoch 1900, loss 0.474266
epoch 2000, loss 0.9324
epoch 2100, loss 0.914775
epoch 2200, loss 0.762441
epoch 2300, loss 0.815904
epoch 2400, loss 1.03274
epoch 2500, loss 0.495665
epoch 2600, loss 1.10383
epoch 2700, loss 0.952374
epoch 2800, loss 0.695749
epoch 2900, loss 0.553527
epoch 3000, loss 0.416674
epoch 3100, loss 0.732695
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
146.624 84.4212
47.4619 83.0646
19.4471 35.2486
69.8093 82.713
13.842 35.9321
parameters: [ 9.704  1.149  2.711  4.714  3.166]. error: 0.148324709306.
----------------------------
epoch 0, loss 1.00254
epoch 100, loss 0.834774
epoch 200, loss 0.908121
epoch 300, loss 1.56996
epoch 400, loss 0.814275
epoch 500, loss 1.21076
epoch 600, loss 0.43407
epoch 700, loss 0.623176
epoch 800, loss 0.727955
epoch 900, loss 0.806659
epoch 1000, loss 0.723322
epoch 1100, loss 0.445284
epoch 1200, loss 0.775385
epoch 1300, loss 0.945516
epoch 1400, loss 0.60057
epoch 1500, loss 0.595005
epoch 1600, loss 0.4713
epoch 1700, loss 0.620092
epoch 1800, loss 0.526903
epoch 1900, loss 0.467959
epoch 2000, loss 0.742891
epoch 2100, loss 0.404451
epoch 2200, loss 0.541511
epoch 2300, loss 0.76075
epoch 2400, loss 0.793895
epoch 2500, loss 0.672128
epoch 2600, loss 0.550249
epoch 2700, loss 0.490943
epoch 2800, loss 0.624714
epoch 2900, loss 0.464413
epoch 3000, loss 0.562333
epoch 3100, loss 0.411046
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
31.6796 35.3712
45.3756 73.484
3.22686 14.2575
96.1397 46.591
47.6327 34.3605
parameters: [ 9.704  1.159  2.711  4.714  3.166]. error: 0.471517576255.
----------------------------
epoch 0, loss 0.424819
epoch 100, loss 1.02308
epoch 200, loss 1.03604
epoch 300, loss 0.736088
epoch 400, loss 1.11339
epoch 500, loss 0.765513
epoch 600, loss 0.690098
epoch 700, loss 1.07572
epoch 800, loss 0.935679
epoch 900, loss 0.544173
epoch 1000, loss 1.21781
epoch 1100, loss 0.446572
epoch 1200, loss 0.843846
epoch 1300, loss 0.873604
epoch 1400, loss 1.12795
epoch 1500, loss 0.713592
epoch 1600, loss 0.569233
epoch 1700, loss 0.665674
epoch 1800, loss 0.764312
epoch 1900, loss 0.895388
epoch 2000, loss 0.561996
epoch 2100, loss 0.837797
epoch 2200, loss 0.794344
epoch 2300, loss 1.61186
epoch 2400, loss 0.988872
epoch 2500, loss 0.671892
epoch 2600, loss 1.12441
epoch 2700, loss 0.84304
epoch 2800, loss 0.913699
epoch 2900, loss 1.35834
epoch 3000, loss 0.665555
epoch 3100, loss 0.715686
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
3167.53 87.662
64.3569 82.6356
38.4634 103.52
3.22686 48.3419
112.36 93.827
parameters: [ 9.704  1.159  3.711  4.714  3.166]. error: 87.1694722152.
----------------------------
epoch 0, loss 1.09827
epoch 100, loss 0.272904
epoch 200, loss 0.714857
epoch 300, loss 0.577369
epoch 400, loss 0.365034
epoch 500, loss 0.518794
epoch 600, loss 0.455952
epoch 700, loss 0.289639
epoch 800, loss 0.487952
epoch 900, loss 0.205374
epoch 1000, loss 0.452421
epoch 1100, loss 0.535864
epoch 1200, loss 0.237085
epoch 1300, loss 0.400699
epoch 1400, loss 0.242264
epoch 1500, loss 0.448846
epoch 1600, loss 0.407967
epoch 1700, loss 0.351769
epoch 1800, loss 0.306787
epoch 1900, loss 0.307967
epoch 2000, loss 0.273347
epoch 2100, loss 0.361001
epoch 2200, loss 0.625271
epoch 2300, loss 0.502378
epoch 2400, loss 0.421338
epoch 2500, loss 0.527831
epoch 2600, loss 0.489524
epoch 2700, loss 0.288352
epoch 2800, loss 0.394203
epoch 2900, loss 0.294704
epoch 3000, loss 0.281665
epoch 3100, loss 0.519906
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
20.2755 25.3793
71.8482 45.3041
94.9786 107.811
21.6939 41.4102
259.052 107.811
parameters: [ 9.704  1.159  1.093  4.714  3.166]. error: 0.13983781531.
----------------------------
epoch 0, loss 1.4742
epoch 100, loss 0.958049
epoch 200, loss 0.721909
epoch 300, loss 0.519405
epoch 400, loss 0.425192
epoch 500, loss 0.899806
epoch 600, loss 0.738052
epoch 700, loss 0.490594
epoch 800, loss 0.517833
epoch 900, loss 0.644357
epoch 1000, loss 0.194264
epoch 1100, loss 0.368466
epoch 1200, loss 0.558455
epoch 1300, loss 0.643622
epoch 1400, loss 0.754724
epoch 1500, loss 0.351082
epoch 1600, loss 0.378287
epoch 1700, loss 0.59727
epoch 1800, loss 0.327443
epoch 1900, loss 0.459431
epoch 2000, loss 1.05417
epoch 2100, loss 0.876638
epoch 2200, loss 0.387772
epoch 2300, loss 0.715837
epoch 2400, loss 0.915125
epoch 2500, loss 0.595976
epoch 2600, loss 0.758119
epoch 2700, loss 0.485859
epoch 2800, loss 0.303829
epoch 2900, loss 0.757393
epoch 3000, loss 0.738703
epoch 3100, loss 0.843833
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
106.094 47.6606
112.36 100.188
38.6549 22.6067
13.7745 20.6334
48.9224 40.296
parameters: [ 9.704  1.159  1.899  4.714  3.166]. error: 0.101393698973.
----------------------------
epoch 0, loss 1.02612
epoch 100, loss 0.668431
epoch 200, loss 0.745367
epoch 300, loss 1.00573
epoch 400, loss 0.664178
epoch 500, loss 0.383779
epoch 600, loss 0.533862
epoch 700, loss 0.657055
epoch 800, loss 0.323382
epoch 900, loss 0.423606
epoch 1000, loss 0.652032
epoch 1100, loss 0.576293
epoch 1200, loss 0.540483
epoch 1300, loss 0.293704
epoch 1400, loss 0.199693
epoch 1500, loss 0.6032
epoch 1600, loss 0.745662
epoch 1700, loss 0.409077
epoch 1800, loss 0.446525
epoch 1900, loss 0.290931
epoch 2000, loss 0.329785
epoch 2100, loss 0.471206
epoch 2200, loss 0.463947
epoch 2300, loss 0.78873
epoch 2400, loss 0.298638
epoch 2500, loss 0.604347
epoch 2600, loss 0.540824
epoch 2700, loss 0.394913
epoch 2800, loss 0.41087
epoch 2900, loss 0.517668
epoch 3000, loss 0.454342
epoch 3100, loss 0.477112
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
209.705 50.2378
32.9279 75.7401
3167.53 655.697
38.304 91.404
3167.53 655.697
parameters: [ 9.704  1.159  1.899  4.714  3.166]. error: 0.600877675932.
----------------------------
epoch 0, loss 1.85056
epoch 100, loss 1.3823
epoch 200, loss 1.11357
epoch 300, loss 0.876885
epoch 400, loss 0.666102
epoch 500, loss 0.926741
epoch 600, loss 0.777345
epoch 700, loss 0.542995
epoch 800, loss 1.0382
epoch 900, loss 0.542467
epoch 1000, loss 0.777495
epoch 1100, loss 0.583731
epoch 1200, loss 0.546178
epoch 1300, loss 0.440448
epoch 1400, loss 0.578433
epoch 1500, loss 0.379892
epoch 1600, loss 0.525407
epoch 1700, loss 0.642872
epoch 1800, loss 0.455499
epoch 1900, loss 0.543286
epoch 2000, loss 0.475928
epoch 2100, loss 0.775994
epoch 2200, loss 0.933774
epoch 2300, loss 0.604393
epoch 2400, loss 0.53832
epoch 2500, loss 0.647896
epoch 2600, loss 0.370365
epoch 2700, loss 0.379465
epoch 2800, loss 0.508025
epoch 2900, loss 0.469603
epoch 3000, loss 0.439654
epoch 3100, loss 0.439118
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
209.705 37.9211
23.1269 31.8522
106.094 41.1759
146.624 61.8254
33.8136 29.867
parameters: [ 9.704  1.159  2.209  4.714  3.166]. error: 0.741408928252.
----------------------------
epoch 0, loss 0.962636
epoch 100, loss 0.638696
epoch 200, loss 0.993242
epoch 300, loss 0.555534
epoch 400, loss 0.699078
epoch 500, loss 0.75558
epoch 600, loss 0.558615
epoch 700, loss 0.353125
epoch 800, loss 0.723869
epoch 900, loss 0.406976
epoch 1000, loss 0.330848
epoch 1100, loss 0.402772
epoch 1200, loss 0.264513
epoch 1300, loss 0.489667
epoch 1400, loss 0.503435
epoch 1500, loss 0.515731
epoch 1600, loss 0.43973
epoch 1700, loss 0.240852
epoch 1800, loss 0.451614
epoch 1900, loss 0.363602
epoch 2000, loss 0.616832
epoch 2100, loss 0.773085
epoch 2200, loss 0.464474
epoch 2300, loss 0.822797
epoch 2400, loss 0.706742
epoch 2500, loss 0.657008
epoch 2600, loss 0.350772
epoch 2700, loss 0.359696
epoch 2800, loss 0.567955
epoch 2900, loss 0.493903
epoch 3000, loss 0.456573
epoch 3100, loss 0.54589
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
38.6549 22.1209
39.4136 35.9455
64.3569 68.1995
70.2845 107.2
31.6796 35.36
parameters: [ 9.704  1.159  1.591  4.714  3.166]. error: 0.0690951153049.
----------------------------
epoch 0, loss 1.10229
epoch 100, loss 0.577329
epoch 200, loss 0.801296
epoch 300, loss 0.512033
epoch 400, loss 0.668213
epoch 500, loss 0.344247
epoch 600, loss 0.568872
epoch 700, loss 0.620468
epoch 800, loss 0.516825
epoch 900, loss 0.469222
epoch 1000, loss 0.750732
epoch 1100, loss 0.578125
epoch 1200, loss 0.368608
epoch 1300, loss 0.471763
epoch 1400, loss 0.483041
epoch 1500, loss 0.77691
epoch 1600, loss 0.516763
epoch 1700, loss 0.422011
epoch 1800, loss 0.391833
epoch 1900, loss 0.467807
epoch 2000, loss 0.401007
epoch 2100, loss 0.438764
epoch 2200, loss 0.337062
epoch 2300, loss 0.598178
epoch 2400, loss 0.719502
epoch 2500, loss 0.708979
epoch 2600, loss 0.431709
epoch 2700, loss 0.30821
epoch 2800, loss 0.473642
epoch 2900, loss 0.383474
epoch 3000, loss 0.423267
epoch 3100, loss 0.439409
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
37.0194 107.052
13.7745 15.4321
45.3756 65.4184
32.0605 107.052
112.36 96.0719
parameters: [ 9.704  1.159  1.401  4.714  3.166]. error: 0.218527957378.
----------------------------
epoch 0, loss 1.60298
epoch 100, loss 0.444463
epoch 200, loss 0.750651
epoch 300, loss 0.471738
epoch 400, loss 0.678401
epoch 500, loss 0.426972
epoch 600, loss 0.497819
epoch 700, loss 0.502236
epoch 800, loss 0.770433
epoch 900, loss 0.672739
epoch 1000, loss 0.61554
epoch 1100, loss 0.669943
epoch 1200, loss 0.691612
epoch 1300, loss 0.231378
epoch 1400, loss 0.522881
epoch 1500, loss 0.528168
epoch 1600, loss 0.609893
epoch 1700, loss 0.714606
epoch 1800, loss 0.520533
epoch 1900, loss 0.377951
epoch 2000, loss 0.535061
epoch 2100, loss 0.389765
epoch 2200, loss 0.434161
epoch 2300, loss 0.621193
epoch 2400, loss 1.07311
epoch 2500, loss 0.79698
epoch 2600, loss 0.576609
epoch 2700, loss 0.421738
epoch 2800, loss 0.342647
epoch 2900, loss 0.354865
epoch 3000, loss 0.544165
epoch 3100, loss 0.389276
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
40.0937 45.9076
101.017 177.694
13.9704 44.1117
116.598 94.8369
3.22686 19.8485
parameters: [ 9.704  1.159  1.574  4.714  3.166]. error: 0.955116161003.
----------------------------
epoch 0, loss 1.87087
epoch 100, loss 0.925798
epoch 200, loss 0.488638
epoch 300, loss 0.435455
epoch 400, loss 0.496434
epoch 500, loss 0.619799
epoch 600, loss 0.667896
epoch 700, loss 0.635601
epoch 800, loss 0.588787
epoch 900, loss 0.334501
epoch 1000, loss 0.396042
epoch 1100, loss 0.497224
epoch 1200, loss 0.392729
epoch 1300, loss 0.649214
epoch 1400, loss 0.498568
epoch 1500, loss 0.514193
epoch 1600, loss 0.496407
epoch 1700, loss 0.47299
epoch 1800, loss 0.68255
epoch 1900, loss 0.692865
epoch 2000, loss 0.435423
epoch 2100, loss 0.270239
epoch 2200, loss 0.558397
epoch 2300, loss 0.619223
epoch 2400, loss 0.595199
epoch 2500, loss 0.388466
epoch 2600, loss 0.511485
epoch 2700, loss 0.529716
epoch 2800, loss 0.652399
epoch 2900, loss 0.462025
epoch 3000, loss 0.63231
epoch 3100, loss 0.422764
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
89.7385 549.295
20.2755 27.8871
94.9786 138.374
23.1269 38.5574
22.953 21.1273
parameters: [ 9.704  1.159  1.709  4.714  3.166]. error: 0.939275750234.
----------------------------
epoch 0, loss 1.19174
epoch 100, loss 0.661041
epoch 200, loss 1.14408
epoch 300, loss 0.490923
epoch 400, loss 0.527842
epoch 500, loss 0.639737
epoch 600, loss 0.586176
epoch 700, loss 0.538099
epoch 800, loss 0.457129
epoch 900, loss 0.501486
epoch 1000, loss 0.556789
epoch 1100, loss 0.27998
epoch 1200, loss 0.341535
epoch 1300, loss 0.565172
epoch 1400, loss 0.436997
epoch 1500, loss 0.398647
epoch 1600, loss 0.415987
epoch 1700, loss 0.339487
epoch 1800, loss 0.280324
epoch 1900, loss 0.577239
epoch 2000, loss 0.551734
epoch 2100, loss 0.689918
epoch 2200, loss 0.712308
epoch 2300, loss 0.443328
epoch 2400, loss 0.507664
epoch 2500, loss 0.281075
epoch 2600, loss 0.472854
epoch 2700, loss 0.686732
epoch 2800, loss 0.355161
epoch 2900, loss 0.38158
epoch 3000, loss 0.597081
epoch 3100, loss 0.39244
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
71.133 14.0389
101.017 237.229
25.6565 60.6361
79.3243 15.8285
13.2248 15.8509
parameters: [ 9.704  1.159  1.636  4.714  3.166]. error: 0.663760084452.
----------------------------
epoch 0, loss 1.31767
epoch 100, loss 0.849345
epoch 200, loss 0.417712
epoch 300, loss 0.708548
epoch 400, loss 0.353483
epoch 500, loss 0.329913
epoch 600, loss 0.240052
epoch 700, loss 0.50643
epoch 800, loss 0.319199
epoch 900, loss 0.43948
epoch 1000, loss 0.51354
epoch 1100, loss 0.471833
epoch 1200, loss 0.488421
epoch 1300, loss 0.440043
epoch 1400, loss 0.699356
epoch 1500, loss 0.683615
epoch 1600, loss 0.492221
epoch 1700, loss 0.47748
epoch 1800, loss 0.604754
epoch 1900, loss 0.38205
epoch 2000, loss 0.371468
epoch 2100, loss 0.514132
epoch 2200, loss 0.392484
epoch 2300, loss 0.387831
epoch 2400, loss 0.432852
epoch 2500, loss 0.403368
epoch 2600, loss 0.499207
epoch 2700, loss 0.440178
epoch 2800, loss 0.413344
epoch 2900, loss 0.430714
epoch 3000, loss 0.517684
epoch 3100, loss 0.431017
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
32.0605 66.4869
79.3243 22.5768
16.4294 31.7543
38.4634 175.932
47.4619 94.5362
parameters: [ 9.704  1.159  1.608  4.714  3.166]. error: 0.678846159639.
----------------------------
epoch 0, loss 1.33758
epoch 100, loss 0.636772
epoch 200, loss 0.875211
epoch 300, loss 0.47293
epoch 400, loss 0.5519
epoch 500, loss 0.459837
epoch 600, loss 0.45874
epoch 700, loss 0.680632
epoch 800, loss 0.485402
epoch 900, loss 0.666246
epoch 1000, loss 0.740414
epoch 1100, loss 0.871501
epoch 1200, loss 0.519174
epoch 1300, loss 0.787509
epoch 1400, loss 0.309425
epoch 1500, loss 0.484623
epoch 1600, loss 0.575062
epoch 1700, loss 0.465381
epoch 1800, loss 0.668885
epoch 1900, loss 0.618611
epoch 2000, loss 0.426743
epoch 2100, loss 0.469427
epoch 2200, loss 0.367128
epoch 2300, loss 0.387075
epoch 2400, loss 0.735995
epoch 2500, loss 0.545478
epoch 2600, loss 0.566435
epoch 2700, loss 0.218644
epoch 2800, loss 0.479445
epoch 2900, loss 0.350232
epoch 3000, loss 0.708644
epoch 3100, loss 0.364174
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
13.9704 31.9633
28.7444 90.5213
70.3904 114.845
28.3521 90.5213
20.2734 32.6687
parameters: [ 9.704  1.159  1.591  4.714  3.166]. error: 0.18517662708.
----------------------------
epoch 0, loss 1.74065
epoch 100, loss 1.13764
epoch 200, loss 0.840284
epoch 300, loss 0.731433
epoch 400, loss 0.578685
epoch 500, loss 0.639403
epoch 600, loss 0.481384
epoch 700, loss 0.708431
epoch 800, loss 0.446686
epoch 900, loss 0.435078
epoch 1000, loss 0.316192
epoch 1100, loss 0.40387
epoch 1200, loss 0.556137
epoch 1300, loss 0.470536
epoch 1400, loss 0.348284
epoch 1500, loss 0.641574
epoch 1600, loss 0.450998
epoch 1700, loss 0.752577
epoch 1800, loss 0.58849
epoch 1900, loss 0.454836
epoch 2000, loss 0.462299
epoch 2100, loss 0.399437
epoch 2200, loss 0.449533
epoch 2300, loss 0.330062
epoch 2400, loss 0.334998
epoch 2500, loss 0.332609
epoch 2600, loss 0.458578
epoch 2700, loss 0.510069
epoch 2800, loss 0.322869
epoch 2900, loss 0.50161
epoch 3000, loss 0.458286
epoch 3100, loss 0.639315
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
31.6796 25.2695
831.403 575.596
605.821 423.143
116.598 58.5313
64.3569 60.5571
parameters: [ 9.704  1.159  1.591  5.714  3.166]. error: 0.0645975373758.
----------------------------
epoch 0, loss 1.30009
epoch 100, loss 1.25555
epoch 200, loss 0.658946
epoch 300, loss 0.571763
epoch 400, loss 0.541157
epoch 500, loss 0.545515
epoch 600, loss 0.545565
epoch 700, loss 0.571375
epoch 800, loss 0.706543
epoch 900, loss 0.528038
epoch 1000, loss 0.624377
epoch 1100, loss 0.458507
epoch 1200, loss 0.455693
epoch 1300, loss 0.765056
epoch 1400, loss 0.493467
epoch 1500, loss 0.387425
epoch 1600, loss 0.378058
epoch 1700, loss 0.405201
epoch 1800, loss 0.553942
epoch 1900, loss 0.558411
epoch 2000, loss 0.359885
epoch 2100, loss 0.327981
epoch 2200, loss 0.42574
epoch 2300, loss 0.496168
epoch 2400, loss 0.506065
epoch 2500, loss 0.341624
epoch 2600, loss 0.440782
epoch 2700, loss 0.462709
epoch 2800, loss 0.397456
epoch 2900, loss 0.398178
epoch 3000, loss 0.559453
epoch 3100, loss 0.637036
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
64.3569 59.2444
71.8482 39.937
64.3569 59.2444
57.0616 43.9154
831.403 280.33
parameters: [ 9.704  1.159  1.591  7.332  3.166]. error: 0.159610504691.
----------------------------
epoch 0, loss 1.33327
epoch 100, loss 0.962857
epoch 200, loss 0.473499
epoch 300, loss 0.421582
epoch 400, loss 0.545548
epoch 500, loss 0.35637
epoch 600, loss 0.423047
epoch 700, loss 0.657077
epoch 800, loss 0.361734
epoch 900, loss 0.448484
epoch 1000, loss 0.468525
epoch 1100, loss 0.454303
epoch 1200, loss 0.29139
epoch 1300, loss 0.584264
epoch 1400, loss 0.53112
epoch 1500, loss 0.600569
epoch 1600, loss 0.322435
epoch 1700, loss 0.409038
epoch 1800, loss 0.567601
epoch 1900, loss 0.383626
epoch 2000, loss 0.561808
epoch 2100, loss 0.333851
epoch 2200, loss 0.592947
epoch 2300, loss 0.463755
epoch 2400, loss 0.436885
epoch 2500, loss 0.450308
epoch 2600, loss 0.275244
epoch 2700, loss 0.621847
epoch 2800, loss 0.342765
epoch 2900, loss 0.608962
epoch 3000, loss 0.42311
epoch 3100, loss 0.481113
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
10.5701 12.5907
31.6796 39.7176
22.953 18.4649
246.534 78.2196
67.5897 130.519
parameters: [ 9.704  1.159  1.591  5.714  3.166]. error: 0.228179933633.
----------------------------
epoch 0, loss 1.20843
epoch 100, loss 1.14396
epoch 200, loss 0.78795
epoch 300, loss 0.495965
epoch 400, loss 0.79756
epoch 500, loss 0.697949
epoch 600, loss 0.440357
epoch 700, loss 0.703276
epoch 800, loss 0.573692
epoch 900, loss 0.429601
epoch 1000, loss 0.601888
epoch 1100, loss 0.597355
epoch 1200, loss 0.565569
epoch 1300, loss 0.681593
epoch 1400, loss 0.380068
epoch 1500, loss 0.590442
epoch 1600, loss 0.466888
epoch 1700, loss 0.587048
epoch 1800, loss 0.553439
epoch 1900, loss 0.304565
epoch 2000, loss 0.48356
epoch 2100, loss 0.635551
epoch 2200, loss 0.611988
epoch 2300, loss 0.533647
epoch 2400, loss 0.385456
epoch 2500, loss 0.443002
epoch 2600, loss 0.563373
epoch 2700, loss 0.526143
epoch 2800, loss 0.540783
epoch 2900, loss 0.56063
epoch 3000, loss 0.404643
epoch 3100, loss 0.667206
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
831.403 303.869
94.9786 84.1469
234.37 111.021
39.4136 36.2817
64.3569 86.8475
parameters: [ 9.704  1.159  1.591  6.332  3.166]. error: 0.144981273102.
----------------------------
epoch 0, loss 1.79207
epoch 100, loss 0.432608
epoch 200, loss 0.684628
epoch 300, loss 0.67129
epoch 400, loss 0.429822
epoch 500, loss 0.425642
epoch 600, loss 0.427228
epoch 700, loss 0.446906
epoch 800, loss 0.398715
epoch 900, loss 0.440953
epoch 1000, loss 0.361791
epoch 1100, loss 0.371492
epoch 1200, loss 0.506685
epoch 1300, loss 0.458443
epoch 1400, loss 0.412181
epoch 1500, loss 0.482906
epoch 1600, loss 0.379811
epoch 1700, loss 0.368214
epoch 1800, loss 0.355298
epoch 1900, loss 0.392637
epoch 2000, loss 0.552883
epoch 2100, loss 0.525307
epoch 2200, loss 0.465306
epoch 2300, loss 0.485183
epoch 2400, loss 0.494792
epoch 2500, loss 0.292696
epoch 2600, loss 0.357556
epoch 2700, loss 0.325495
epoch 2800, loss 0.267795
epoch 2900, loss 0.370221
epoch 3000, loss 0.509534
epoch 3100, loss 0.469619
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
234.37 127.148
38.6549 30.2952
36.7438 90.2739
3.22686 13.7701
36.7438 90.2739
parameters: [ 9.704  1.159  1.591  6.714  3.166]. error: 0.422306020486.
----------------------------
epoch 0, loss 1.3007
epoch 100, loss 0.463187
epoch 200, loss 0.587153
epoch 300, loss 0.262635
epoch 400, loss 0.645242
epoch 500, loss 0.318093
epoch 600, loss 0.449682
epoch 700, loss 0.653308
epoch 800, loss 0.600113
epoch 900, loss 0.373353
epoch 1000, loss 0.401395
epoch 1100, loss 0.375875
epoch 1200, loss 0.506893
epoch 1300, loss 0.306543
epoch 1400, loss 0.492318
epoch 1500, loss 0.513511
epoch 1600, loss 0.531079
epoch 1700, loss 0.55731
epoch 1800, loss 0.342748
epoch 1900, loss 0.539716
epoch 2000, loss 0.489607
epoch 2100, loss 0.382798
epoch 2200, loss 0.435441
epoch 2300, loss 0.468843
epoch 2400, loss 0.396318
epoch 2500, loss 0.529078
epoch 2600, loss 0.234968
epoch 2700, loss 0.374059
epoch 2800, loss 0.279403
epoch 2900, loss 0.303236
epoch 3000, loss 0.325681
epoch 3100, loss 0.522263
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
246.534 59.3848
2.37471 17.4239
3167.53 836.284
40.0937 37.6085
40.0937 37.6085
parameters: [ 9.704  1.159  1.591  6.102  3.166]. error: 1.80942257406.
----------------------------
epoch 0, loss 1.63455
epoch 100, loss 1.09425
epoch 200, loss 0.922163
epoch 300, loss 0.489543
epoch 400, loss 0.397639
epoch 500, loss 0.528446
epoch 600, loss 0.406973
epoch 700, loss 0.590694
epoch 800, loss 0.699831
epoch 900, loss 0.546056
epoch 1000, loss 0.41084
epoch 1100, loss 0.461115
epoch 1200, loss 0.619116
epoch 1300, loss 0.429775
epoch 1400, loss 0.485564
epoch 1500, loss 0.458435
epoch 1600, loss 0.358925
epoch 1700, loss 0.660813
epoch 1800, loss 0.335045
epoch 1900, loss 0.431771
epoch 2000, loss 0.431333
epoch 2100, loss 0.425988
epoch 2200, loss 0.2603
epoch 2300, loss 0.372003
epoch 2400, loss 0.663073
epoch 2500, loss 0.551672
epoch 2600, loss 0.361426
epoch 2700, loss 0.434297
epoch 2800, loss 0.377501
epoch 2900, loss 0.189788
epoch 3000, loss 0.415785
epoch 3100, loss 0.3868
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
106.094 41.7912
53.6961 19.9733
305.167 112.622
40.0937 33.8454
94.9786 113.235
parameters: [ 9.704  1.159  1.591  6.478  3.166]. error: 0.136379674018.
----------------------------
epoch 0, loss 1.30545
epoch 100, loss 0.552206
epoch 200, loss 0.559082
epoch 300, loss 0.313489
epoch 400, loss 0.59497
epoch 500, loss 0.600352
epoch 600, loss 0.639249
epoch 700, loss 0.669304
epoch 800, loss 0.51206
epoch 900, loss 0.864385
epoch 1000, loss 0.441628
epoch 1100, loss 0.383013
epoch 1200, loss 0.67955
epoch 1300, loss 0.413036
epoch 1400, loss 0.435779
epoch 1500, loss 0.367142
epoch 1600, loss 0.64498
epoch 1700, loss 0.501572
epoch 1800, loss 0.643791
epoch 1900, loss 0.522509
epoch 2000, loss 0.295622
epoch 2100, loss 0.610429
epoch 2200, loss 0.654125
epoch 2300, loss 0.545173
epoch 2400, loss 0.349406
epoch 2500, loss 0.610694
epoch 2600, loss 0.757919
epoch 2700, loss 0.276489
epoch 2800, loss 0.423987
epoch 2900, loss 0.346546
epoch 3000, loss 0.536242
epoch 3100, loss 0.379025
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
605.821 246.675
37.0194 76.8048
70.2845 92.6829
234.37 46.4664
14.1268 18.3724
parameters: [ 9.704  1.159  1.591  6.569  3.166]. error: 0.633358548704.
----------------------------
epoch 0, loss 1.05538
epoch 100, loss 0.480969
epoch 200, loss 0.563987
epoch 300, loss 0.5448
epoch 400, loss 0.434194
epoch 500, loss 0.674089
epoch 600, loss 0.496028
epoch 700, loss 0.464747
epoch 800, loss 0.396762
epoch 900, loss 0.63418
epoch 1000, loss 0.417152
epoch 1100, loss 0.476926
epoch 1200, loss 0.434991
epoch 1300, loss 0.303114
epoch 1400, loss 0.585391
epoch 1500, loss 0.403
epoch 1600, loss 0.706116
epoch 1700, loss 0.495721
epoch 1800, loss 0.49662
epoch 1900, loss 0.49994
epoch 2000, loss 0.716882
epoch 2100, loss 0.50348
epoch 2200, loss 0.430575
epoch 2300, loss 0.386479
epoch 2400, loss 0.506619
epoch 2500, loss 0.455465
epoch 2600, loss 0.246344
epoch 2700, loss 0.330138
epoch 2800, loss 0.338848
epoch 2900, loss 0.440578
epoch 3000, loss 0.472001
epoch 3100, loss 0.362389
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
33.8136 37.4122
246.534 61.4368
13.842 33.1124
21.6939 41.6834
70.2845 75.9144
parameters: [ 9.704  1.159  1.591  6.423  3.166]. error: 0.411074900817.
----------------------------
epoch 0, loss 1.27482
epoch 100, loss 1.72427
epoch 200, loss 0.870723
epoch 300, loss 0.595727
epoch 400, loss 0.948677
epoch 500, loss 0.573802
epoch 600, loss 0.535061
epoch 700, loss 0.768337
epoch 800, loss 0.586133
epoch 900, loss 0.394898
epoch 1000, loss 0.311734
epoch 1100, loss 0.406401
epoch 1200, loss 0.326536
epoch 1300, loss 0.580795
epoch 1400, loss 0.390561
epoch 1500, loss 0.647771
epoch 1600, loss 0.592758
epoch 1700, loss 0.496922
epoch 1800, loss 0.524548
epoch 1900, loss 0.415838
epoch 2000, loss 0.351502
epoch 2100, loss 0.421778
epoch 2200, loss 0.615438
epoch 2300, loss 0.337024
epoch 2400, loss 0.542016
epoch 2500, loss 0.428529
epoch 2600, loss 0.411546
epoch 2700, loss 0.478624
epoch 2800, loss 0.449029
epoch 2900, loss 0.428797
epoch 3000, loss 0.401527
epoch 3100, loss 0.527571
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
20.2734 40.3055
259.052 75.5795
20.2755 39.8449
37.0194 69.2323
10.5701 17.8629
parameters: [ 9.704  1.159  1.591  6.513  3.166]. error: 0.273229594693.
----------------------------
epoch 0, loss 1.54955
epoch 100, loss 0.582627
epoch 200, loss 0.683247
epoch 300, loss 0.457403
epoch 400, loss 0.30694
epoch 500, loss 0.527767
epoch 600, loss 0.404577
epoch 700, loss 0.290367
epoch 800, loss 0.467906
epoch 900, loss 0.807122
epoch 1000, loss 0.543954
epoch 1100, loss 0.473646
epoch 1200, loss 0.546908
epoch 1300, loss 0.421931
epoch 1400, loss 0.67257
epoch 1500, loss 0.484316
epoch 1600, loss 0.512475
epoch 1700, loss 0.376004
epoch 1800, loss 0.360074
epoch 1900, loss 0.406961
epoch 2000, loss 0.362418
epoch 2100, loss 0.321368
epoch 2200, loss 0.256554
epoch 2300, loss 0.690006
epoch 2400, loss 0.514616
epoch 2500, loss 0.480139
epoch 2600, loss 0.423338
epoch 2700, loss 0.514652
epoch 2800, loss 0.418554
epoch 2900, loss 0.194533
epoch 3000, loss 0.511656
epoch 3100, loss 0.55927
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
162.436 53.1376
53.6961 13.414
32.9279 126.007
70.3904 93.0679
28.3521 58.9702
parameters: [ 9.704  1.159  1.591  6.457  3.166]. error: 0.607067338583.
----------------------------
epoch 0, loss 1.66345
epoch 100, loss 0.494879
epoch 200, loss 0.679339
epoch 300, loss 0.47514
epoch 400, loss 0.786589
epoch 500, loss 0.808773
epoch 600, loss 0.63522
epoch 700, loss 0.414931
epoch 800, loss 0.53906
epoch 900, loss 0.653
epoch 1000, loss 0.422103
epoch 1100, loss 0.581179
epoch 1200, loss 0.63106
epoch 1300, loss 0.518841
epoch 1400, loss 0.569009
epoch 1500, loss 0.507992
epoch 1600, loss 0.317392
epoch 1700, loss 0.382379
epoch 1800, loss 0.471426
epoch 1900, loss 0.571257
epoch 2000, loss 0.406409
epoch 2100, loss 0.402431
epoch 2200, loss 0.45778
epoch 2300, loss 0.485776
epoch 2400, loss 0.42917
epoch 2500, loss 0.482778
epoch 2600, loss 0.3287
epoch 2700, loss 0.516663
epoch 2800, loss 0.411702
epoch 2900, loss 0.511907
epoch 3000, loss 0.413465
epoch 3100, loss 0.527057
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
3.22686 15.019
89.7385 558.916
23.1269 29.8947
96.1397 148.704
23.1269 29.8947
parameters: [ 9.704  1.159  1.591  6.478  3.166]. error: 0.973363224308.
----------------------------
epoch 0, loss 1.09428
epoch 100, loss 0.778813
epoch 200, loss 0.519794
epoch 300, loss 0.546863
epoch 400, loss 0.430996
epoch 500, loss 0.547882
epoch 600, loss 0.444612
epoch 700, loss 0.480245
epoch 800, loss 0.381322
epoch 900, loss 0.696048
epoch 1000, loss 0.437458
epoch 1100, loss 0.579587
epoch 1200, loss 0.606794
epoch 1300, loss 0.564245
epoch 1400, loss 0.755281
epoch 1500, loss 0.306924
epoch 1600, loss 0.607587
epoch 1700, loss 0.595128
epoch 1800, loss 0.265471
epoch 1900, loss 0.442224
epoch 2000, loss 0.434262
epoch 2100, loss 0.333636
epoch 2200, loss 0.403178
epoch 2300, loss 0.563689
epoch 2400, loss 0.599336
epoch 2500, loss 0.406114
epoch 2600, loss 0.561628
epoch 2700, loss 0.460758
epoch 2800, loss 0.328571
epoch 2900, loss 0.57905
epoch 3000, loss 0.430877
epoch 3100, loss 0.361078
epoch 3200, loss 0.325546
epoch 3300, loss 0.509504
epoch 3400, loss 0.436856
epoch 3500, loss 0.439106
epoch 3600, loss 0.66291
epoch 3700, loss 0.287889
epoch 3800, loss 0.306531
epoch 3900, loss 0.516225
epoch 4000, loss 0.470963
epoch 4100, loss 0.504808
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
209.705 95.5916
89.7385 295.737
32.0605 52.0075
259.052 109.577
209.705 95.5916
parameters: [ 9.704  1.159  1.591  6.478  4.166]. error: 0.283092905992.
----------------------------
epoch 0, loss 1.21683
epoch 100, loss 0.603193
epoch 200, loss 0.564389
epoch 300, loss 0.63862
epoch 400, loss 0.499775
epoch 500, loss 0.587987
epoch 600, loss 0.416067
epoch 700, loss 0.459121
epoch 800, loss 0.53336
epoch 900, loss 0.679663
epoch 1000, loss 0.426867
epoch 1100, loss 0.585672
epoch 1200, loss 0.508756
epoch 1300, loss 0.748275
epoch 1400, loss 0.641072
epoch 1500, loss 0.464434
epoch 1600, loss 0.421531
epoch 1700, loss 0.541039
epoch 1800, loss 0.631458
epoch 1900, loss 0.644535
epoch 2000, loss 0.611825
epoch 2100, loss 0.383883
epoch 2200, loss 0.407613
epoch 2300, loss 0.472167
epoch 2400, loss 0.44708
epoch 2500, loss 0.484064
epoch 2600, loss 0.878091
epoch 2700, loss 0.563432
epoch 2800, loss 0.401663
epoch 2900, loss 0.38609
epoch 3000, loss 0.715151
epoch 3100, loss 0.59573
epoch 3200, loss 0.352846
epoch 3300, loss 0.625742
epoch 3400, loss 0.720011
epoch 3500, loss 0.381559
epoch 3600, loss 0.472249
epoch 3700, loss 0.304248
epoch 3800, loss 0.384363
epoch 3900, loss 0.459465
epoch 4000, loss 0.377511
epoch 4100, loss 0.345641
epoch 4200, loss 0.528683
epoch 4300, loss 0.564268
epoch 4400, loss 0.474954
epoch 4500, loss 0.528325
epoch 4600, loss 0.359442
epoch 4700, loss 0.320303
epoch 4800, loss 0.268862
epoch 4900, loss 0.555942
epoch 5000, loss 0.349966
epoch 5100, loss 0.44409
epoch 5200, loss 0.569851
epoch 5300, loss 0.419672
epoch 5400, loss 0.344233
epoch 5500, loss 0.231482
epoch 5600, loss 0.510913
epoch 5700, loss 0.568752
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
56.7553 42.3313
831.403 253.079
20.2734 36.2855
89.2785 39.4881
605.821 183.933
parameters: [ 9.704  1.159  1.591  6.478  5.784]. error: 0.239739595161.
----------------------------
epoch 0, loss 1.17324
epoch 100, loss 0.392116
epoch 200, loss 0.602684
epoch 300, loss 0.458914
epoch 400, loss 0.655517
epoch 500, loss 0.487393
epoch 600, loss 0.625345
epoch 700, loss 0.570974
epoch 800, loss 0.607078
epoch 900, loss 0.349037
epoch 1000, loss 0.390693
epoch 1100, loss 0.314673
epoch 1200, loss 0.364196
epoch 1300, loss 0.334814
epoch 1400, loss 0.359397
epoch 1500, loss 0.354703
epoch 1600, loss 0.572658
epoch 1700, loss 0.355028
epoch 1800, loss 0.368633
epoch 1900, loss 0.498987
epoch 2000, loss 0.29693
epoch 2100, loss 0.346097
epoch 2200, loss 0.568188
epoch 2300, loss 0.218538
epoch 2400, loss 0.400456
epoch 2500, loss 0.391218
epoch 2600, loss 0.473223
epoch 2700, loss 0.745355
epoch 2800, loss 0.439913
epoch 2900, loss 0.520624
epoch 3000, loss 0.381637
epoch 3100, loss 0.342785
epoch 3200, loss 0.317053
epoch 3300, loss 0.517849
epoch 3400, loss 0.403677
epoch 3500, loss 0.298068
epoch 3600, loss 0.381572
epoch 3700, loss 0.341393
epoch 3800, loss 0.571595
epoch 3900, loss 0.403082
epoch 4000, loss 0.309489
epoch 4100, loss 0.46438
epoch 4200, loss 0.405889
epoch 4300, loss 0.570925
epoch 4400, loss 0.437403
epoch 4500, loss 0.327538
epoch 4600, loss 0.301726
epoch 4700, loss 0.472157
epoch 4800, loss 0.334544
epoch 4900, loss 0.374242
epoch 5000, loss 0.304435
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
305.167 83.5706
586.598 29.7321
209.705 29.7321
209.705 29.7321
106.094 55.9631
parameters: [ 9.704  1.159  1.591  6.478  5.028]. error: 17.2917584719.
----------------------------
epoch 0, loss 1.28457
epoch 100, loss 0.749385
epoch 200, loss 0.563947
epoch 300, loss 0.581015
epoch 400, loss 0.450487
epoch 500, loss 0.430888
epoch 600, loss 0.554308
epoch 700, loss 0.503417
epoch 800, loss 0.541748
epoch 900, loss 0.288939
epoch 1000, loss 0.56526
epoch 1100, loss 0.486122
epoch 1200, loss 0.320419
epoch 1300, loss 0.752003
epoch 1400, loss 0.552919
epoch 1500, loss 0.383066
epoch 1600, loss 0.484301
epoch 1700, loss 0.467942
epoch 1800, loss 0.382019
epoch 1900, loss 0.343656
epoch 2000, loss 0.285548
epoch 2100, loss 0.446759
epoch 2200, loss 0.517126
epoch 2300, loss 0.473755
epoch 2400, loss 0.631176
epoch 2500, loss 0.610408
epoch 2600, loss 0.366675
epoch 2700, loss 0.593637
epoch 2800, loss 0.603002
epoch 2900, loss 0.417569
epoch 3000, loss 0.504726
epoch 3100, loss 0.597719
epoch 3200, loss 0.48821
epoch 3300, loss 0.53411
epoch 3400, loss 0.386139
epoch 3500, loss 0.448851
epoch 3600, loss 0.409013
epoch 3700, loss 0.405426
epoch 3800, loss 0.532584
epoch 3900, loss 0.363861
epoch 4000, loss 0.445131
epoch 4100, loss 0.723531
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
146.624 87.1843
126.871 327.375
112.36 90.4173
31.6796 31.5739
23.1269 31.6156
parameters: [ 9.704  1.159  1.591  6.478  4.166]. error: 0.143636447491.
----------------------------
epoch 0, loss 1.34705
epoch 100, loss 0.795797
epoch 200, loss 0.641416
epoch 300, loss 0.369438
epoch 400, loss 0.483538
epoch 500, loss 0.455057
epoch 600, loss 0.449765
epoch 700, loss 0.533829
epoch 800, loss 0.456017
epoch 900, loss 0.450426
epoch 1000, loss 0.664414
epoch 1100, loss 0.591468
epoch 1200, loss 0.401749
epoch 1300, loss 0.42161
epoch 1400, loss 0.489034
epoch 1500, loss 0.443698
epoch 1600, loss 0.47723
epoch 1700, loss 0.424206
epoch 1800, loss 0.716956
epoch 1900, loss 0.542665
epoch 2000, loss 0.248463
epoch 2100, loss 0.399089
epoch 2200, loss 0.376601
epoch 2300, loss 0.557344
epoch 2400, loss 0.438064
epoch 2500, loss 0.76801
epoch 2600, loss 0.319122
epoch 2700, loss 0.310287
epoch 2800, loss 0.420114
epoch 2900, loss 0.560644
epoch 3000, loss 0.62575
epoch 3100, loss 0.417922
epoch 3200, loss 0.698153
epoch 3300, loss 0.621585
epoch 3400, loss 0.261073
epoch 3500, loss 0.438232
epoch 3600, loss 0.677546
epoch 3700, loss 0.245069
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
234.37 60.0268
460.913 153.575
79.3243 21.421
16.4294 33.6044
20.2734 36.6377
parameters: [ 9.704  1.159  1.591  6.478  3.784]. error: 0.361058984877.
----------------------------
epoch 0, loss 1.43773
epoch 100, loss 1.16327
epoch 200, loss 0.789533
epoch 300, loss 0.571573
epoch 400, loss 0.469382
epoch 500, loss 0.577425
epoch 600, loss 0.389476
epoch 700, loss 0.450733
epoch 800, loss 0.617159
epoch 900, loss 0.433505
epoch 1000, loss 0.448662
epoch 1100, loss 0.544431
epoch 1200, loss 0.547813
epoch 1300, loss 0.470036
epoch 1400, loss 0.385018
epoch 1500, loss 0.607795
epoch 1600, loss 0.460134
epoch 1700, loss 0.5414
epoch 1800, loss 0.383649
epoch 1900, loss 0.557162
epoch 2000, loss 0.335382
epoch 2100, loss 0.548788
epoch 2200, loss 0.36465
epoch 2300, loss 0.411818
epoch 2400, loss 0.510468
epoch 2500, loss 0.37455
epoch 2600, loss 0.422652
epoch 2700, loss 0.32806
epoch 2800, loss 0.465104
epoch 2900, loss 0.433296
epoch 3000, loss 0.453332
epoch 3100, loss 0.271119
epoch 3200, loss 0.507048
epoch 3300, loss 0.297468
epoch 3400, loss 0.229546
epoch 3500, loss 0.245604
epoch 3600, loss 0.382481
epoch 3700, loss 0.316445
epoch 3800, loss 0.379136
epoch 3900, loss 0.353762
epoch 4000, loss 0.514629
epoch 4100, loss 0.296181
epoch 4200, loss 0.348418
epoch 4300, loss 0.448165
epoch 4400, loss 0.245771
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
38.4634 159.617
2.37471 11.3245
94.9786 106.514
89.7385 474.847
89.7385 474.847
parameters: [ 9.704  1.159  1.591  6.478  4.495]. error: 0.651585164837.
----------------------------
epoch 0, loss 1.11061
epoch 100, loss 0.463878
epoch 200, loss 0.690064
epoch 300, loss 0.403326
epoch 400, loss 0.446752
epoch 500, loss 0.392499
epoch 600, loss 0.509102
epoch 700, loss 0.429677
epoch 800, loss 0.55438
epoch 900, loss 0.610897
epoch 1000, loss 0.437175
epoch 1100, loss 0.490273
epoch 1200, loss 0.436183
epoch 1300, loss 0.315232
epoch 1400, loss 0.388999
epoch 1500, loss 0.708499
epoch 1600, loss 0.266208
epoch 1700, loss 0.439055
epoch 1800, loss 0.303802
epoch 1900, loss 0.301598
epoch 2000, loss 0.311055
epoch 2100, loss 0.447438
epoch 2200, loss 0.424651
epoch 2300, loss 0.506168
epoch 2400, loss 0.361234
epoch 2500, loss 0.271371
epoch 2600, loss 0.589495
epoch 2700, loss 0.385086
epoch 2800, loss 0.418014
epoch 2900, loss 0.445911
epoch 3000, loss 0.427628
epoch 3100, loss 0.483616
epoch 3200, loss 0.328336
epoch 3300, loss 0.444319
epoch 3400, loss 0.476267
epoch 3500, loss 0.403472
epoch 3600, loss 0.489706
epoch 3700, loss 0.498022
epoch 3800, loss 0.414611
epoch 3900, loss 0.320608
epoch 4000, loss 0.232753
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
89.2785 35.9166
38.4634 157.151
40.0937 36.7709
38.304 124.75
2.37471 15.8881
parameters: [ 9.704  1.159  1.591  6.478  4.071]. error: 1.25526466248.
----------------------------
epoch 0, loss 1.34762
epoch 100, loss 0.737408
epoch 200, loss 0.451699
epoch 300, loss 0.449108
epoch 400, loss 0.408289
epoch 500, loss 0.438382
epoch 600, loss 0.567266
epoch 700, loss 0.472799
epoch 800, loss 0.633934
epoch 900, loss 0.578192
epoch 1000, loss 0.409581
epoch 1100, loss 0.484933
epoch 1200, loss 0.47021
epoch 1300, loss 0.385664
epoch 1400, loss 0.478041
epoch 1500, loss 0.488754
epoch 1600, loss 0.577091
epoch 1700, loss 0.58079
epoch 1800, loss 0.436996
epoch 1900, loss 0.468895
epoch 2000, loss 0.456641
epoch 2100, loss 0.567009
epoch 2200, loss 0.345413
epoch 2300, loss 0.549187
epoch 2400, loss 0.312228
epoch 2500, loss 0.520854
epoch 2600, loss 0.40699
epoch 2700, loss 0.405572
epoch 2800, loss 0.31908
epoch 2900, loss 0.663599
epoch 3000, loss 0.335788
epoch 3100, loss 0.350631
epoch 3200, loss 0.404093
epoch 3300, loss 0.488091
epoch 3400, loss 0.360071
epoch 3500, loss 0.510724
epoch 3600, loss 0.389773
epoch 3700, loss 0.392653
epoch 3800, loss 0.619749
epoch 3900, loss 0.41567
epoch 4000, loss 0.342971
epoch 4100, loss 0.383565
epoch 4200, loss 0.508231
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
19.4471 45.6863
21.6939 42.9533
146.624 87.8021
3.22686 12.091
69.8093 90.0822
parameters: [ 9.704  1.159  1.591  6.478  4.292]. error: 0.307811935553.
----------------------------
epoch 0, loss 1.13464
epoch 100, loss 0.600626
epoch 200, loss 0.507286
epoch 300, loss 0.38905
epoch 400, loss 0.386307
epoch 500, loss 0.334213
epoch 600, loss 0.341757
epoch 700, loss 0.588478
epoch 800, loss 0.563342
epoch 900, loss 0.734382
epoch 1000, loss 0.286262
epoch 1100, loss 0.495122
epoch 1200, loss 0.731221
epoch 1300, loss 0.405153
epoch 1400, loss 0.321835
epoch 1500, loss 0.3059
epoch 1600, loss 0.402826
epoch 1700, loss 0.338043
epoch 1800, loss 0.534677
epoch 1900, loss 0.349419
epoch 2000, loss 0.293029
epoch 2100, loss 0.290936
epoch 2200, loss 0.236763
epoch 2300, loss 0.461579
epoch 2400, loss 0.336289
epoch 2500, loss 0.474984
epoch 2600, loss 0.526944
epoch 2700, loss 0.512355
epoch 2800, loss 0.471357
epoch 2900, loss 0.366834
epoch 3000, loss 0.323173
epoch 3100, loss 0.255425
epoch 3200, loss 0.570816
epoch 3300, loss 0.52973
epoch 3400, loss 0.640507
epoch 3500, loss 0.277809
epoch 3600, loss 0.338959
epoch 3700, loss 0.613923
epoch 3800, loss 0.386099
epoch 3900, loss 0.622725
epoch 4000, loss 0.367308
epoch 4100, loss 0.488134
epoch 4200, loss 0.304663
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
2.37471 11.6725
20.2755 30.5385
21.6939 30.1673
69.8093 54.836
71.133 17.1373
parameters: [ 9.704  1.159  1.591  6.478  4.214]. error: 0.886662655178.
----------------------------
epoch 0, loss 1.3044
epoch 100, loss 0.446268
epoch 200, loss 0.71702
epoch 300, loss 0.494582
epoch 400, loss 0.331147
epoch 500, loss 0.366568
epoch 600, loss 0.76143
epoch 700, loss 0.427514
epoch 800, loss 0.401606
epoch 900, loss 0.43214
epoch 1000, loss 0.579695
epoch 1100, loss 0.530258
epoch 1200, loss 0.575118
epoch 1300, loss 0.753613
epoch 1400, loss 0.619899
epoch 1500, loss 0.647883
epoch 1600, loss 0.651787
epoch 1700, loss 0.461028
epoch 1800, loss 0.650515
epoch 1900, loss 0.377697
epoch 2000, loss 0.490065
epoch 2100, loss 0.300345
epoch 2200, loss 0.487992
epoch 2300, loss 0.426272
epoch 2400, loss 0.574087
epoch 2500, loss 0.463811
epoch 2600, loss 0.445139
epoch 2700, loss 0.472633
epoch 2800, loss 0.438384
epoch 2900, loss 0.343459
epoch 3000, loss 0.431939
epoch 3100, loss 0.265622
epoch 3200, loss 0.389194
epoch 3300, loss 0.464294
epoch 3400, loss 0.647836
epoch 3500, loss 0.228492
epoch 3600, loss 0.583754
epoch 3700, loss 0.529146
epoch 3800, loss 0.28638
epoch 3900, loss 0.4422
epoch 4000, loss 0.341487
epoch 4100, loss 0.393497
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
194.962 149.61
126.871 574.011
162.436 176.764
259.052 80.6028
194.962 149.61
parameters: [ 9.704  1.159  1.591  6.478  4.13 ]. error: 0.620586102518.
----------------------------
epoch 0, loss 1.08289
epoch 100, loss 0.415886
epoch 200, loss 0.571328
epoch 300, loss 0.569335
epoch 400, loss 0.4589
epoch 500, loss 0.450559
epoch 600, loss 0.790231
epoch 700, loss 0.628785
epoch 800, loss 0.658388
epoch 900, loss 0.529778
epoch 1000, loss 0.437826
epoch 1100, loss 0.602184
epoch 1200, loss 0.645618
epoch 1300, loss 0.488946
epoch 1400, loss 0.495701
epoch 1500, loss 0.551644
epoch 1600, loss 0.32518
epoch 1700, loss 0.53853
epoch 1800, loss 0.238554
epoch 1900, loss 0.32411
epoch 2000, loss 0.475071
epoch 2100, loss 0.33752
epoch 2200, loss 0.599422
epoch 2300, loss 0.394649
epoch 2400, loss 0.393457
epoch 2500, loss 0.615808
epoch 2600, loss 0.32484
epoch 2700, loss 0.414498
epoch 2800, loss 0.4265
epoch 2900, loss 0.429825
epoch 3000, loss 0.387798
epoch 3100, loss 0.34784
epoch 3200, loss 0.594431
epoch 3300, loss 0.35546
epoch 3400, loss 0.283304
epoch 3500, loss 0.398402
epoch 3600, loss 0.469091
epoch 3700, loss 0.38464
epoch 3800, loss 0.544482
epoch 3900, loss 0.566868
epoch 4000, loss 0.327595
epoch 4100, loss 0.50173
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
10.5701 16.8192
305.167 127.638
10.5701 16.8192
234.37 31.1992
32.9441 26.7867
parameters: [ 9.704  1.159  1.591  6.478  4.185]. error: 1.57860612066.
----------------------------
epoch 0, loss 1.61584
epoch 100, loss 0.880166
epoch 200, loss 0.615141
epoch 300, loss 0.539942
epoch 400, loss 0.314503
epoch 500, loss 0.625617
epoch 600, loss 0.287263
epoch 700, loss 0.281848
epoch 800, loss 0.38888
epoch 900, loss 0.34995
epoch 1000, loss 0.546834
epoch 1100, loss 0.436795
epoch 1200, loss 0.450846
epoch 1300, loss 0.32231
epoch 1400, loss 0.56179
epoch 1500, loss 0.39213
epoch 1600, loss 0.359096
epoch 1700, loss 0.437455
epoch 1800, loss 0.70566
epoch 1900, loss 0.275793
epoch 2000, loss 0.405668
epoch 2100, loss 0.308597
epoch 2200, loss 0.608394
epoch 2300, loss 0.478171
epoch 2400, loss 0.44566
epoch 2500, loss 0.353283
epoch 2600, loss 0.286374
epoch 2700, loss 0.712029
epoch 2800, loss 0.629235
epoch 2900, loss 0.503381
epoch 3000, loss 0.531714
epoch 3100, loss 0.360937
epoch 3200, loss 0.33857
epoch 3300, loss 0.681461
epoch 3400, loss 0.310786
epoch 3500, loss 0.703251
epoch 3600, loss 0.423236
epoch 3700, loss 0.403662
epoch 3800, loss 0.502135
epoch 3900, loss 0.406647
epoch 4000, loss 0.436944
epoch 4100, loss 0.335379
MlVaspSpeed.train: training finished. evaluation on last items: 
 actual | predicted
3.22686 13.7447
64.3569 87.3329
146.624 103.787
94.9786 103.787
89.7385 527.134
parameters: [ 9.704  1.159  1.591  6.478  4.152]. error: 0.8600097235.
   direc: array([[ 1.,  0.,  0.,  0.,  0.],
       [ 0.,  1.,  0.,  0.,  0.],
       [ 0.,  0.,  1.,  0.,  0.],
       [ 0.,  0.,  0.,  1.,  0.],
       [ 0.,  0.,  0.,  0.,  1.]])
     fun: 0.14363644749055246
 message: 'Optimization terminated successfully.'
    nfev: 197
     nit: 3
  status: 0
 success: True
       x: array([ 9.704,  1.159,  1.591,  6.478,  4.166])
finished! :)
